{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SAiDL_CV_semi.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "deae2525a19d47c784c3de77cbedccd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_045e503bdeb845a49898a9e28bcb1a14",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_06639804430d4654a98f7ade0b66665c",
              "IPY_MODEL_c3bc53edf0094ba3bce4213fe007a1e5"
            ]
          }
        },
        "045e503bdeb845a49898a9e28bcb1a14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06639804430d4654a98f7ade0b66665c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9e3bd8ab118549e59adee4518a6481b5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2640397119,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2640397119,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_89213534f141443994261626946f97e9"
          }
        },
        "c3bc53edf0094ba3bce4213fe007a1e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f8b6cad50e024ecdb63e32f59b9c2753",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2640397312/? [05:39&lt;00:00, 7781447.91it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0764791518024dc7aeae426b62a43933"
          }
        },
        "9e3bd8ab118549e59adee4518a6481b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "89213534f141443994261626946f97e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f8b6cad50e024ecdb63e32f59b9c2753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0764791518024dc7aeae426b62a43933": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM9KsArYy-Yw"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as f\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader,Dataset,random_split\n",
        "import PIL\n",
        "import random\n",
        "if (torch.cuda.is_available()):\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZWNFzvKiPmt"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):   \n",
        "        super().__init__()\n",
        "        self.l1 = nn.Conv2d(3,32,3,padding = 1)\n",
        "        self.n1 = nn.BatchNorm2d(32)\n",
        "        self.l2 = nn.Conv2d(32,32,3,padding = 1)\n",
        "        self.n2 = nn.BatchNorm2d(32)\n",
        "        self.l3 = nn.Conv2d(32,64,3,padding = 1)\n",
        "        self.n3 = nn.BatchNorm2d(64)\n",
        "        self.l4 = nn.Conv2d(64,64,3,padding = 1)\n",
        "        self.n4 = nn.BatchNorm2d(64)\n",
        "        self.l5 = nn.Conv2d(64,128,3,padding = 1)\n",
        "        self.n5 = nn.BatchNorm2d(128)\n",
        "        self.l6 = nn.Conv2d(128,128,3,padding = 1)\n",
        "        self.n6 = nn.BatchNorm2d(128)\n",
        "        self.l7 = nn.Conv2d(128,128,3,padding = 1)\n",
        "        self.n7 = nn.BatchNorm2d(128)\n",
        "        self.l8 = nn.Conv2d(128,256,3,padding = 1)\n",
        "        self.n8 = nn.BatchNorm2d(256)\n",
        "        self.l9 = nn.Conv2d(256,256,3,padding = 1)\n",
        "        self.n9 = nn.BatchNorm2d(256)\n",
        "        self.l10 = nn.Linear(9216,1024)\n",
        "        self.l11 = nn.Linear(1024,10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.drop = nn.Dropout(p = 0.3)\n",
        "        self.drop2d = nn.Dropout2d(p = 0.3)\n",
        "        self.softmax = nn.Softmax()\n",
        "        self.pool = nn.MaxPool2d(2,stride = 2)\n",
        "    def forward(self,xt,flag = False):\n",
        "      x = xt\n",
        "      convert = torch.zeros((x.shape[0],32-x.shape[1],x.shape[2],x.shape[3]))\n",
        "      convert = convert.to(device)\n",
        "      xt = torch.cat([xt,convert],dim = 1)\n",
        "      x = self.l1(x)\n",
        "      x = self.n1(x)\n",
        "      x = self.relu(x)\n",
        "      if(flag):\n",
        "        x = self.drop2d(x)\n",
        "      x = self.l2(x)\n",
        "      x = x+xt\n",
        "      x = self.n2(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.pool(x)\n",
        "      xt = x\n",
        "      x = self.l3(x)\n",
        "      x = self.n3(x)\n",
        "      x = self.relu(x)\n",
        "      if(flag):\n",
        "        x = self.drop2d(x)\n",
        "      x = self.l4(x)\n",
        "      convert = torch.zeros(xt.shape,device=device)\n",
        "      xt = torch.cat([xt,convert],dim = 1)\n",
        "      x = x + torch.reshape(xt,x.shape)\n",
        "      x = self.n4(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.pool(x)\n",
        "      xt = x\n",
        "      x = self.l5(x)\n",
        "      x = self.n5(x)\n",
        "      x = self.relu(x)\n",
        "      if(flag):\n",
        "        x = self.drop2d(x)\n",
        "      x = self.l6(x)\n",
        "      convert = torch.zeros(xt.shape,device=device)\n",
        "      xt = torch.cat([xt,convert],dim = 1)\n",
        "      x = x + torch.reshape(xt,x.shape)\n",
        "      x = self.n6(x)\n",
        "      x = self.relu(x)\n",
        "      if(flag):\n",
        "        x = self.drop2d(x)\n",
        "      x = self.pool(x)\n",
        "      xt = x\n",
        "      x = self.l7(x)\n",
        "      x = self.n7(x)\n",
        "      x = self.relu(x)\n",
        "      if(flag):\n",
        "        x = self.drop2d(x)\n",
        "      x = self.l8(x)\n",
        "      convert = torch.zeros(xt.shape,device=device)\n",
        "      xt = torch.cat([xt,convert],dim = 1)\n",
        "      x = x + torch.reshape(xt,x.shape)\n",
        "      x = self.n8(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.pool(x)\n",
        "      x = self.l9(x)\n",
        "      x = self.n9(x)\n",
        "      x = self.relu(x)\n",
        "      x = torch.reshape(x,(x.shape[0],-1,1,1))\n",
        "      x = torch.squeeze(x,dim = 2)\n",
        "      x = torch.squeeze(x,dim = 2)\n",
        "      if(flag):\n",
        "        x = self.drop(x)\n",
        "      x = self.l10(x)\n",
        "      x = torch.sigmoid(x)\n",
        "      x = self.l11(x)\n",
        "      x = self.softmax(x)\n",
        "      return x\n",
        "model = Network()\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQCGzTrmHZYB"
      },
      "source": [
        "transform = transforms.ToTensor()\n",
        "class Soupdata(Dataset):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    transform = transforms.ToTensor()\n",
        "    self.data = torchvision.datasets.STL10(root = '/',split = 'train',download = True,transform = transform)\n",
        "    self.n = len(self.data)\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  \n",
        "  def __getitem__(self,i):\n",
        "    return self.data[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133,
          "referenced_widgets": [
            "deae2525a19d47c784c3de77cbedccd5",
            "045e503bdeb845a49898a9e28bcb1a14",
            "06639804430d4654a98f7ade0b66665c",
            "c3bc53edf0094ba3bce4213fe007a1e5",
            "9e3bd8ab118549e59adee4518a6481b5",
            "89213534f141443994261626946f97e9",
            "f8b6cad50e024ecdb63e32f59b9c2753",
            "0764791518024dc7aeae426b62a43933"
          ]
        },
        "id": "F_CGRUCySvql",
        "outputId": "68dbc6fb-ad4a-4dec-c405-e1def50cb5b8"
      },
      "source": [
        "batch_size = 128\n",
        "unsoup = torchvision.datasets.STL10(root = '/',split = 'unlabeled',download = True,transform = transform)\n",
        "unsouploader = DataLoader(dataset=unsoup,batch_size = batch_size,shuffle = True)\n",
        "soup =  Soupdata()\n",
        "train_data,test_data = random_split(soup,[len(soup)-500,500])\n",
        "souptrain = DataLoader(dataset=train_data,batch_size = batch_size,shuffle = True)\n",
        "souptest = torchvision.datasets.STL10(root = '/',split = 'test',download = True,transform = transform)\n",
        "soupval = DataLoader(dataset=test_data,batch_size = len(test_data),shuffle = True)\n",
        "souptest = DataLoader(dataset=souptest,batch_size = 500,shuffle = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to /stl10_binary.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "deae2525a19d47c784c3de77cbedccd5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2640397119.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting /stl10_binary.tar.gz to /\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1a9xI6416Bn"
      },
      "source": [
        "cost = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIinezqgc6Ga"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.0001)\n",
        "def test(data):\n",
        "    c = 0\n",
        "    s = 0\n",
        "    for x,y in (data):\n",
        "        with torch.no_grad():\n",
        "            x =x.to(device)\n",
        "            y = y.to(device)\n",
        "            yt = model(x)\n",
        "            yt = torch.squeeze(yt)\n",
        "            yt = torch.argmax(yt, dim= 1)\n",
        "            c = (y == yt).sum()\n",
        "            s = y.shape[0]\n",
        "        break\n",
        "    return (100*c/s).item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kSo9xy9TYfB"
      },
      "source": [
        "def teste(data):\n",
        "    c = 0\n",
        "    s = 0\n",
        "    for x,y in (data):\n",
        "        with torch.no_grad():\n",
        "            x =x.to(device)\n",
        "            y = y.to(device)\n",
        "            yt = model(x)\n",
        "            yt = torch.squeeze(yt)\n",
        "            yt = torch.argmax(yt, dim= 1)\n",
        "            c += (y == yt).sum()\n",
        "            s += y.shape[0]\n",
        "    return (100*c/s).item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCT1lYNNfD2w",
        "outputId": "c463db87-8670-4c50-ab6d-24f131025eae"
      },
      "source": [
        "epochs = 40\n",
        "flag = False\n",
        "maxacc = 0\n",
        "for j in range(epochs):\n",
        "    for i,(xt,yt) in enumerate(souptrain) :\n",
        "        xt = xt.to(device)\n",
        "        yt = yt.to(device)\n",
        "        y_pred = model(xt,True)\n",
        "        y_pred = torch.squeeze(y_pred)\n",
        "        loss = cost(y_pred,yt)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (i%20==0):\n",
        "          acc = test(soupval)\n",
        "          testacc = test(souptrain)\n",
        "          if (acc>maxacc):\n",
        "            maxacc = acc\n",
        "          print(f'epoch {j+1} step {i} loss {loss} test_accuracy {acc} train_accuracy {testacc}')\n",
        "        else:\n",
        "          print(f'epoch {j+1} step {i} loss {loss}')\n",
        "    if (flag):\n",
        "      break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "epoch 14 step 22 loss 1.5121526718139648\n",
            "epoch 14 step 23 loss 1.5168099403381348\n",
            "epoch 14 step 24 loss 1.5245540142059326\n",
            "epoch 14 step 25 loss 1.5278013944625854\n",
            "epoch 14 step 26 loss 1.508071780204773\n",
            "epoch 14 step 27 loss 1.534417748451233\n",
            "epoch 14 step 28 loss 1.525316596031189\n",
            "epoch 14 step 29 loss 1.527147650718689\n",
            "epoch 14 step 30 loss 1.5192689895629883\n",
            "epoch 14 step 31 loss 1.4978702068328857\n",
            "epoch 14 step 32 loss 1.5379093885421753\n",
            "epoch 14 step 33 loss 1.5327365398406982\n",
            "epoch 14 step 34 loss 1.5273231267929077\n",
            "epoch 14 step 35 loss 1.5319414138793945\n",
            "epoch 14 step 36 loss 1.4994162321090698\n",
            "epoch 14 step 37 loss 1.5206022262573242\n",
            "epoch 14 step 38 loss 1.5178029537200928\n",
            "epoch 14 step 39 loss 1.5363563299179077\n",
            "epoch 14 step 40 loss 1.5479066371917725 test_accuracy 68.4000015258789 train_accuracy 96.09375\n",
            "epoch 14 step 41 loss 1.5159251689910889\n",
            "epoch 14 step 42 loss 1.5317970514297485\n",
            "epoch 14 step 43 loss 1.5192819833755493\n",
            "epoch 14 step 44 loss 1.523069977760315\n",
            "epoch 14 step 45 loss 1.492788314819336\n",
            "epoch 14 step 46 loss 1.526731014251709\n",
            "epoch 14 step 47 loss 1.5246946811676025\n",
            "epoch 14 step 48 loss 1.5244410037994385\n",
            "epoch 14 step 49 loss 1.565950632095337\n",
            "epoch 14 step 50 loss 1.5350852012634277\n",
            "epoch 14 step 51 loss 1.5292749404907227\n",
            "epoch 14 step 52 loss 1.5250422954559326\n",
            "epoch 14 step 53 loss 1.5133458375930786\n",
            "epoch 14 step 54 loss 1.48768949508667\n",
            "epoch 14 step 55 loss 1.5187907218933105\n",
            "epoch 14 step 56 loss 1.5508434772491455\n",
            "epoch 14 step 57 loss 1.5593136548995972\n",
            "epoch 14 step 58 loss 1.50316321849823\n",
            "epoch 14 step 59 loss 1.536320686340332\n",
            "epoch 14 step 60 loss 1.5257234573364258 test_accuracy 70.20000457763672 train_accuracy 95.3125\n",
            "epoch 14 step 61 loss 1.5295276641845703\n",
            "epoch 14 step 62 loss 1.5018953084945679\n",
            "epoch 14 step 63 loss 1.5457079410552979\n",
            "epoch 14 step 64 loss 1.5272547006607056\n",
            "epoch 14 step 65 loss 1.4947845935821533\n",
            "epoch 14 step 66 loss 1.4883794784545898\n",
            "epoch 14 step 67 loss 1.5064159631729126\n",
            "epoch 14 step 68 loss 1.5707111358642578\n",
            "epoch 14 step 69 loss 1.5218383073806763\n",
            "epoch 14 step 70 loss 1.536816120147705\n",
            "epoch 14 step 71 loss 1.5177196264266968\n",
            "epoch 14 step 72 loss 1.5446956157684326\n",
            "epoch 14 step 73 loss 1.5108767747879028\n",
            "epoch 14 step 74 loss 1.5066535472869873\n",
            "epoch 14 step 75 loss 1.5626837015151978\n",
            "epoch 14 step 76 loss 1.5168951749801636\n",
            "epoch 14 step 77 loss 1.5222612619400024\n",
            "epoch 14 step 78 loss 1.526533842086792\n",
            "epoch 14 step 79 loss 1.5300061702728271\n",
            "epoch 14 step 80 loss 1.5220718383789062 test_accuracy 70.20000457763672 train_accuracy 96.875\n",
            "epoch 14 step 81 loss 1.5387216806411743\n",
            "epoch 14 step 82 loss 1.485451579093933\n",
            "epoch 14 step 83 loss 1.512799620628357\n",
            "epoch 14 step 84 loss 1.4922293424606323\n",
            "epoch 14 step 85 loss 1.5456849336624146\n",
            "epoch 14 step 86 loss 1.4892909526824951\n",
            "epoch 14 step 87 loss 1.5320608615875244\n",
            "epoch 14 step 88 loss 1.525078535079956\n",
            "epoch 14 step 89 loss 1.5497058629989624\n",
            "epoch 14 step 90 loss 1.5169310569763184\n",
            "epoch 14 step 91 loss 1.5253645181655884\n",
            "epoch 14 step 92 loss 1.5201817750930786\n",
            "epoch 14 step 93 loss 1.5280804634094238\n",
            "epoch 14 step 94 loss 1.5230889320373535\n",
            "epoch 14 step 95 loss 1.5159931182861328\n",
            "epoch 14 step 96 loss 1.5651378631591797\n",
            "epoch 14 step 97 loss 1.5456597805023193\n",
            "epoch 14 step 98 loss 1.5271908044815063\n",
            "epoch 14 step 99 loss 1.5395665168762207\n",
            "epoch 14 step 100 loss 1.530480146408081 test_accuracy 70.20000457763672 train_accuracy 96.09375\n",
            "epoch 14 step 101 loss 1.5221571922302246\n",
            "epoch 14 step 102 loss 1.5018110275268555\n",
            "epoch 14 step 103 loss 1.5754188299179077\n",
            "epoch 14 step 104 loss 1.526120901107788\n",
            "epoch 14 step 105 loss 1.5322679281234741\n",
            "epoch 14 step 106 loss 1.522973895072937\n",
            "epoch 14 step 107 loss 1.5174843072891235\n",
            "epoch 14 step 108 loss 1.5496959686279297\n",
            "epoch 14 step 109 loss 1.4881359338760376\n",
            "epoch 14 step 110 loss 1.5411291122436523\n",
            "epoch 14 step 111 loss 1.5469820499420166\n",
            "epoch 14 step 112 loss 1.4969708919525146\n",
            "epoch 14 step 113 loss 1.558294415473938\n",
            "epoch 14 step 114 loss 1.4860786199569702\n",
            "epoch 14 step 115 loss 1.5142340660095215\n",
            "epoch 14 step 116 loss 1.528592824935913\n",
            "epoch 14 step 117 loss 1.542906641960144\n",
            "epoch 14 step 118 loss 1.5189365148544312\n",
            "epoch 14 step 119 loss 1.5470608472824097\n",
            "epoch 14 step 120 loss 1.5041396617889404 test_accuracy 70.20000457763672 train_accuracy 92.1875\n",
            "epoch 14 step 121 loss 1.534936785697937\n",
            "epoch 14 step 122 loss 1.5010813474655151\n",
            "epoch 14 step 123 loss 1.509168267250061\n",
            "epoch 14 step 124 loss 1.5085363388061523\n",
            "epoch 14 step 125 loss 1.5510400533676147\n",
            "epoch 14 step 126 loss 1.5317662954330444\n",
            "epoch 14 step 127 loss 1.506343960762024\n",
            "epoch 14 step 128 loss 1.5268422365188599\n",
            "epoch 14 step 129 loss 1.4983919858932495\n",
            "epoch 14 step 130 loss 1.552120327949524\n",
            "epoch 14 step 131 loss 1.5200304985046387\n",
            "epoch 14 step 132 loss 1.5064036846160889\n",
            "epoch 14 step 133 loss 1.4855557680130005\n",
            "epoch 14 step 134 loss 1.514793872833252\n",
            "epoch 14 step 135 loss 1.5538184642791748\n",
            "epoch 14 step 136 loss 1.4829366207122803\n",
            "epoch 14 step 137 loss 1.5339398384094238\n",
            "epoch 14 step 138 loss 1.514432668685913\n",
            "epoch 14 step 139 loss 1.5047273635864258\n",
            "epoch 14 step 140 loss 1.5504475831985474 test_accuracy 71.0 train_accuracy 93.75\n",
            "epoch 14 step 141 loss 1.526637315750122\n",
            "epoch 14 step 142 loss 1.538697361946106\n",
            "epoch 14 step 143 loss 1.5011296272277832\n",
            "epoch 14 step 144 loss 1.570194959640503\n",
            "epoch 14 step 145 loss 1.4998729228973389\n",
            "epoch 14 step 146 loss 1.5368506908416748\n",
            "epoch 14 step 147 loss 1.5297276973724365\n",
            "epoch 14 step 148 loss 1.5433118343353271\n",
            "epoch 14 step 149 loss 1.5250314474105835\n",
            "epoch 14 step 150 loss 1.5253362655639648\n",
            "epoch 14 step 151 loss 1.5394666194915771\n",
            "epoch 14 step 152 loss 1.5337543487548828\n",
            "epoch 14 step 153 loss 1.5649116039276123\n",
            "epoch 14 step 154 loss 1.5081578493118286\n",
            "epoch 14 step 155 loss 1.5494157075881958\n",
            "epoch 14 step 156 loss 1.5112446546554565\n",
            "epoch 14 step 157 loss 1.5101922750473022\n",
            "epoch 14 step 158 loss 1.5419299602508545\n",
            "epoch 14 step 159 loss 1.507847785949707\n",
            "epoch 14 step 160 loss 1.4960618019104004 test_accuracy 70.4000015258789 train_accuracy 92.96875\n",
            "epoch 14 step 161 loss 1.5447852611541748\n",
            "epoch 14 step 162 loss 1.5684459209442139\n",
            "epoch 14 step 163 loss 1.5207629203796387\n",
            "epoch 14 step 164 loss 1.4890763759613037\n",
            "epoch 14 step 165 loss 1.515120029449463\n",
            "epoch 14 step 166 loss 1.5215626955032349\n",
            "epoch 14 step 167 loss 1.5118125677108765\n",
            "epoch 14 step 168 loss 1.539375901222229\n",
            "epoch 14 step 169 loss 1.5447341203689575\n",
            "epoch 14 step 170 loss 1.521899700164795\n",
            "epoch 14 step 171 loss 1.5233426094055176\n",
            "epoch 14 step 172 loss 1.5049409866333008\n",
            "epoch 14 step 173 loss 1.531355857849121\n",
            "epoch 14 step 174 loss 1.5187828540802002\n",
            "epoch 14 step 175 loss 1.5185484886169434\n",
            "epoch 14 step 176 loss 1.5142781734466553\n",
            "epoch 14 step 177 loss 1.4898332357406616\n",
            "epoch 14 step 178 loss 1.5399621725082397\n",
            "epoch 14 step 179 loss 1.5151515007019043\n",
            "epoch 14 step 180 loss 1.5022709369659424 test_accuracy 70.4000015258789 train_accuracy 97.65625\n",
            "epoch 14 step 181 loss 1.5248160362243652\n",
            "epoch 14 step 182 loss 1.5291147232055664\n",
            "epoch 14 step 183 loss 1.5167158842086792\n",
            "epoch 14 step 184 loss 1.5239245891571045\n",
            "epoch 14 step 185 loss 1.4659165143966675\n",
            "epoch 15 step 0 loss 1.518206000328064 test_accuracy 70.80000305175781 train_accuracy 96.875\n",
            "epoch 15 step 1 loss 1.5329844951629639\n",
            "epoch 15 step 2 loss 1.4943673610687256\n",
            "epoch 15 step 3 loss 1.5223348140716553\n",
            "epoch 15 step 4 loss 1.5293807983398438\n",
            "epoch 15 step 5 loss 1.5370063781738281\n",
            "epoch 15 step 6 loss 1.5204805135726929\n",
            "epoch 15 step 7 loss 1.5190129280090332\n",
            "epoch 15 step 8 loss 1.5524318218231201\n",
            "epoch 15 step 9 loss 1.544170618057251\n",
            "epoch 15 step 10 loss 1.5215836763381958\n",
            "epoch 15 step 11 loss 1.5181430578231812\n",
            "epoch 15 step 12 loss 1.505510926246643\n",
            "epoch 15 step 13 loss 1.5584354400634766\n",
            "epoch 15 step 14 loss 1.55751371383667\n",
            "epoch 15 step 15 loss 1.5155948400497437\n",
            "epoch 15 step 16 loss 1.5051177740097046\n",
            "epoch 15 step 17 loss 1.541515827178955\n",
            "epoch 15 step 18 loss 1.5591375827789307\n",
            "epoch 15 step 19 loss 1.5136311054229736\n",
            "epoch 15 step 20 loss 1.5086712837219238 test_accuracy 70.20000457763672 train_accuracy 95.3125\n",
            "epoch 15 step 21 loss 1.5222725868225098\n",
            "epoch 15 step 22 loss 1.4965063333511353\n",
            "epoch 15 step 23 loss 1.5203499794006348\n",
            "epoch 15 step 24 loss 1.5113434791564941\n",
            "epoch 15 step 25 loss 1.536192536354065\n",
            "epoch 15 step 26 loss 1.503987193107605\n",
            "epoch 15 step 27 loss 1.5106401443481445\n",
            "epoch 15 step 28 loss 1.5043327808380127\n",
            "epoch 15 step 29 loss 1.5369614362716675\n",
            "epoch 15 step 30 loss 1.5429826974868774\n",
            "epoch 15 step 31 loss 1.5131304264068604\n",
            "epoch 15 step 32 loss 1.4961450099945068\n",
            "epoch 15 step 33 loss 1.5395947694778442\n",
            "epoch 15 step 34 loss 1.539548635482788\n",
            "epoch 15 step 35 loss 1.515022873878479\n",
            "epoch 15 step 36 loss 1.5305927991867065\n",
            "epoch 15 step 37 loss 1.491637945175171\n",
            "epoch 15 step 38 loss 1.5206522941589355\n",
            "epoch 15 step 39 loss 1.518669843673706\n",
            "epoch 15 step 40 loss 1.5111286640167236 test_accuracy 70.80000305175781 train_accuracy 96.875\n",
            "epoch 15 step 41 loss 1.5309406518936157\n",
            "epoch 15 step 42 loss 1.532480001449585\n",
            "epoch 15 step 43 loss 1.4993622303009033\n",
            "epoch 15 step 44 loss 1.507217526435852\n",
            "epoch 15 step 45 loss 1.5145907402038574\n",
            "epoch 15 step 46 loss 1.492743968963623\n",
            "epoch 15 step 47 loss 1.5300757884979248\n",
            "epoch 15 step 48 loss 1.5571390390396118\n",
            "epoch 15 step 49 loss 1.5052374601364136\n",
            "epoch 15 step 50 loss 1.4870688915252686\n",
            "epoch 15 step 51 loss 1.5373954772949219\n",
            "epoch 15 step 52 loss 1.5289394855499268\n",
            "epoch 15 step 53 loss 1.518492341041565\n",
            "epoch 15 step 54 loss 1.5170371532440186\n",
            "epoch 15 step 55 loss 1.5312167406082153\n",
            "epoch 15 step 56 loss 1.5145963430404663\n",
            "epoch 15 step 57 loss 1.4986445903778076\n",
            "epoch 15 step 58 loss 1.5339781045913696\n",
            "epoch 15 step 59 loss 1.5302764177322388\n",
            "epoch 15 step 60 loss 1.4859769344329834 test_accuracy 72.20000457763672 train_accuracy 96.09375\n",
            "epoch 15 step 61 loss 1.5181922912597656\n",
            "epoch 15 step 62 loss 1.507021188735962\n",
            "epoch 15 step 63 loss 1.5173957347869873\n",
            "epoch 15 step 64 loss 1.518886685371399\n",
            "epoch 15 step 65 loss 1.5104224681854248\n",
            "epoch 15 step 66 loss 1.55803644657135\n",
            "epoch 15 step 67 loss 1.512254238128662\n",
            "epoch 15 step 68 loss 1.5124995708465576\n",
            "epoch 15 step 69 loss 1.5342354774475098\n",
            "epoch 15 step 70 loss 1.5075522661209106\n",
            "epoch 15 step 71 loss 1.5453822612762451\n",
            "epoch 15 step 72 loss 1.5236661434173584\n",
            "epoch 15 step 73 loss 1.522002935409546\n",
            "epoch 15 step 74 loss 1.478104591369629\n",
            "epoch 15 step 75 loss 1.5283523797988892\n",
            "epoch 15 step 76 loss 1.5013203620910645\n",
            "epoch 15 step 77 loss 1.5119612216949463\n",
            "epoch 15 step 78 loss 1.546276330947876\n",
            "epoch 15 step 79 loss 1.5054476261138916\n",
            "epoch 15 step 80 loss 1.498421311378479 test_accuracy 71.20000457763672 train_accuracy 93.75\n",
            "epoch 15 step 81 loss 1.5239105224609375\n",
            "epoch 15 step 82 loss 1.5647096633911133\n",
            "epoch 15 step 83 loss 1.5418649911880493\n",
            "epoch 15 step 84 loss 1.539066195487976\n",
            "epoch 15 step 85 loss 1.5304410457611084\n",
            "epoch 15 step 86 loss 1.5210447311401367\n",
            "epoch 15 step 87 loss 1.5348979234695435\n",
            "epoch 15 step 88 loss 1.5341947078704834\n",
            "epoch 15 step 89 loss 1.535801649093628\n",
            "epoch 15 step 90 loss 1.4889616966247559\n",
            "epoch 15 step 91 loss 1.5330638885498047\n",
            "epoch 15 step 92 loss 1.5266841650009155\n",
            "epoch 15 step 93 loss 1.5080077648162842\n",
            "epoch 15 step 94 loss 1.530347466468811\n",
            "epoch 15 step 95 loss 1.4905434846878052\n",
            "epoch 15 step 96 loss 1.5441542863845825\n",
            "epoch 15 step 97 loss 1.536269187927246\n",
            "epoch 15 step 98 loss 1.5359779596328735\n",
            "epoch 15 step 99 loss 1.5310934782028198\n",
            "epoch 15 step 100 loss 1.5127078294754028 test_accuracy 69.80000305175781 train_accuracy 93.75\n",
            "epoch 15 step 101 loss 1.5549049377441406\n",
            "epoch 15 step 102 loss 1.5586538314819336\n",
            "epoch 15 step 103 loss 1.5349589586257935\n",
            "epoch 15 step 104 loss 1.5304712057113647\n",
            "epoch 15 step 105 loss 1.5229735374450684\n",
            "epoch 15 step 106 loss 1.5393441915512085\n",
            "epoch 15 step 107 loss 1.5088820457458496\n",
            "epoch 15 step 108 loss 1.5129213333129883\n",
            "epoch 15 step 109 loss 1.523013710975647\n",
            "epoch 15 step 110 loss 1.5078781843185425\n",
            "epoch 15 step 111 loss 1.4854912757873535\n",
            "epoch 15 step 112 loss 1.5038820505142212\n",
            "epoch 15 step 113 loss 1.4939104318618774\n",
            "epoch 15 step 114 loss 1.5345457792282104\n",
            "epoch 15 step 115 loss 1.4945294857025146\n",
            "epoch 15 step 116 loss 1.5089303255081177\n",
            "epoch 15 step 117 loss 1.528037428855896\n",
            "epoch 15 step 118 loss 1.5291533470153809\n",
            "epoch 15 step 119 loss 1.5046203136444092\n",
            "epoch 15 step 120 loss 1.5221314430236816 test_accuracy 70.4000015258789 train_accuracy 96.875\n",
            "epoch 15 step 121 loss 1.5703788995742798\n",
            "epoch 15 step 122 loss 1.5229378938674927\n",
            "epoch 15 step 123 loss 1.5552330017089844\n",
            "epoch 15 step 124 loss 1.5066416263580322\n",
            "epoch 15 step 125 loss 1.5432020425796509\n",
            "epoch 15 step 126 loss 1.5394880771636963\n",
            "epoch 15 step 127 loss 1.5595544576644897\n",
            "epoch 15 step 128 loss 1.5126073360443115\n",
            "epoch 15 step 129 loss 1.539215087890625\n",
            "epoch 15 step 130 loss 1.530929684638977\n",
            "epoch 15 step 131 loss 1.531428337097168\n",
            "epoch 15 step 132 loss 1.5284225940704346\n",
            "epoch 15 step 133 loss 1.5098387002944946\n",
            "epoch 15 step 134 loss 1.4998699426651\n",
            "epoch 15 step 135 loss 1.5352468490600586\n",
            "epoch 15 step 136 loss 1.5301858186721802\n",
            "epoch 15 step 137 loss 1.5452842712402344\n",
            "epoch 15 step 138 loss 1.4937503337860107\n",
            "epoch 15 step 139 loss 1.5180332660675049\n",
            "epoch 15 step 140 loss 1.5530060529708862 test_accuracy 70.4000015258789 train_accuracy 96.09375\n",
            "epoch 15 step 141 loss 1.489816665649414\n",
            "epoch 15 step 142 loss 1.5207769870758057\n",
            "epoch 15 step 143 loss 1.5220521688461304\n",
            "epoch 15 step 144 loss 1.5503242015838623\n",
            "epoch 15 step 145 loss 1.5032474994659424\n",
            "epoch 15 step 146 loss 1.545648455619812\n",
            "epoch 15 step 147 loss 1.556929349899292\n",
            "epoch 15 step 148 loss 1.5140610933303833\n",
            "epoch 15 step 149 loss 1.5261294841766357\n",
            "epoch 15 step 150 loss 1.5286414623260498\n",
            "epoch 15 step 151 loss 1.530104398727417\n",
            "epoch 15 step 152 loss 1.508185863494873\n",
            "epoch 15 step 153 loss 1.4958827495574951\n",
            "epoch 15 step 154 loss 1.5537769794464111\n",
            "epoch 15 step 155 loss 1.5629011392593384\n",
            "epoch 15 step 156 loss 1.502109408378601\n",
            "epoch 15 step 157 loss 1.501713514328003\n",
            "epoch 15 step 158 loss 1.5419790744781494\n",
            "epoch 15 step 159 loss 1.5209016799926758\n",
            "epoch 15 step 160 loss 1.4960975646972656 test_accuracy 70.60000610351562 train_accuracy 92.1875\n",
            "epoch 15 step 161 loss 1.5173652172088623\n",
            "epoch 15 step 162 loss 1.5277541875839233\n",
            "epoch 15 step 163 loss 1.5092005729675293\n",
            "epoch 15 step 164 loss 1.5530084371566772\n",
            "epoch 15 step 165 loss 1.5338208675384521\n",
            "epoch 15 step 166 loss 1.494733452796936\n",
            "epoch 15 step 167 loss 1.5096118450164795\n",
            "epoch 15 step 168 loss 1.4830355644226074\n",
            "epoch 15 step 169 loss 1.5006552934646606\n",
            "epoch 15 step 170 loss 1.5105518102645874\n",
            "epoch 15 step 171 loss 1.4828494787216187\n",
            "epoch 15 step 172 loss 1.5171757936477661\n",
            "epoch 15 step 173 loss 1.500610113143921\n",
            "epoch 15 step 174 loss 1.5082005262374878\n",
            "epoch 15 step 175 loss 1.5053678750991821\n",
            "epoch 15 step 176 loss 1.550818920135498\n",
            "epoch 15 step 177 loss 1.5151664018630981\n",
            "epoch 15 step 178 loss 1.5338233709335327\n",
            "epoch 15 step 179 loss 1.5144720077514648\n",
            "epoch 15 step 180 loss 1.5265676975250244 test_accuracy 71.60000610351562 train_accuracy 100.0\n",
            "epoch 15 step 181 loss 1.4850891828536987\n",
            "epoch 15 step 182 loss 1.5341174602508545\n",
            "epoch 15 step 183 loss 1.5280441045761108\n",
            "epoch 15 step 184 loss 1.4984016418457031\n",
            "epoch 15 step 185 loss 1.4931844472885132\n",
            "epoch 16 step 0 loss 1.493391752243042 test_accuracy 71.20000457763672 train_accuracy 96.875\n",
            "epoch 16 step 1 loss 1.5208827257156372\n",
            "epoch 16 step 2 loss 1.5568628311157227\n",
            "epoch 16 step 3 loss 1.4852769374847412\n",
            "epoch 16 step 4 loss 1.536787986755371\n",
            "epoch 16 step 5 loss 1.5182610750198364\n",
            "epoch 16 step 6 loss 1.5403618812561035\n",
            "epoch 16 step 7 loss 1.5215017795562744\n",
            "epoch 16 step 8 loss 1.521912932395935\n",
            "epoch 16 step 9 loss 1.5113677978515625\n",
            "epoch 16 step 10 loss 1.5239192247390747\n",
            "epoch 16 step 11 loss 1.490394949913025\n",
            "epoch 16 step 12 loss 1.5092118978500366\n",
            "epoch 16 step 13 loss 1.5515470504760742\n",
            "epoch 16 step 14 loss 1.546900749206543\n",
            "epoch 16 step 15 loss 1.5164850950241089\n",
            "epoch 16 step 16 loss 1.5014599561691284\n",
            "epoch 16 step 17 loss 1.5352553129196167\n",
            "epoch 16 step 18 loss 1.52944016456604\n",
            "epoch 16 step 19 loss 1.5903880596160889\n",
            "epoch 16 step 20 loss 1.5200495719909668 test_accuracy 71.60000610351562 train_accuracy 96.875\n",
            "epoch 16 step 21 loss 1.5128111839294434\n",
            "epoch 16 step 22 loss 1.4958902597427368\n",
            "epoch 16 step 23 loss 1.5345475673675537\n",
            "epoch 16 step 24 loss 1.503536581993103\n",
            "epoch 16 step 25 loss 1.5080852508544922\n",
            "epoch 16 step 26 loss 1.5428415536880493\n",
            "epoch 16 step 27 loss 1.539906620979309\n",
            "epoch 16 step 28 loss 1.503340721130371\n",
            "epoch 16 step 29 loss 1.5232892036437988\n",
            "epoch 16 step 30 loss 1.5074104070663452\n",
            "epoch 16 step 31 loss 1.5774221420288086\n",
            "epoch 16 step 32 loss 1.5399333238601685\n",
            "epoch 16 step 33 loss 1.5345180034637451\n",
            "epoch 16 step 34 loss 1.5293117761611938\n",
            "epoch 16 step 35 loss 1.5334495306015015\n",
            "epoch 16 step 36 loss 1.488614797592163\n",
            "epoch 16 step 37 loss 1.5271997451782227\n",
            "epoch 16 step 38 loss 1.5141832828521729\n",
            "epoch 16 step 39 loss 1.5309902429580688\n",
            "epoch 16 step 40 loss 1.5305237770080566 test_accuracy 71.0 train_accuracy 93.75\n",
            "epoch 16 step 41 loss 1.5082459449768066\n",
            "epoch 16 step 42 loss 1.4989041090011597\n",
            "epoch 16 step 43 loss 1.4970269203186035\n",
            "epoch 16 step 44 loss 1.492580533027649\n",
            "epoch 16 step 45 loss 1.5258944034576416\n",
            "epoch 16 step 46 loss 1.5136489868164062\n",
            "epoch 16 step 47 loss 1.5066843032836914\n",
            "epoch 16 step 48 loss 1.5174967050552368\n",
            "epoch 16 step 49 loss 1.5018970966339111\n",
            "epoch 16 step 50 loss 1.4685498476028442\n",
            "epoch 16 step 51 loss 1.5125341415405273\n",
            "epoch 16 step 52 loss 1.493126392364502\n",
            "epoch 16 step 53 loss 1.5246994495391846\n",
            "epoch 16 step 54 loss 1.5108155012130737\n",
            "epoch 16 step 55 loss 1.50265634059906\n",
            "epoch 16 step 56 loss 1.513135552406311\n",
            "epoch 16 step 57 loss 1.5432054996490479\n",
            "epoch 16 step 58 loss 1.5032709836959839\n",
            "epoch 16 step 59 loss 1.5241848230361938\n",
            "epoch 16 step 60 loss 1.5215284824371338 test_accuracy 70.60000610351562 train_accuracy 93.75\n",
            "epoch 16 step 61 loss 1.5494462251663208\n",
            "epoch 16 step 62 loss 1.4955540895462036\n",
            "epoch 16 step 63 loss 1.5445477962493896\n",
            "epoch 16 step 64 loss 1.5448640584945679\n",
            "epoch 16 step 65 loss 1.53281569480896\n",
            "epoch 16 step 66 loss 1.5141754150390625\n",
            "epoch 16 step 67 loss 1.5359582901000977\n",
            "epoch 16 step 68 loss 1.5339419841766357\n",
            "epoch 16 step 69 loss 1.506851315498352\n",
            "epoch 16 step 70 loss 1.5059767961502075\n",
            "epoch 16 step 71 loss 1.5286260843276978\n",
            "epoch 16 step 72 loss 1.5317202806472778\n",
            "epoch 16 step 73 loss 1.5112806558609009\n",
            "epoch 16 step 74 loss 1.5080146789550781\n",
            "epoch 16 step 75 loss 1.505263328552246\n",
            "epoch 16 step 76 loss 1.532967209815979\n",
            "epoch 16 step 77 loss 1.5192010402679443\n",
            "epoch 16 step 78 loss 1.5176112651824951\n",
            "epoch 16 step 79 loss 1.5108928680419922\n",
            "epoch 16 step 80 loss 1.5236244201660156 test_accuracy 71.4000015258789 train_accuracy 95.3125\n",
            "epoch 16 step 81 loss 1.477588415145874\n",
            "epoch 16 step 82 loss 1.5141695737838745\n",
            "epoch 16 step 83 loss 1.5299533605575562\n",
            "epoch 16 step 84 loss 1.5087003707885742\n",
            "epoch 16 step 85 loss 1.5291357040405273\n",
            "epoch 16 step 86 loss 1.5256279706954956\n",
            "epoch 16 step 87 loss 1.526824951171875\n",
            "epoch 16 step 88 loss 1.5139628648757935\n",
            "epoch 16 step 89 loss 1.530916690826416\n",
            "epoch 16 step 90 loss 1.5271841287612915\n",
            "epoch 16 step 91 loss 1.5372620820999146\n",
            "epoch 16 step 92 loss 1.4909602403640747\n",
            "epoch 16 step 93 loss 1.4893839359283447\n",
            "epoch 16 step 94 loss 1.5069806575775146\n",
            "epoch 16 step 95 loss 1.5259228944778442\n",
            "epoch 16 step 96 loss 1.5281903743743896\n",
            "epoch 16 step 97 loss 1.5150665044784546\n",
            "epoch 16 step 98 loss 1.5132520198822021\n",
            "epoch 16 step 99 loss 1.5123265981674194\n",
            "epoch 16 step 100 loss 1.513970971107483 test_accuracy 71.4000015258789 train_accuracy 95.3125\n",
            "epoch 16 step 101 loss 1.4978928565979004\n",
            "epoch 16 step 102 loss 1.5486838817596436\n",
            "epoch 16 step 103 loss 1.5123398303985596\n",
            "epoch 16 step 104 loss 1.5483710765838623\n",
            "epoch 16 step 105 loss 1.498747706413269\n",
            "epoch 16 step 106 loss 1.5368667840957642\n",
            "epoch 16 step 107 loss 1.5416028499603271\n",
            "epoch 16 step 108 loss 1.5189205408096313\n",
            "epoch 16 step 109 loss 1.5257879495620728\n",
            "epoch 16 step 110 loss 1.5168838500976562\n",
            "epoch 16 step 111 loss 1.5630536079406738\n",
            "epoch 16 step 112 loss 1.4979243278503418\n",
            "epoch 16 step 113 loss 1.5154739618301392\n",
            "epoch 16 step 114 loss 1.5214327573776245\n",
            "epoch 16 step 115 loss 1.550447940826416\n",
            "epoch 16 step 116 loss 1.5039690732955933\n",
            "epoch 16 step 117 loss 1.5283819437026978\n",
            "epoch 16 step 118 loss 1.5286571979522705\n",
            "epoch 16 step 119 loss 1.5004193782806396\n",
            "epoch 16 step 120 loss 1.495215892791748 test_accuracy 71.0 train_accuracy 97.65625\n",
            "epoch 16 step 121 loss 1.4967974424362183\n",
            "epoch 16 step 122 loss 1.5030322074890137\n",
            "epoch 16 step 123 loss 1.518154263496399\n",
            "epoch 16 step 124 loss 1.5228074789047241\n",
            "epoch 16 step 125 loss 1.5030701160430908\n",
            "epoch 16 step 126 loss 1.5631474256515503\n",
            "epoch 16 step 127 loss 1.5751895904541016\n",
            "epoch 16 step 128 loss 1.4974943399429321\n",
            "epoch 16 step 129 loss 1.5061063766479492\n",
            "epoch 16 step 130 loss 1.5259343385696411\n",
            "epoch 16 step 131 loss 1.5129706859588623\n",
            "epoch 16 step 132 loss 1.5174790620803833\n",
            "epoch 16 step 133 loss 1.4981271028518677\n",
            "epoch 16 step 134 loss 1.5195631980895996\n",
            "epoch 16 step 135 loss 1.5148564577102661\n",
            "epoch 16 step 136 loss 1.5366605520248413\n",
            "epoch 16 step 137 loss 1.5590643882751465\n",
            "epoch 16 step 138 loss 1.526779055595398\n",
            "epoch 16 step 139 loss 1.5221166610717773\n",
            "epoch 16 step 140 loss 1.5145745277404785 test_accuracy 70.60000610351562 train_accuracy 92.1875\n",
            "epoch 16 step 141 loss 1.5097594261169434\n",
            "epoch 16 step 142 loss 1.5130540132522583\n",
            "epoch 16 step 143 loss 1.517657995223999\n",
            "epoch 16 step 144 loss 1.5058661699295044\n",
            "epoch 16 step 145 loss 1.5213944911956787\n",
            "epoch 16 step 146 loss 1.5176894664764404\n",
            "epoch 16 step 147 loss 1.5262943506240845\n",
            "epoch 16 step 148 loss 1.5283814668655396\n",
            "epoch 16 step 149 loss 1.5259917974472046\n",
            "epoch 16 step 150 loss 1.520856261253357\n",
            "epoch 16 step 151 loss 1.5057986974716187\n",
            "epoch 16 step 152 loss 1.5181105136871338\n",
            "epoch 16 step 153 loss 1.5481432676315308\n",
            "epoch 16 step 154 loss 1.4963014125823975\n",
            "epoch 16 step 155 loss 1.538559913635254\n",
            "epoch 16 step 156 loss 1.5228618383407593\n",
            "epoch 16 step 157 loss 1.5070080757141113\n",
            "epoch 16 step 158 loss 1.5360413789749146\n",
            "epoch 16 step 159 loss 1.527582049369812\n",
            "epoch 16 step 160 loss 1.5012179613113403 test_accuracy 71.60000610351562 train_accuracy 97.65625\n",
            "epoch 16 step 161 loss 1.5151649713516235\n",
            "epoch 16 step 162 loss 1.5566432476043701\n",
            "epoch 16 step 163 loss 1.5198967456817627\n",
            "epoch 16 step 164 loss 1.5386133193969727\n",
            "epoch 16 step 165 loss 1.497321367263794\n",
            "epoch 16 step 166 loss 1.5198818445205688\n",
            "epoch 16 step 167 loss 1.5116286277770996\n",
            "epoch 16 step 168 loss 1.5356690883636475\n",
            "epoch 16 step 169 loss 1.5225801467895508\n",
            "epoch 16 step 170 loss 1.511739730834961\n",
            "epoch 16 step 171 loss 1.5038803815841675\n",
            "epoch 16 step 172 loss 1.548115849494934\n",
            "epoch 16 step 173 loss 1.5273240804672241\n",
            "epoch 16 step 174 loss 1.5356582403182983\n",
            "epoch 16 step 175 loss 1.514783263206482\n",
            "epoch 16 step 176 loss 1.5036541223526\n",
            "epoch 16 step 177 loss 1.486331582069397\n",
            "epoch 16 step 178 loss 1.5198991298675537\n",
            "epoch 16 step 179 loss 1.5277494192123413\n",
            "epoch 16 step 180 loss 1.5245909690856934 test_accuracy 71.80000305175781 train_accuracy 94.53125\n",
            "epoch 16 step 181 loss 1.501007318496704\n",
            "epoch 16 step 182 loss 1.5214169025421143\n",
            "epoch 16 step 183 loss 1.5411814451217651\n",
            "epoch 16 step 184 loss 1.5187311172485352\n",
            "epoch 16 step 185 loss 1.5172783136367798\n",
            "epoch 17 step 0 loss 1.5210598707199097 test_accuracy 71.4000015258789 train_accuracy 95.3125\n",
            "epoch 17 step 1 loss 1.5360963344573975\n",
            "epoch 17 step 2 loss 1.522692322731018\n",
            "epoch 17 step 3 loss 1.5229061841964722\n",
            "epoch 17 step 4 loss 1.528261661529541\n",
            "epoch 17 step 5 loss 1.5136748552322388\n",
            "epoch 17 step 6 loss 1.523543357849121\n",
            "epoch 17 step 7 loss 1.5121127367019653\n",
            "epoch 17 step 8 loss 1.5118740797042847\n",
            "epoch 17 step 9 loss 1.5351290702819824\n",
            "epoch 17 step 10 loss 1.5089722871780396\n",
            "epoch 17 step 11 loss 1.4989314079284668\n",
            "epoch 17 step 12 loss 1.506518840789795\n",
            "epoch 17 step 13 loss 1.5159796476364136\n",
            "epoch 17 step 14 loss 1.5172368288040161\n",
            "epoch 17 step 15 loss 1.5009554624557495\n",
            "epoch 17 step 16 loss 1.5032662153244019\n",
            "epoch 17 step 17 loss 1.5164200067520142\n",
            "epoch 17 step 18 loss 1.5059581995010376\n",
            "epoch 17 step 19 loss 1.5370817184448242\n",
            "epoch 17 step 20 loss 1.4981824159622192 test_accuracy 71.20000457763672 train_accuracy 93.75\n",
            "epoch 17 step 21 loss 1.545224666595459\n",
            "epoch 17 step 22 loss 1.4881397485733032\n",
            "epoch 17 step 23 loss 1.5084264278411865\n",
            "epoch 17 step 24 loss 1.497732400894165\n",
            "epoch 17 step 25 loss 1.5270079374313354\n",
            "epoch 17 step 26 loss 1.5353089570999146\n",
            "epoch 17 step 27 loss 1.4886378049850464\n",
            "epoch 17 step 28 loss 1.4967485666275024\n",
            "epoch 17 step 29 loss 1.5064473152160645\n",
            "epoch 17 step 30 loss 1.5081894397735596\n",
            "epoch 17 step 31 loss 1.5340310335159302\n",
            "epoch 17 step 32 loss 1.516340732574463\n",
            "epoch 17 step 33 loss 1.4912818670272827\n",
            "epoch 17 step 34 loss 1.5326483249664307\n",
            "epoch 17 step 35 loss 1.5139191150665283\n",
            "epoch 17 step 36 loss 1.5224676132202148\n",
            "epoch 17 step 37 loss 1.4748591184616089\n",
            "epoch 17 step 38 loss 1.5029278993606567\n",
            "epoch 17 step 39 loss 1.5108710527420044\n",
            "epoch 17 step 40 loss 1.5171149969100952 test_accuracy 71.60000610351562 train_accuracy 95.3125\n",
            "epoch 17 step 41 loss 1.5323853492736816\n",
            "epoch 17 step 42 loss 1.5398979187011719\n",
            "epoch 17 step 43 loss 1.5272817611694336\n",
            "epoch 17 step 44 loss 1.5345726013183594\n",
            "epoch 17 step 45 loss 1.5493983030319214\n",
            "epoch 17 step 46 loss 1.5149208307266235\n",
            "epoch 17 step 47 loss 1.4937536716461182\n",
            "epoch 17 step 48 loss 1.524362564086914\n",
            "epoch 17 step 49 loss 1.4924358129501343\n",
            "epoch 17 step 50 loss 1.5037367343902588\n",
            "epoch 17 step 51 loss 1.5042216777801514\n",
            "epoch 17 step 52 loss 1.5374815464019775\n",
            "epoch 17 step 53 loss 1.5375289916992188\n",
            "epoch 17 step 54 loss 1.518727421760559\n",
            "epoch 17 step 55 loss 1.5316866636276245\n",
            "epoch 17 step 56 loss 1.5220344066619873\n",
            "epoch 17 step 57 loss 1.5114219188690186\n",
            "epoch 17 step 58 loss 1.52489173412323\n",
            "epoch 17 step 59 loss 1.5301427841186523\n",
            "epoch 17 step 60 loss 1.5251954793930054 test_accuracy 71.60000610351562 train_accuracy 95.3125\n",
            "epoch 17 step 61 loss 1.5183128118515015\n",
            "epoch 17 step 62 loss 1.486894965171814\n",
            "epoch 17 step 63 loss 1.4958436489105225\n",
            "epoch 17 step 64 loss 1.5327130556106567\n",
            "epoch 17 step 65 loss 1.5130106210708618\n",
            "epoch 17 step 66 loss 1.5228984355926514\n",
            "epoch 17 step 67 loss 1.5354108810424805\n",
            "epoch 17 step 68 loss 1.5540648698806763\n",
            "epoch 17 step 69 loss 1.5514628887176514\n",
            "epoch 17 step 70 loss 1.489898920059204\n",
            "epoch 17 step 71 loss 1.4979913234710693\n",
            "epoch 17 step 72 loss 1.5337697267532349\n",
            "epoch 17 step 73 loss 1.4924428462982178\n",
            "epoch 17 step 74 loss 1.5381550788879395\n",
            "epoch 17 step 75 loss 1.5460436344146729\n",
            "epoch 17 step 76 loss 1.5260995626449585\n",
            "epoch 17 step 77 loss 1.5071184635162354\n",
            "epoch 17 step 78 loss 1.5134364366531372\n",
            "epoch 17 step 79 loss 1.5276366472244263\n",
            "epoch 17 step 80 loss 1.5234322547912598 test_accuracy 71.4000015258789 train_accuracy 98.4375\n",
            "epoch 17 step 81 loss 1.5303384065628052\n",
            "epoch 17 step 82 loss 1.5474029779434204\n",
            "epoch 17 step 83 loss 1.4891753196716309\n",
            "epoch 17 step 84 loss 1.5244405269622803\n",
            "epoch 17 step 85 loss 1.5043774843215942\n",
            "epoch 17 step 86 loss 1.5000808238983154\n",
            "epoch 17 step 87 loss 1.5192065238952637\n",
            "epoch 17 step 88 loss 1.5293055772781372\n",
            "epoch 17 step 89 loss 1.5096670389175415\n",
            "epoch 17 step 90 loss 1.5199074745178223\n",
            "epoch 17 step 91 loss 1.5313470363616943\n",
            "epoch 17 step 92 loss 1.5195931196212769\n",
            "epoch 17 step 93 loss 1.5126862525939941\n",
            "epoch 17 step 94 loss 1.5550273656845093\n",
            "epoch 17 step 95 loss 1.5495516061782837\n",
            "epoch 17 step 96 loss 1.5158836841583252\n",
            "epoch 17 step 97 loss 1.5017856359481812\n",
            "epoch 17 step 98 loss 1.5223772525787354\n",
            "epoch 17 step 99 loss 1.5382450819015503\n",
            "epoch 17 step 100 loss 1.5179502964019775 test_accuracy 71.60000610351562 train_accuracy 96.09375\n",
            "epoch 17 step 101 loss 1.518870234489441\n",
            "epoch 17 step 102 loss 1.53179931640625\n",
            "epoch 17 step 103 loss 1.4939113855361938\n",
            "epoch 17 step 104 loss 1.5486586093902588\n",
            "epoch 17 step 105 loss 1.5057190656661987\n",
            "epoch 17 step 106 loss 1.5034103393554688\n",
            "epoch 17 step 107 loss 1.5280495882034302\n",
            "epoch 17 step 108 loss 1.5356111526489258\n",
            "epoch 17 step 109 loss 1.5101219415664673\n",
            "epoch 17 step 110 loss 1.5421327352523804\n",
            "epoch 17 step 111 loss 1.5712374448776245\n",
            "epoch 17 step 112 loss 1.529671549797058\n",
            "epoch 17 step 113 loss 1.5140116214752197\n",
            "epoch 17 step 114 loss 1.5251126289367676\n",
            "epoch 17 step 115 loss 1.5282057523727417\n",
            "epoch 17 step 116 loss 1.5188510417938232\n",
            "epoch 17 step 117 loss 1.4985147714614868\n",
            "epoch 17 step 118 loss 1.5505704879760742\n",
            "epoch 17 step 119 loss 1.5420010089874268\n",
            "epoch 17 step 120 loss 1.504921555519104 test_accuracy 71.80000305175781 train_accuracy 96.09375\n",
            "epoch 17 step 121 loss 1.5345391035079956\n",
            "epoch 17 step 122 loss 1.5191848278045654\n",
            "epoch 17 step 123 loss 1.5185264348983765\n",
            "epoch 17 step 124 loss 1.5575833320617676\n",
            "epoch 17 step 125 loss 1.5219346284866333\n",
            "epoch 17 step 126 loss 1.521946907043457\n",
            "epoch 17 step 127 loss 1.5416511297225952\n",
            "epoch 17 step 128 loss 1.5287846326828003\n",
            "epoch 17 step 129 loss 1.505619764328003\n",
            "epoch 17 step 130 loss 1.5333266258239746\n",
            "epoch 17 step 131 loss 1.486804485321045\n",
            "epoch 17 step 132 loss 1.5083063840866089\n",
            "epoch 17 step 133 loss 1.517350673675537\n",
            "epoch 17 step 134 loss 1.547167181968689\n",
            "epoch 17 step 135 loss 1.4995481967926025\n",
            "epoch 17 step 136 loss 1.5167800188064575\n",
            "epoch 17 step 137 loss 1.537161111831665\n",
            "epoch 17 step 138 loss 1.5215357542037964\n",
            "epoch 17 step 139 loss 1.5366454124450684\n",
            "epoch 17 step 140 loss 1.5406465530395508 test_accuracy 72.0 train_accuracy 94.53125\n",
            "epoch 17 step 141 loss 1.4896774291992188\n",
            "epoch 17 step 142 loss 1.507755994796753\n",
            "epoch 17 step 143 loss 1.5138614177703857\n",
            "epoch 17 step 144 loss 1.557900071144104\n",
            "epoch 17 step 145 loss 1.5367553234100342\n",
            "epoch 17 step 146 loss 1.5161809921264648\n",
            "epoch 17 step 147 loss 1.538336992263794\n",
            "epoch 17 step 148 loss 1.499127984046936\n",
            "epoch 17 step 149 loss 1.5228261947631836\n",
            "epoch 17 step 150 loss 1.5394593477249146\n",
            "epoch 17 step 151 loss 1.5317461490631104\n",
            "epoch 17 step 152 loss 1.4960750341415405\n",
            "epoch 17 step 153 loss 1.5073862075805664\n",
            "epoch 17 step 154 loss 1.5224536657333374\n",
            "epoch 17 step 155 loss 1.501570701599121\n",
            "epoch 17 step 156 loss 1.508111596107483\n",
            "epoch 17 step 157 loss 1.5257858037948608\n",
            "epoch 17 step 158 loss 1.4625060558319092\n",
            "epoch 17 step 159 loss 1.490925669670105\n",
            "epoch 17 step 160 loss 1.5255814790725708 test_accuracy 71.20000457763672 train_accuracy 92.1875\n",
            "epoch 17 step 161 loss 1.517745852470398\n",
            "epoch 17 step 162 loss 1.480466365814209\n",
            "epoch 17 step 163 loss 1.5517888069152832\n",
            "epoch 17 step 164 loss 1.535206913948059\n",
            "epoch 17 step 165 loss 1.5357662439346313\n",
            "epoch 17 step 166 loss 1.530421257019043\n",
            "epoch 17 step 167 loss 1.5303927659988403\n",
            "epoch 17 step 168 loss 1.4987845420837402\n",
            "epoch 17 step 169 loss 1.5349323749542236\n",
            "epoch 17 step 170 loss 1.5386189222335815\n",
            "epoch 17 step 171 loss 1.5787322521209717\n",
            "epoch 17 step 172 loss 1.5489156246185303\n",
            "epoch 17 step 173 loss 1.5165373086929321\n",
            "epoch 17 step 174 loss 1.491747260093689\n",
            "epoch 17 step 175 loss 1.5277079343795776\n",
            "epoch 17 step 176 loss 1.5293329954147339\n",
            "epoch 17 step 177 loss 1.5168673992156982\n",
            "epoch 17 step 178 loss 1.5226194858551025\n",
            "epoch 17 step 179 loss 1.5214091539382935\n",
            "epoch 17 step 180 loss 1.5079916715621948 test_accuracy 71.60000610351562 train_accuracy 96.875\n",
            "epoch 17 step 181 loss 1.5164109468460083\n",
            "epoch 17 step 182 loss 1.4861202239990234\n",
            "epoch 17 step 183 loss 1.4947788715362549\n",
            "epoch 17 step 184 loss 1.5004653930664062\n",
            "epoch 17 step 185 loss 1.4842591285705566\n",
            "epoch 18 step 0 loss 1.49472177028656 test_accuracy 71.60000610351562 train_accuracy 96.875\n",
            "epoch 18 step 1 loss 1.5011612176895142\n",
            "epoch 18 step 2 loss 1.5174407958984375\n",
            "epoch 18 step 3 loss 1.528702974319458\n",
            "epoch 18 step 4 loss 1.501708745956421\n",
            "epoch 18 step 5 loss 1.5280159711837769\n",
            "epoch 18 step 6 loss 1.5294116735458374\n",
            "epoch 18 step 7 loss 1.4941589832305908\n",
            "epoch 18 step 8 loss 1.5137470960617065\n",
            "epoch 18 step 9 loss 1.5105133056640625\n",
            "epoch 18 step 10 loss 1.5380631685256958\n",
            "epoch 18 step 11 loss 1.5047448873519897\n",
            "epoch 18 step 12 loss 1.4985929727554321\n",
            "epoch 18 step 13 loss 1.48954439163208\n",
            "epoch 18 step 14 loss 1.498067855834961\n",
            "epoch 18 step 15 loss 1.4974976778030396\n",
            "epoch 18 step 16 loss 1.496685266494751\n",
            "epoch 18 step 17 loss 1.498569130897522\n",
            "epoch 18 step 18 loss 1.5163545608520508\n",
            "epoch 18 step 19 loss 1.515135645866394\n",
            "epoch 18 step 20 loss 1.560886263847351 test_accuracy 71.80000305175781 train_accuracy 96.875\n",
            "epoch 18 step 21 loss 1.548084020614624\n",
            "epoch 18 step 22 loss 1.5053194761276245\n",
            "epoch 18 step 23 loss 1.5266578197479248\n",
            "epoch 18 step 24 loss 1.5531439781188965\n",
            "epoch 18 step 25 loss 1.5038446187973022\n",
            "epoch 18 step 26 loss 1.5229485034942627\n",
            "epoch 18 step 27 loss 1.5559605360031128\n",
            "epoch 18 step 28 loss 1.5291191339492798\n",
            "epoch 18 step 29 loss 1.5351945161819458\n",
            "epoch 18 step 30 loss 1.500780463218689\n",
            "epoch 18 step 31 loss 1.50901198387146\n",
            "epoch 18 step 32 loss 1.5523653030395508\n",
            "epoch 18 step 33 loss 1.536437749862671\n",
            "epoch 18 step 34 loss 1.5531505346298218\n",
            "epoch 18 step 35 loss 1.522092580795288\n",
            "epoch 18 step 36 loss 1.5483708381652832\n",
            "epoch 18 step 37 loss 1.5116983652114868\n",
            "epoch 18 step 38 loss 1.517552375793457\n",
            "epoch 18 step 39 loss 1.4981043338775635\n",
            "epoch 18 step 40 loss 1.4956578016281128 test_accuracy 72.0 train_accuracy 94.53125\n",
            "epoch 18 step 41 loss 1.5227490663528442\n",
            "epoch 18 step 42 loss 1.5123491287231445\n",
            "epoch 18 step 43 loss 1.5112459659576416\n",
            "epoch 18 step 44 loss 1.525546908378601\n",
            "epoch 18 step 45 loss 1.505894660949707\n",
            "epoch 18 step 46 loss 1.4831486940383911\n",
            "epoch 18 step 47 loss 1.5528223514556885\n",
            "epoch 18 step 48 loss 1.5421106815338135\n",
            "epoch 18 step 49 loss 1.5075607299804688\n",
            "epoch 18 step 50 loss 1.5017801523208618\n",
            "epoch 18 step 51 loss 1.4828293323516846\n",
            "epoch 18 step 52 loss 1.5625015497207642\n",
            "epoch 18 step 53 loss 1.513289451599121\n",
            "epoch 18 step 54 loss 1.5137455463409424\n",
            "epoch 18 step 55 loss 1.5146507024765015\n",
            "epoch 18 step 56 loss 1.503382682800293\n",
            "epoch 18 step 57 loss 1.4734174013137817\n",
            "epoch 18 step 58 loss 1.5465070009231567\n",
            "epoch 18 step 59 loss 1.4929344654083252\n",
            "epoch 18 step 60 loss 1.5023444890975952 test_accuracy 71.80000305175781 train_accuracy 96.875\n",
            "epoch 18 step 61 loss 1.522503137588501\n",
            "epoch 18 step 62 loss 1.556580901145935\n",
            "epoch 18 step 63 loss 1.575488567352295\n",
            "epoch 18 step 64 loss 1.5449512004852295\n",
            "epoch 18 step 65 loss 1.5252019166946411\n",
            "epoch 18 step 66 loss 1.4975496530532837\n",
            "epoch 18 step 67 loss 1.5276379585266113\n",
            "epoch 18 step 68 loss 1.4955339431762695\n",
            "epoch 18 step 69 loss 1.514153242111206\n",
            "epoch 18 step 70 loss 1.522830605506897\n",
            "epoch 18 step 71 loss 1.5336122512817383\n",
            "epoch 18 step 72 loss 1.4832789897918701\n",
            "epoch 18 step 73 loss 1.5200886726379395\n",
            "epoch 18 step 74 loss 1.5194917917251587\n",
            "epoch 18 step 75 loss 1.5255359411239624\n",
            "epoch 18 step 76 loss 1.5265558958053589\n",
            "epoch 18 step 77 loss 1.5295238494873047\n",
            "epoch 18 step 78 loss 1.546604037284851\n",
            "epoch 18 step 79 loss 1.5270566940307617\n",
            "epoch 18 step 80 loss 1.5428627729415894 test_accuracy 71.80000305175781 train_accuracy 94.53125\n",
            "epoch 18 step 81 loss 1.5125175714492798\n",
            "epoch 18 step 82 loss 1.556391716003418\n",
            "epoch 18 step 83 loss 1.529763102531433\n",
            "epoch 18 step 84 loss 1.544772982597351\n",
            "epoch 18 step 85 loss 1.520616054534912\n",
            "epoch 18 step 86 loss 1.5040125846862793\n",
            "epoch 18 step 87 loss 1.5094956159591675\n",
            "epoch 18 step 88 loss 1.4925243854522705\n",
            "epoch 18 step 89 loss 1.5063480138778687\n",
            "epoch 18 step 90 loss 1.5218383073806763\n",
            "epoch 18 step 91 loss 1.4986454248428345\n",
            "epoch 18 step 92 loss 1.5170726776123047\n",
            "epoch 18 step 93 loss 1.5120314359664917\n",
            "epoch 18 step 94 loss 1.520215392112732\n",
            "epoch 18 step 95 loss 1.4958852529525757\n",
            "epoch 18 step 96 loss 1.553239345550537\n",
            "epoch 18 step 97 loss 1.4908900260925293\n",
            "epoch 18 step 98 loss 1.5718084573745728\n",
            "epoch 18 step 99 loss 1.4837732315063477\n",
            "epoch 18 step 100 loss 1.5027562379837036 test_accuracy 71.0 train_accuracy 98.4375\n",
            "epoch 18 step 101 loss 1.5450366735458374\n",
            "epoch 18 step 102 loss 1.5021007061004639\n",
            "epoch 18 step 103 loss 1.5023170709609985\n",
            "epoch 18 step 104 loss 1.5247528553009033\n",
            "epoch 18 step 105 loss 1.5019170045852661\n",
            "epoch 18 step 106 loss 1.5288724899291992\n",
            "epoch 18 step 107 loss 1.497119665145874\n",
            "epoch 18 step 108 loss 1.5258152484893799\n",
            "epoch 18 step 109 loss 1.542414903640747\n",
            "epoch 18 step 110 loss 1.5065293312072754\n",
            "epoch 18 step 111 loss 1.507869005203247\n",
            "epoch 18 step 112 loss 1.5135098695755005\n",
            "epoch 18 step 113 loss 1.5233360528945923\n",
            "epoch 18 step 114 loss 1.5010654926300049\n",
            "epoch 18 step 115 loss 1.5569992065429688\n",
            "epoch 18 step 116 loss 1.5275146961212158\n",
            "epoch 18 step 117 loss 1.4919525384902954\n",
            "epoch 18 step 118 loss 1.5439659357070923\n",
            "epoch 18 step 119 loss 1.5321658849716187\n",
            "epoch 18 step 120 loss 1.5101633071899414 test_accuracy 71.4000015258789 train_accuracy 96.09375\n",
            "epoch 18 step 121 loss 1.554988145828247\n",
            "epoch 18 step 122 loss 1.5581598281860352\n",
            "epoch 18 step 123 loss 1.5114535093307495\n",
            "epoch 18 step 124 loss 1.487890362739563\n",
            "epoch 18 step 125 loss 1.5260071754455566\n",
            "epoch 18 step 126 loss 1.5146632194519043\n",
            "epoch 18 step 127 loss 1.5499725341796875\n",
            "epoch 18 step 128 loss 1.5336861610412598\n",
            "epoch 18 step 129 loss 1.5303672552108765\n",
            "epoch 18 step 130 loss 1.5079891681671143\n",
            "epoch 18 step 131 loss 1.5195504426956177\n",
            "epoch 18 step 132 loss 1.5512900352478027\n",
            "epoch 18 step 133 loss 1.5177255868911743\n",
            "epoch 18 step 134 loss 1.517250657081604\n",
            "epoch 18 step 135 loss 1.5225954055786133\n",
            "epoch 18 step 136 loss 1.480429768562317\n",
            "epoch 18 step 137 loss 1.5293387174606323\n",
            "epoch 18 step 138 loss 1.5341705083847046\n",
            "epoch 18 step 139 loss 1.5031384229660034\n",
            "epoch 18 step 140 loss 1.5257922410964966 test_accuracy 70.80000305175781 train_accuracy 97.65625\n",
            "epoch 18 step 141 loss 1.5269163846969604\n",
            "epoch 18 step 142 loss 1.5278986692428589\n",
            "epoch 18 step 143 loss 1.5012915134429932\n",
            "epoch 18 step 144 loss 1.504233956336975\n",
            "epoch 18 step 145 loss 1.5064181089401245\n",
            "epoch 18 step 146 loss 1.5097459554672241\n",
            "epoch 18 step 147 loss 1.5118005275726318\n",
            "epoch 18 step 148 loss 1.5058244466781616\n",
            "epoch 18 step 149 loss 1.5119075775146484\n",
            "epoch 18 step 150 loss 1.5242724418640137\n",
            "epoch 18 step 151 loss 1.5084646940231323\n",
            "epoch 18 step 152 loss 1.5045098066329956\n",
            "epoch 18 step 153 loss 1.511390209197998\n",
            "epoch 18 step 154 loss 1.5836060047149658\n",
            "epoch 18 step 155 loss 1.534636378288269\n",
            "epoch 18 step 156 loss 1.4987419843673706\n",
            "epoch 18 step 157 loss 1.4945366382598877\n",
            "epoch 18 step 158 loss 1.5352857112884521\n",
            "epoch 18 step 159 loss 1.5228137969970703\n",
            "epoch 18 step 160 loss 1.5429332256317139 test_accuracy 72.0 train_accuracy 94.53125\n",
            "epoch 18 step 161 loss 1.4877079725265503\n",
            "epoch 18 step 162 loss 1.5560294389724731\n",
            "epoch 18 step 163 loss 1.5041218996047974\n",
            "epoch 18 step 164 loss 1.5074559450149536\n",
            "epoch 18 step 165 loss 1.5021436214447021\n",
            "epoch 18 step 166 loss 1.5285195112228394\n",
            "epoch 18 step 167 loss 1.5429075956344604\n",
            "epoch 18 step 168 loss 1.4950981140136719\n",
            "epoch 18 step 169 loss 1.5026663541793823\n",
            "epoch 18 step 170 loss 1.501821756362915\n",
            "epoch 18 step 171 loss 1.5375370979309082\n",
            "epoch 18 step 172 loss 1.4909191131591797\n",
            "epoch 18 step 173 loss 1.5019055604934692\n",
            "epoch 18 step 174 loss 1.5299874544143677\n",
            "epoch 18 step 175 loss 1.5160114765167236\n",
            "epoch 18 step 176 loss 1.5274434089660645\n",
            "epoch 18 step 177 loss 1.5028512477874756\n",
            "epoch 18 step 178 loss 1.542172908782959\n",
            "epoch 18 step 179 loss 1.5058233737945557\n",
            "epoch 18 step 180 loss 1.5046231746673584 test_accuracy 71.4000015258789 train_accuracy 96.875\n",
            "epoch 18 step 181 loss 1.5206820964813232\n",
            "epoch 18 step 182 loss 1.5363118648529053\n",
            "epoch 18 step 183 loss 1.527138113975525\n",
            "epoch 18 step 184 loss 1.5283782482147217\n",
            "epoch 18 step 185 loss 1.523393988609314\n",
            "epoch 19 step 0 loss 1.5117591619491577 test_accuracy 70.4000015258789 train_accuracy 95.3125\n",
            "epoch 19 step 1 loss 1.5175197124481201\n",
            "epoch 19 step 2 loss 1.5106326341629028\n",
            "epoch 19 step 3 loss 1.5351539850234985\n",
            "epoch 19 step 4 loss 1.5076900720596313\n",
            "epoch 19 step 5 loss 1.5001009702682495\n",
            "epoch 19 step 6 loss 1.516297459602356\n",
            "epoch 19 step 7 loss 1.5016885995864868\n",
            "epoch 19 step 8 loss 1.5500497817993164\n",
            "epoch 19 step 9 loss 1.4944716691970825\n",
            "epoch 19 step 10 loss 1.514357328414917\n",
            "epoch 19 step 11 loss 1.5295166969299316\n",
            "epoch 19 step 12 loss 1.5345876216888428\n",
            "epoch 19 step 13 loss 1.5120642185211182\n",
            "epoch 19 step 14 loss 1.5088393688201904\n",
            "epoch 19 step 15 loss 1.5615030527114868\n",
            "epoch 19 step 16 loss 1.5184447765350342\n",
            "epoch 19 step 17 loss 1.5095224380493164\n",
            "epoch 19 step 18 loss 1.5150306224822998\n",
            "epoch 19 step 19 loss 1.5002057552337646\n",
            "epoch 19 step 20 loss 1.5207109451293945 test_accuracy 71.0 train_accuracy 98.4375\n",
            "epoch 19 step 21 loss 1.5150457620620728\n",
            "epoch 19 step 22 loss 1.5181444883346558\n",
            "epoch 19 step 23 loss 1.4888025522232056\n",
            "epoch 19 step 24 loss 1.5362952947616577\n",
            "epoch 19 step 25 loss 1.508226990699768\n",
            "epoch 19 step 26 loss 1.5126497745513916\n",
            "epoch 19 step 27 loss 1.5354290008544922\n",
            "epoch 19 step 28 loss 1.4986697435379028\n",
            "epoch 19 step 29 loss 1.4848880767822266\n",
            "epoch 19 step 30 loss 1.5083792209625244\n",
            "epoch 19 step 31 loss 1.4972862005233765\n",
            "epoch 19 step 32 loss 1.513035535812378\n",
            "epoch 19 step 33 loss 1.490160346031189\n",
            "epoch 19 step 34 loss 1.4989148378372192\n",
            "epoch 19 step 35 loss 1.5283886194229126\n",
            "epoch 19 step 36 loss 1.4961609840393066\n",
            "epoch 19 step 37 loss 1.4911054372787476\n",
            "epoch 19 step 38 loss 1.501370906829834\n",
            "epoch 19 step 39 loss 1.5407713651657104\n",
            "epoch 19 step 40 loss 1.5310091972351074 test_accuracy 72.0 train_accuracy 96.875\n",
            "epoch 19 step 41 loss 1.495569109916687\n",
            "epoch 19 step 42 loss 1.5053423643112183\n",
            "epoch 19 step 43 loss 1.532785177230835\n",
            "epoch 19 step 44 loss 1.4960265159606934\n",
            "epoch 19 step 45 loss 1.5120769739151\n",
            "epoch 19 step 46 loss 1.532636046409607\n",
            "epoch 19 step 47 loss 1.5331283807754517\n",
            "epoch 19 step 48 loss 1.4973275661468506\n",
            "epoch 19 step 49 loss 1.5771948099136353\n",
            "epoch 19 step 50 loss 1.5512205362319946\n",
            "epoch 19 step 51 loss 1.5471606254577637\n",
            "epoch 19 step 52 loss 1.5373395681381226\n",
            "epoch 19 step 53 loss 1.5161538124084473\n",
            "epoch 19 step 54 loss 1.5180314779281616\n",
            "epoch 19 step 55 loss 1.487221360206604\n",
            "epoch 19 step 56 loss 1.5413553714752197\n",
            "epoch 19 step 57 loss 1.5015817880630493\n",
            "epoch 19 step 58 loss 1.5575942993164062\n",
            "epoch 19 step 59 loss 1.5063056945800781\n",
            "epoch 19 step 60 loss 1.4830925464630127 test_accuracy 72.20000457763672 train_accuracy 97.65625\n",
            "epoch 19 step 61 loss 1.506406545639038\n",
            "epoch 19 step 62 loss 1.5206762552261353\n",
            "epoch 19 step 63 loss 1.5281118154525757\n",
            "epoch 19 step 64 loss 1.493999719619751\n",
            "epoch 19 step 65 loss 1.507873773574829\n",
            "epoch 19 step 66 loss 1.5024768114089966\n",
            "epoch 19 step 67 loss 1.4959396123886108\n",
            "epoch 19 step 68 loss 1.50454843044281\n",
            "epoch 19 step 69 loss 1.4882827997207642\n",
            "epoch 19 step 70 loss 1.5140577554702759\n",
            "epoch 19 step 71 loss 1.5262399911880493\n",
            "epoch 19 step 72 loss 1.5148361921310425\n",
            "epoch 19 step 73 loss 1.5211433172225952\n",
            "epoch 19 step 74 loss 1.5029358863830566\n",
            "epoch 19 step 75 loss 1.524671196937561\n",
            "epoch 19 step 76 loss 1.523564338684082\n",
            "epoch 19 step 77 loss 1.4962009191513062\n",
            "epoch 19 step 78 loss 1.5234659910202026\n",
            "epoch 19 step 79 loss 1.5077590942382812\n",
            "epoch 19 step 80 loss 1.5042740106582642 test_accuracy 72.20000457763672 train_accuracy 96.09375\n",
            "epoch 19 step 81 loss 1.4988933801651\n",
            "epoch 19 step 82 loss 1.492531180381775\n",
            "epoch 19 step 83 loss 1.5157091617584229\n",
            "epoch 19 step 84 loss 1.5113734006881714\n",
            "epoch 19 step 85 loss 1.4994745254516602\n",
            "epoch 19 step 86 loss 1.5179375410079956\n",
            "epoch 19 step 87 loss 1.5345169305801392\n",
            "epoch 19 step 88 loss 1.512956976890564\n",
            "epoch 19 step 89 loss 1.5279868841171265\n",
            "epoch 19 step 90 loss 1.5239554643630981\n",
            "epoch 19 step 91 loss 1.551093339920044\n",
            "epoch 19 step 92 loss 1.508991003036499\n",
            "epoch 19 step 93 loss 1.5299235582351685\n",
            "epoch 19 step 94 loss 1.4860637187957764\n",
            "epoch 19 step 95 loss 1.5001906156539917\n",
            "epoch 19 step 96 loss 1.5008432865142822\n",
            "epoch 19 step 97 loss 1.5314278602600098\n",
            "epoch 19 step 98 loss 1.529537558555603\n",
            "epoch 19 step 99 loss 1.520951509475708\n",
            "epoch 19 step 100 loss 1.518836259841919 test_accuracy 71.80000305175781 train_accuracy 93.75\n",
            "epoch 19 step 101 loss 1.482709288597107\n",
            "epoch 19 step 102 loss 1.5214165449142456\n",
            "epoch 19 step 103 loss 1.559431552886963\n",
            "epoch 19 step 104 loss 1.513579249382019\n",
            "epoch 19 step 105 loss 1.5061511993408203\n",
            "epoch 19 step 106 loss 1.511041283607483\n",
            "epoch 19 step 107 loss 1.5451306104660034\n",
            "epoch 19 step 108 loss 1.5218615531921387\n",
            "epoch 19 step 109 loss 1.5320042371749878\n",
            "epoch 19 step 110 loss 1.4886366128921509\n",
            "epoch 19 step 111 loss 1.4964855909347534\n",
            "epoch 19 step 112 loss 1.5194321870803833\n",
            "epoch 19 step 113 loss 1.5177257061004639\n",
            "epoch 19 step 114 loss 1.5370936393737793\n",
            "epoch 19 step 115 loss 1.5447667837142944\n",
            "epoch 19 step 116 loss 1.4993470907211304\n",
            "epoch 19 step 117 loss 1.541103720664978\n",
            "epoch 19 step 118 loss 1.504038691520691\n",
            "epoch 19 step 119 loss 1.5397590398788452\n",
            "epoch 19 step 120 loss 1.5226162672042847 test_accuracy 72.4000015258789 train_accuracy 96.875\n",
            "epoch 19 step 121 loss 1.5211505889892578\n",
            "epoch 19 step 122 loss 1.5007319450378418\n",
            "epoch 19 step 123 loss 1.516251802444458\n",
            "epoch 19 step 124 loss 1.5146934986114502\n",
            "epoch 19 step 125 loss 1.515046238899231\n",
            "epoch 19 step 126 loss 1.5372264385223389\n",
            "epoch 19 step 127 loss 1.5230393409729004\n",
            "epoch 19 step 128 loss 1.5060850381851196\n",
            "epoch 19 step 129 loss 1.5175267457962036\n",
            "epoch 19 step 130 loss 1.4997586011886597\n",
            "epoch 19 step 131 loss 1.5130724906921387\n",
            "epoch 19 step 132 loss 1.5138182640075684\n",
            "epoch 19 step 133 loss 1.5196022987365723\n",
            "epoch 19 step 134 loss 1.531693935394287\n",
            "epoch 19 step 135 loss 1.5410857200622559\n",
            "epoch 19 step 136 loss 1.5429257154464722\n",
            "epoch 19 step 137 loss 1.5228596925735474\n",
            "epoch 19 step 138 loss 1.5178157091140747\n",
            "epoch 19 step 139 loss 1.4946991205215454\n",
            "epoch 19 step 140 loss 1.5224944353103638 test_accuracy 72.60000610351562 train_accuracy 96.09375\n",
            "epoch 19 step 141 loss 1.4981812238693237\n",
            "epoch 19 step 142 loss 1.5037842988967896\n",
            "epoch 19 step 143 loss 1.5251476764678955\n",
            "epoch 19 step 144 loss 1.505028247833252\n",
            "epoch 19 step 145 loss 1.5016050338745117\n",
            "epoch 19 step 146 loss 1.5215942859649658\n",
            "epoch 19 step 147 loss 1.5181533098220825\n",
            "epoch 19 step 148 loss 1.5065784454345703\n",
            "epoch 19 step 149 loss 1.560779333114624\n",
            "epoch 19 step 150 loss 1.5156395435333252\n",
            "epoch 19 step 151 loss 1.5162101984024048\n",
            "epoch 19 step 152 loss 1.5037271976470947\n",
            "epoch 19 step 153 loss 1.5088917016983032\n",
            "epoch 19 step 154 loss 1.5058717727661133\n",
            "epoch 19 step 155 loss 1.5061613321304321\n",
            "epoch 19 step 156 loss 1.556154489517212\n",
            "epoch 19 step 157 loss 1.514922857284546\n",
            "epoch 19 step 158 loss 1.5393915176391602\n",
            "epoch 19 step 159 loss 1.5279778242111206\n",
            "epoch 19 step 160 loss 1.5248390436172485 test_accuracy 73.0 train_accuracy 93.75\n",
            "epoch 19 step 161 loss 1.528873085975647\n",
            "epoch 19 step 162 loss 1.5368874073028564\n",
            "epoch 19 step 163 loss 1.5399844646453857\n",
            "epoch 19 step 164 loss 1.5176793336868286\n",
            "epoch 19 step 165 loss 1.5233488082885742\n",
            "epoch 19 step 166 loss 1.5002633333206177\n",
            "epoch 19 step 167 loss 1.5197629928588867\n",
            "epoch 19 step 168 loss 1.503183364868164\n",
            "epoch 19 step 169 loss 1.5405302047729492\n",
            "epoch 19 step 170 loss 1.5230985879898071\n",
            "epoch 19 step 171 loss 1.531466007232666\n",
            "epoch 19 step 172 loss 1.5128008127212524\n",
            "epoch 19 step 173 loss 1.497914433479309\n",
            "epoch 19 step 174 loss 1.5269032716751099\n",
            "epoch 19 step 175 loss 1.5026144981384277\n",
            "epoch 19 step 176 loss 1.5189011096954346\n",
            "epoch 19 step 177 loss 1.513948917388916\n",
            "epoch 19 step 178 loss 1.5111584663391113\n",
            "epoch 19 step 179 loss 1.555997371673584\n",
            "epoch 19 step 180 loss 1.5365607738494873 test_accuracy 72.80000305175781 train_accuracy 95.3125\n",
            "epoch 19 step 181 loss 1.5181864500045776\n",
            "epoch 19 step 182 loss 1.5414563417434692\n",
            "epoch 19 step 183 loss 1.509365200996399\n",
            "epoch 19 step 184 loss 1.5095351934432983\n",
            "epoch 19 step 185 loss 1.5147674083709717\n",
            "epoch 20 step 0 loss 1.5180691480636597 test_accuracy 72.20000457763672 train_accuracy 95.3125\n",
            "epoch 20 step 1 loss 1.5009779930114746\n",
            "epoch 20 step 2 loss 1.5250016450881958\n",
            "epoch 20 step 3 loss 1.5346426963806152\n",
            "epoch 20 step 4 loss 1.4724712371826172\n",
            "epoch 20 step 5 loss 1.5101557970046997\n",
            "epoch 20 step 6 loss 1.5130752325057983\n",
            "epoch 20 step 7 loss 1.5667182207107544\n",
            "epoch 20 step 8 loss 1.5317208766937256\n",
            "epoch 20 step 9 loss 1.5478729009628296\n",
            "epoch 20 step 10 loss 1.5076826810836792\n",
            "epoch 20 step 11 loss 1.5086323022842407\n",
            "epoch 20 step 12 loss 1.4925261735916138\n",
            "epoch 20 step 13 loss 1.5078672170639038\n",
            "epoch 20 step 14 loss 1.4916337728500366\n",
            "epoch 20 step 15 loss 1.4979184865951538\n",
            "epoch 20 step 16 loss 1.5053017139434814\n",
            "epoch 20 step 17 loss 1.5257537364959717\n",
            "epoch 20 step 18 loss 1.5051120519638062\n",
            "epoch 20 step 19 loss 1.5044738054275513\n",
            "epoch 20 step 20 loss 1.530500888824463 test_accuracy 72.0 train_accuracy 96.09375\n",
            "epoch 20 step 21 loss 1.5276778936386108\n",
            "epoch 20 step 22 loss 1.5539780855178833\n",
            "epoch 20 step 23 loss 1.537644624710083\n",
            "epoch 20 step 24 loss 1.5001522302627563\n",
            "epoch 20 step 25 loss 1.4826914072036743\n",
            "epoch 20 step 26 loss 1.5169545412063599\n",
            "epoch 20 step 27 loss 1.5209707021713257\n",
            "epoch 20 step 28 loss 1.5268585681915283\n",
            "epoch 20 step 29 loss 1.5283102989196777\n",
            "epoch 20 step 30 loss 1.5195847749710083\n",
            "epoch 20 step 31 loss 1.5141493082046509\n",
            "epoch 20 step 32 loss 1.5003352165222168\n",
            "epoch 20 step 33 loss 1.498216152191162\n",
            "epoch 20 step 34 loss 1.5057908296585083\n",
            "epoch 20 step 35 loss 1.52743661403656\n",
            "epoch 20 step 36 loss 1.498111367225647\n",
            "epoch 20 step 37 loss 1.5182974338531494\n",
            "epoch 20 step 38 loss 1.5222262144088745\n",
            "epoch 20 step 39 loss 1.5438016653060913\n",
            "epoch 20 step 40 loss 1.5338438749313354 test_accuracy 72.4000015258789 train_accuracy 92.96875\n",
            "epoch 20 step 41 loss 1.5210576057434082\n",
            "epoch 20 step 42 loss 1.5270997285842896\n",
            "epoch 20 step 43 loss 1.524147391319275\n",
            "epoch 20 step 44 loss 1.5339128971099854\n",
            "epoch 20 step 45 loss 1.525596261024475\n",
            "epoch 20 step 46 loss 1.5119770765304565\n",
            "epoch 20 step 47 loss 1.5223647356033325\n",
            "epoch 20 step 48 loss 1.5232415199279785\n",
            "epoch 20 step 49 loss 1.5181427001953125\n",
            "epoch 20 step 50 loss 1.5168375968933105\n",
            "epoch 20 step 51 loss 1.5403499603271484\n",
            "epoch 20 step 52 loss 1.5170830488204956\n",
            "epoch 20 step 53 loss 1.517229676246643\n",
            "epoch 20 step 54 loss 1.541725993156433\n",
            "epoch 20 step 55 loss 1.5107017755508423\n",
            "epoch 20 step 56 loss 1.5107128620147705\n",
            "epoch 20 step 57 loss 1.5391554832458496\n",
            "epoch 20 step 58 loss 1.5046032667160034\n",
            "epoch 20 step 59 loss 1.509845495223999\n",
            "epoch 20 step 60 loss 1.5010992288589478 test_accuracy 71.80000305175781 train_accuracy 94.53125\n",
            "epoch 20 step 61 loss 1.4994823932647705\n",
            "epoch 20 step 62 loss 1.5312414169311523\n",
            "epoch 20 step 63 loss 1.4938924312591553\n",
            "epoch 20 step 64 loss 1.5588322877883911\n",
            "epoch 20 step 65 loss 1.5366848707199097\n",
            "epoch 20 step 66 loss 1.5186024904251099\n",
            "epoch 20 step 67 loss 1.5121197700500488\n",
            "epoch 20 step 68 loss 1.5281484127044678\n",
            "epoch 20 step 69 loss 1.4866125583648682\n",
            "epoch 20 step 70 loss 1.4984692335128784\n",
            "epoch 20 step 71 loss 1.5460501909255981\n",
            "epoch 20 step 72 loss 1.5041922330856323\n",
            "epoch 20 step 73 loss 1.5216584205627441\n",
            "epoch 20 step 74 loss 1.5217230319976807\n",
            "epoch 20 step 75 loss 1.4936809539794922\n",
            "epoch 20 step 76 loss 1.5375266075134277\n",
            "epoch 20 step 77 loss 1.4889888763427734\n",
            "epoch 20 step 78 loss 1.5391790866851807\n",
            "epoch 20 step 79 loss 1.5277880430221558\n",
            "epoch 20 step 80 loss 1.4819368124008179 test_accuracy 72.4000015258789 train_accuracy 93.75\n",
            "epoch 20 step 81 loss 1.5180431604385376\n",
            "epoch 20 step 82 loss 1.5200581550598145\n",
            "epoch 20 step 83 loss 1.5152735710144043\n",
            "epoch 20 step 84 loss 1.5224905014038086\n",
            "epoch 20 step 85 loss 1.5074667930603027\n",
            "epoch 20 step 86 loss 1.5082603693008423\n",
            "epoch 20 step 87 loss 1.4951330423355103\n",
            "epoch 20 step 88 loss 1.5199493169784546\n",
            "epoch 20 step 89 loss 1.496172308921814\n",
            "epoch 20 step 90 loss 1.5546671152114868\n",
            "epoch 20 step 91 loss 1.5022941827774048\n",
            "epoch 20 step 92 loss 1.4882915019989014\n",
            "epoch 20 step 93 loss 1.5262439250946045\n",
            "epoch 20 step 94 loss 1.501479983329773\n",
            "epoch 20 step 95 loss 1.4976961612701416\n",
            "epoch 20 step 96 loss 1.5149368047714233\n",
            "epoch 20 step 97 loss 1.5268417596817017\n",
            "epoch 20 step 98 loss 1.5204359292984009\n",
            "epoch 20 step 99 loss 1.5113084316253662\n",
            "epoch 20 step 100 loss 1.5252811908721924 test_accuracy 72.0 train_accuracy 96.875\n",
            "epoch 20 step 101 loss 1.5177748203277588\n",
            "epoch 20 step 102 loss 1.5114918947219849\n",
            "epoch 20 step 103 loss 1.5057644844055176\n",
            "epoch 20 step 104 loss 1.4925203323364258\n",
            "epoch 20 step 105 loss 1.5501190423965454\n",
            "epoch 20 step 106 loss 1.4955003261566162\n",
            "epoch 20 step 107 loss 1.5021387338638306\n",
            "epoch 20 step 108 loss 1.5309829711914062\n",
            "epoch 20 step 109 loss 1.512718677520752\n",
            "epoch 20 step 110 loss 1.5364162921905518\n",
            "epoch 20 step 111 loss 1.4967199563980103\n",
            "epoch 20 step 112 loss 1.4913347959518433\n",
            "epoch 20 step 113 loss 1.511444091796875\n",
            "epoch 20 step 114 loss 1.5095347166061401\n",
            "epoch 20 step 115 loss 1.540514588356018\n",
            "epoch 20 step 116 loss 1.5135126113891602\n",
            "epoch 20 step 117 loss 1.5037192106246948\n",
            "epoch 20 step 118 loss 1.508885383605957\n",
            "epoch 20 step 119 loss 1.4985712766647339\n",
            "epoch 20 step 120 loss 1.511728286743164 test_accuracy 72.20000457763672 train_accuracy 93.75\n",
            "epoch 20 step 121 loss 1.5477075576782227\n",
            "epoch 20 step 122 loss 1.5342411994934082\n",
            "epoch 20 step 123 loss 1.4896481037139893\n",
            "epoch 20 step 124 loss 1.5245213508605957\n",
            "epoch 20 step 125 loss 1.5141948461532593\n",
            "epoch 20 step 126 loss 1.5226236581802368\n",
            "epoch 20 step 127 loss 1.5373246669769287\n",
            "epoch 20 step 128 loss 1.5242139101028442\n",
            "epoch 20 step 129 loss 1.5351191759109497\n",
            "epoch 20 step 130 loss 1.5303524732589722\n",
            "epoch 20 step 131 loss 1.5066351890563965\n",
            "epoch 20 step 132 loss 1.5216139554977417\n",
            "epoch 20 step 133 loss 1.4884629249572754\n",
            "epoch 20 step 134 loss 1.5241796970367432\n",
            "epoch 20 step 135 loss 1.509798288345337\n",
            "epoch 20 step 136 loss 1.5166056156158447\n",
            "epoch 20 step 137 loss 1.4919848442077637\n",
            "epoch 20 step 138 loss 1.5162348747253418\n",
            "epoch 20 step 139 loss 1.4887146949768066\n",
            "epoch 20 step 140 loss 1.5187879800796509 test_accuracy 71.4000015258789 train_accuracy 96.875\n",
            "epoch 20 step 141 loss 1.5041872262954712\n",
            "epoch 20 step 142 loss 1.51792311668396\n",
            "epoch 20 step 143 loss 1.5086356401443481\n",
            "epoch 20 step 144 loss 1.538756251335144\n",
            "epoch 20 step 145 loss 1.4928382635116577\n",
            "epoch 20 step 146 loss 1.5423895120620728\n",
            "epoch 20 step 147 loss 1.5334795713424683\n",
            "epoch 20 step 148 loss 1.4980745315551758\n",
            "epoch 20 step 149 loss 1.4993996620178223\n",
            "epoch 20 step 150 loss 1.5558589696884155\n",
            "epoch 20 step 151 loss 1.50362229347229\n",
            "epoch 20 step 152 loss 1.5041372776031494\n",
            "epoch 20 step 153 loss 1.4917489290237427\n",
            "epoch 20 step 154 loss 1.5117777585983276\n",
            "epoch 20 step 155 loss 1.5204881429672241\n",
            "epoch 20 step 156 loss 1.5297274589538574\n",
            "epoch 20 step 157 loss 1.5039020776748657\n",
            "epoch 20 step 158 loss 1.5368010997772217\n",
            "epoch 20 step 159 loss 1.4978435039520264\n",
            "epoch 20 step 160 loss 1.5335761308670044 test_accuracy 73.0 train_accuracy 94.53125\n",
            "epoch 20 step 161 loss 1.5154318809509277\n",
            "epoch 20 step 162 loss 1.5159924030303955\n",
            "epoch 20 step 163 loss 1.517248272895813\n",
            "epoch 20 step 164 loss 1.5536143779754639\n",
            "epoch 20 step 165 loss 1.520005702972412\n",
            "epoch 20 step 166 loss 1.531896710395813\n",
            "epoch 20 step 167 loss 1.4970513582229614\n",
            "epoch 20 step 168 loss 1.515863299369812\n",
            "epoch 20 step 169 loss 1.5474516153335571\n",
            "epoch 20 step 170 loss 1.496465802192688\n",
            "epoch 20 step 171 loss 1.5293461084365845\n",
            "epoch 20 step 172 loss 1.5245256423950195\n",
            "epoch 20 step 173 loss 1.503720998764038\n",
            "epoch 20 step 174 loss 1.5175286531448364\n",
            "epoch 20 step 175 loss 1.4925751686096191\n",
            "epoch 20 step 176 loss 1.5771089792251587\n",
            "epoch 20 step 177 loss 1.4997295141220093\n",
            "epoch 20 step 178 loss 1.516823649406433\n",
            "epoch 20 step 179 loss 1.5076978206634521\n",
            "epoch 20 step 180 loss 1.5126025676727295 test_accuracy 72.20000457763672 train_accuracy 95.3125\n",
            "epoch 20 step 181 loss 1.4969496726989746\n",
            "epoch 20 step 182 loss 1.5139249563217163\n",
            "epoch 20 step 183 loss 1.5210940837860107\n",
            "epoch 20 step 184 loss 1.5103873014450073\n",
            "epoch 20 step 185 loss 1.4982943534851074\n",
            "epoch 21 step 0 loss 1.5434751510620117 test_accuracy 72.60000610351562 train_accuracy 95.3125\n",
            "epoch 21 step 1 loss 1.5218467712402344\n",
            "epoch 21 step 2 loss 1.4922775030136108\n",
            "epoch 21 step 3 loss 1.5246778726577759\n",
            "epoch 21 step 4 loss 1.5130703449249268\n",
            "epoch 21 step 5 loss 1.5041476488113403\n",
            "epoch 21 step 6 loss 1.5137569904327393\n",
            "epoch 21 step 7 loss 1.5229425430297852\n",
            "epoch 21 step 8 loss 1.4842746257781982\n",
            "epoch 21 step 9 loss 1.496256709098816\n",
            "epoch 21 step 10 loss 1.5234055519104004\n",
            "epoch 21 step 11 loss 1.503329873085022\n",
            "epoch 21 step 12 loss 1.5393673181533813\n",
            "epoch 21 step 13 loss 1.5176899433135986\n",
            "epoch 21 step 14 loss 1.5153770446777344\n",
            "epoch 21 step 15 loss 1.5116373300552368\n",
            "epoch 21 step 16 loss 1.5166329145431519\n",
            "epoch 21 step 17 loss 1.5001085996627808\n",
            "epoch 21 step 18 loss 1.5011448860168457\n",
            "epoch 21 step 19 loss 1.5021508932113647\n",
            "epoch 21 step 20 loss 1.5422312021255493 test_accuracy 72.60000610351562 train_accuracy 96.09375\n",
            "epoch 21 step 21 loss 1.5289688110351562\n",
            "epoch 21 step 22 loss 1.5496153831481934\n",
            "epoch 21 step 23 loss 1.5203039646148682\n",
            "epoch 21 step 24 loss 1.5193603038787842\n",
            "epoch 21 step 25 loss 1.550539493560791\n",
            "epoch 21 step 26 loss 1.5396134853363037\n",
            "epoch 21 step 27 loss 1.495602011680603\n",
            "epoch 21 step 28 loss 1.4809149503707886\n",
            "epoch 21 step 29 loss 1.4957879781723022\n",
            "epoch 21 step 30 loss 1.5203453302383423\n",
            "epoch 21 step 31 loss 1.5512216091156006\n",
            "epoch 21 step 32 loss 1.496537446975708\n",
            "epoch 21 step 33 loss 1.5467902421951294\n",
            "epoch 21 step 34 loss 1.521531105041504\n",
            "epoch 21 step 35 loss 1.5015783309936523\n",
            "epoch 21 step 36 loss 1.489874005317688\n",
            "epoch 21 step 37 loss 1.5068769454956055\n",
            "epoch 21 step 38 loss 1.518413782119751\n",
            "epoch 21 step 39 loss 1.5406416654586792\n",
            "epoch 21 step 40 loss 1.5335227251052856 test_accuracy 73.4000015258789 train_accuracy 92.1875\n",
            "epoch 21 step 41 loss 1.5249724388122559\n",
            "epoch 21 step 42 loss 1.5100327730178833\n",
            "epoch 21 step 43 loss 1.4989093542099\n",
            "epoch 21 step 44 loss 1.5153242349624634\n",
            "epoch 21 step 45 loss 1.503625512123108\n",
            "epoch 21 step 46 loss 1.496536135673523\n",
            "epoch 21 step 47 loss 1.4988723993301392\n",
            "epoch 21 step 48 loss 1.510797142982483\n",
            "epoch 21 step 49 loss 1.510594129562378\n",
            "epoch 21 step 50 loss 1.482979416847229\n",
            "epoch 21 step 51 loss 1.523415446281433\n",
            "epoch 21 step 52 loss 1.5098516941070557\n",
            "epoch 21 step 53 loss 1.4997459650039673\n",
            "epoch 21 step 54 loss 1.533989429473877\n",
            "epoch 21 step 55 loss 1.5288701057434082\n",
            "epoch 21 step 56 loss 1.4814066886901855\n",
            "epoch 21 step 57 loss 1.5129932165145874\n",
            "epoch 21 step 58 loss 1.4892522096633911\n",
            "epoch 21 step 59 loss 1.524085521697998\n",
            "epoch 21 step 60 loss 1.511163592338562 test_accuracy 72.80000305175781 train_accuracy 96.875\n",
            "epoch 21 step 61 loss 1.5052523612976074\n",
            "epoch 21 step 62 loss 1.5364590883255005\n",
            "epoch 21 step 63 loss 1.526463508605957\n",
            "epoch 21 step 64 loss 1.4904751777648926\n",
            "epoch 21 step 65 loss 1.5230720043182373\n",
            "epoch 21 step 66 loss 1.5291615724563599\n",
            "epoch 21 step 67 loss 1.5072169303894043\n",
            "epoch 21 step 68 loss 1.5171903371810913\n",
            "epoch 21 step 69 loss 1.5177057981491089\n",
            "epoch 21 step 70 loss 1.5244227647781372\n",
            "epoch 21 step 71 loss 1.5162713527679443\n",
            "epoch 21 step 72 loss 1.512134313583374\n",
            "epoch 21 step 73 loss 1.5099049806594849\n",
            "epoch 21 step 74 loss 1.4846775531768799\n",
            "epoch 21 step 75 loss 1.5403062105178833\n",
            "epoch 21 step 76 loss 1.5135825872421265\n",
            "epoch 21 step 77 loss 1.5441051721572876\n",
            "epoch 21 step 78 loss 1.5040855407714844\n",
            "epoch 21 step 79 loss 1.4950567483901978\n",
            "epoch 21 step 80 loss 1.503899097442627 test_accuracy 72.60000610351562 train_accuracy 97.65625\n",
            "epoch 21 step 81 loss 1.5559684038162231\n",
            "epoch 21 step 82 loss 1.5013232231140137\n",
            "epoch 21 step 83 loss 1.5174586772918701\n",
            "epoch 21 step 84 loss 1.4981099367141724\n",
            "epoch 21 step 85 loss 1.5512850284576416\n",
            "epoch 21 step 86 loss 1.5479052066802979\n",
            "epoch 21 step 87 loss 1.5019187927246094\n",
            "epoch 21 step 88 loss 1.4917558431625366\n",
            "epoch 21 step 89 loss 1.5042728185653687\n",
            "epoch 21 step 90 loss 1.5463907718658447\n",
            "epoch 21 step 91 loss 1.499216079711914\n",
            "epoch 21 step 92 loss 1.5253914594650269\n",
            "epoch 21 step 93 loss 1.5152279138565063\n",
            "epoch 21 step 94 loss 1.5045007467269897\n",
            "epoch 21 step 95 loss 1.5169607400894165\n",
            "epoch 21 step 96 loss 1.5039522647857666\n",
            "epoch 21 step 97 loss 1.5105198621749878\n",
            "epoch 21 step 98 loss 1.5099984407424927\n",
            "epoch 21 step 99 loss 1.5126533508300781\n",
            "epoch 21 step 100 loss 1.5260367393493652 test_accuracy 72.80000305175781 train_accuracy 96.09375\n",
            "epoch 21 step 101 loss 1.5405551195144653\n",
            "epoch 21 step 102 loss 1.522447109222412\n",
            "epoch 21 step 103 loss 1.5352939367294312\n",
            "epoch 21 step 104 loss 1.4996377229690552\n",
            "epoch 21 step 105 loss 1.489323377609253\n",
            "epoch 21 step 106 loss 1.5645256042480469\n",
            "epoch 21 step 107 loss 1.5075620412826538\n",
            "epoch 21 step 108 loss 1.5002151727676392\n",
            "epoch 21 step 109 loss 1.5119951963424683\n",
            "epoch 21 step 110 loss 1.5099072456359863\n",
            "epoch 21 step 111 loss 1.5103611946105957\n",
            "epoch 21 step 112 loss 1.4766348600387573\n",
            "epoch 21 step 113 loss 1.4943821430206299\n",
            "epoch 21 step 114 loss 1.4963771104812622\n",
            "epoch 21 step 115 loss 1.5107322931289673\n",
            "epoch 21 step 116 loss 1.5033800601959229\n",
            "epoch 21 step 117 loss 1.5290122032165527\n",
            "epoch 21 step 118 loss 1.4879748821258545\n",
            "epoch 21 step 119 loss 1.50358247756958\n",
            "epoch 21 step 120 loss 1.5159403085708618 test_accuracy 72.60000610351562 train_accuracy 94.53125\n",
            "epoch 21 step 121 loss 1.5024726390838623\n",
            "epoch 21 step 122 loss 1.4909130334854126\n",
            "epoch 21 step 123 loss 1.5633243322372437\n",
            "epoch 21 step 124 loss 1.5198405981063843\n",
            "epoch 21 step 125 loss 1.5359443426132202\n",
            "epoch 21 step 126 loss 1.4988231658935547\n",
            "epoch 21 step 127 loss 1.5156282186508179\n",
            "epoch 21 step 128 loss 1.5223982334136963\n",
            "epoch 21 step 129 loss 1.5154954195022583\n",
            "epoch 21 step 130 loss 1.5127356052398682\n",
            "epoch 21 step 131 loss 1.5024399757385254\n",
            "epoch 21 step 132 loss 1.5421334505081177\n",
            "epoch 21 step 133 loss 1.5145132541656494\n",
            "epoch 21 step 134 loss 1.5172420740127563\n",
            "epoch 21 step 135 loss 1.4906928539276123\n",
            "epoch 21 step 136 loss 1.5136138200759888\n",
            "epoch 21 step 137 loss 1.5344027280807495\n",
            "epoch 21 step 138 loss 1.5237841606140137\n",
            "epoch 21 step 139 loss 1.5212924480438232\n",
            "epoch 21 step 140 loss 1.5121906995773315 test_accuracy 72.0 train_accuracy 95.3125\n",
            "epoch 21 step 141 loss 1.5084431171417236\n",
            "epoch 21 step 142 loss 1.5095326900482178\n",
            "epoch 21 step 143 loss 1.5215421915054321\n",
            "epoch 21 step 144 loss 1.506600260734558\n",
            "epoch 21 step 145 loss 1.4900256395339966\n",
            "epoch 21 step 146 loss 1.5249147415161133\n",
            "epoch 21 step 147 loss 1.529992938041687\n",
            "epoch 21 step 148 loss 1.5094414949417114\n",
            "epoch 21 step 149 loss 1.513385534286499\n",
            "epoch 21 step 150 loss 1.5369229316711426\n",
            "epoch 21 step 151 loss 1.5259504318237305\n",
            "epoch 21 step 152 loss 1.5100351572036743\n",
            "epoch 21 step 153 loss 1.4938948154449463\n",
            "epoch 21 step 154 loss 1.5284934043884277\n",
            "epoch 21 step 155 loss 1.531343936920166\n",
            "epoch 21 step 156 loss 1.520127296447754\n",
            "epoch 21 step 157 loss 1.525207281112671\n",
            "epoch 21 step 158 loss 1.50636625289917\n",
            "epoch 21 step 159 loss 1.5138828754425049\n",
            "epoch 21 step 160 loss 1.527855634689331 test_accuracy 72.4000015258789 train_accuracy 94.53125\n",
            "epoch 21 step 161 loss 1.517625093460083\n",
            "epoch 21 step 162 loss 1.5181536674499512\n",
            "epoch 21 step 163 loss 1.5102616548538208\n",
            "epoch 21 step 164 loss 1.5460785627365112\n",
            "epoch 21 step 165 loss 1.4948511123657227\n",
            "epoch 21 step 166 loss 1.503067970275879\n",
            "epoch 21 step 167 loss 1.5062270164489746\n",
            "epoch 21 step 168 loss 1.528633952140808\n",
            "epoch 21 step 169 loss 1.5116080045700073\n",
            "epoch 21 step 170 loss 1.4992320537567139\n",
            "epoch 21 step 171 loss 1.5398961305618286\n",
            "epoch 21 step 172 loss 1.56538987159729\n",
            "epoch 21 step 173 loss 1.5152205228805542\n",
            "epoch 21 step 174 loss 1.5176244974136353\n",
            "epoch 21 step 175 loss 1.531285047531128\n",
            "epoch 21 step 176 loss 1.4999592304229736\n",
            "epoch 21 step 177 loss 1.5161091089248657\n",
            "epoch 21 step 178 loss 1.5200772285461426\n",
            "epoch 21 step 179 loss 1.5177315473556519\n",
            "epoch 21 step 180 loss 1.5074617862701416 test_accuracy 72.60000610351562 train_accuracy 96.875\n",
            "epoch 21 step 181 loss 1.5081162452697754\n",
            "epoch 21 step 182 loss 1.5118894577026367\n",
            "epoch 21 step 183 loss 1.5455613136291504\n",
            "epoch 21 step 184 loss 1.5133745670318604\n",
            "epoch 21 step 185 loss 1.55890691280365\n",
            "epoch 22 step 0 loss 1.5019837617874146 test_accuracy 72.4000015258789 train_accuracy 93.75\n",
            "epoch 22 step 1 loss 1.504827618598938\n",
            "epoch 22 step 2 loss 1.5062997341156006\n",
            "epoch 22 step 3 loss 1.4943612813949585\n",
            "epoch 22 step 4 loss 1.5101174116134644\n",
            "epoch 22 step 5 loss 1.5214561223983765\n",
            "epoch 22 step 6 loss 1.5136395692825317\n",
            "epoch 22 step 7 loss 1.5053260326385498\n",
            "epoch 22 step 8 loss 1.5299663543701172\n",
            "epoch 22 step 9 loss 1.5059641599655151\n",
            "epoch 22 step 10 loss 1.5369089841842651\n",
            "epoch 22 step 11 loss 1.5205577611923218\n",
            "epoch 22 step 12 loss 1.5208479166030884\n",
            "epoch 22 step 13 loss 1.4861924648284912\n",
            "epoch 22 step 14 loss 1.5293835401535034\n",
            "epoch 22 step 15 loss 1.4998785257339478\n",
            "epoch 22 step 16 loss 1.4978924989700317\n",
            "epoch 22 step 17 loss 1.5073224306106567\n",
            "epoch 22 step 18 loss 1.5063273906707764\n",
            "epoch 22 step 19 loss 1.547742247581482\n",
            "epoch 22 step 20 loss 1.5070292949676514 test_accuracy 72.60000610351562 train_accuracy 98.4375\n",
            "epoch 22 step 21 loss 1.5035237073898315\n",
            "epoch 22 step 22 loss 1.5499275922775269\n",
            "epoch 22 step 23 loss 1.5369987487792969\n",
            "epoch 22 step 24 loss 1.5328037738800049\n",
            "epoch 22 step 25 loss 1.5073579549789429\n",
            "epoch 22 step 26 loss 1.5213028192520142\n",
            "epoch 22 step 27 loss 1.5108087062835693\n",
            "epoch 22 step 28 loss 1.4990698099136353\n",
            "epoch 22 step 29 loss 1.530586838722229\n",
            "epoch 22 step 30 loss 1.5129404067993164\n",
            "epoch 22 step 31 loss 1.5050081014633179\n",
            "epoch 22 step 32 loss 1.4959969520568848\n",
            "epoch 22 step 33 loss 1.4928207397460938\n",
            "epoch 22 step 34 loss 1.5243253707885742\n",
            "epoch 22 step 35 loss 1.5003197193145752\n",
            "epoch 22 step 36 loss 1.494271993637085\n",
            "epoch 22 step 37 loss 1.5183122158050537\n",
            "epoch 22 step 38 loss 1.51999032497406\n",
            "epoch 22 step 39 loss 1.5087730884552002\n",
            "epoch 22 step 40 loss 1.4973325729370117 test_accuracy 72.0 train_accuracy 96.875\n",
            "epoch 22 step 41 loss 1.5008111000061035\n",
            "epoch 22 step 42 loss 1.4916949272155762\n",
            "epoch 22 step 43 loss 1.5299339294433594\n",
            "epoch 22 step 44 loss 1.5032761096954346\n",
            "epoch 22 step 45 loss 1.5212106704711914\n",
            "epoch 22 step 46 loss 1.5081545114517212\n",
            "epoch 22 step 47 loss 1.5176664590835571\n",
            "epoch 22 step 48 loss 1.5122230052947998\n",
            "epoch 22 step 49 loss 1.495473861694336\n",
            "epoch 22 step 50 loss 1.525820255279541\n",
            "epoch 22 step 51 loss 1.5289539098739624\n",
            "epoch 22 step 52 loss 1.5259571075439453\n",
            "epoch 22 step 53 loss 1.5018634796142578\n",
            "epoch 22 step 54 loss 1.5062354803085327\n",
            "epoch 22 step 55 loss 1.5450809001922607\n",
            "epoch 22 step 56 loss 1.5115714073181152\n",
            "epoch 22 step 57 loss 1.502142310142517\n",
            "epoch 22 step 58 loss 1.5111477375030518\n",
            "epoch 22 step 59 loss 1.4869418144226074\n",
            "epoch 22 step 60 loss 1.5039300918579102 test_accuracy 73.20000457763672 train_accuracy 92.1875\n",
            "epoch 22 step 61 loss 1.5064921379089355\n",
            "epoch 22 step 62 loss 1.5123475790023804\n",
            "epoch 22 step 63 loss 1.5051460266113281\n",
            "epoch 22 step 64 loss 1.4970262050628662\n",
            "epoch 22 step 65 loss 1.4900267124176025\n",
            "epoch 22 step 66 loss 1.5480784177780151\n",
            "epoch 22 step 67 loss 1.5577818155288696\n",
            "epoch 22 step 68 loss 1.5386031866073608\n",
            "epoch 22 step 69 loss 1.540822982788086\n",
            "epoch 22 step 70 loss 1.534447193145752\n",
            "epoch 22 step 71 loss 1.5094566345214844\n",
            "epoch 22 step 72 loss 1.5009241104125977\n",
            "epoch 22 step 73 loss 1.5060255527496338\n",
            "epoch 22 step 74 loss 1.5254079103469849\n",
            "epoch 22 step 75 loss 1.5089409351348877\n",
            "epoch 22 step 76 loss 1.518187165260315\n",
            "epoch 22 step 77 loss 1.5305378437042236\n",
            "epoch 22 step 78 loss 1.5175597667694092\n",
            "epoch 22 step 79 loss 1.4976940155029297\n",
            "epoch 22 step 80 loss 1.514106273651123 test_accuracy 72.80000305175781 train_accuracy 92.96875\n",
            "epoch 22 step 81 loss 1.5050163269042969\n",
            "epoch 22 step 82 loss 1.5202375650405884\n",
            "epoch 22 step 83 loss 1.5013365745544434\n",
            "epoch 22 step 84 loss 1.5114521980285645\n",
            "epoch 22 step 85 loss 1.51849365234375\n",
            "epoch 22 step 86 loss 1.5137286186218262\n",
            "epoch 22 step 87 loss 1.5147786140441895\n",
            "epoch 22 step 88 loss 1.5156735181808472\n",
            "epoch 22 step 89 loss 1.5095582008361816\n",
            "epoch 22 step 90 loss 1.509790301322937\n",
            "epoch 22 step 91 loss 1.4909420013427734\n",
            "epoch 22 step 92 loss 1.5034072399139404\n",
            "epoch 22 step 93 loss 1.5236196517944336\n",
            "epoch 22 step 94 loss 1.4752326011657715\n",
            "epoch 22 step 95 loss 1.5291237831115723\n",
            "epoch 22 step 96 loss 1.5387818813323975\n",
            "epoch 22 step 97 loss 1.5120280981063843\n",
            "epoch 22 step 98 loss 1.5444375276565552\n",
            "epoch 22 step 99 loss 1.5414105653762817\n",
            "epoch 22 step 100 loss 1.515952229499817 test_accuracy 73.4000015258789 train_accuracy 96.09375\n",
            "epoch 22 step 101 loss 1.5287848711013794\n",
            "epoch 22 step 102 loss 1.4927679300308228\n",
            "epoch 22 step 103 loss 1.4928513765335083\n",
            "epoch 22 step 104 loss 1.4995627403259277\n",
            "epoch 22 step 105 loss 1.4877361059188843\n",
            "epoch 22 step 106 loss 1.507613182067871\n",
            "epoch 22 step 107 loss 1.4874132871627808\n",
            "epoch 22 step 108 loss 1.5268778800964355\n",
            "epoch 22 step 109 loss 1.5379310846328735\n",
            "epoch 22 step 110 loss 1.510453462600708\n",
            "epoch 22 step 111 loss 1.5077641010284424\n",
            "epoch 22 step 112 loss 1.5373038053512573\n",
            "epoch 22 step 113 loss 1.5310138463974\n",
            "epoch 22 step 114 loss 1.506956934928894\n",
            "epoch 22 step 115 loss 1.5179007053375244\n",
            "epoch 22 step 116 loss 1.4838299751281738\n",
            "epoch 22 step 117 loss 1.5029538869857788\n",
            "epoch 22 step 118 loss 1.5220967531204224\n",
            "epoch 22 step 119 loss 1.510479211807251\n",
            "epoch 22 step 120 loss 1.5072269439697266 test_accuracy 72.4000015258789 train_accuracy 94.53125\n",
            "epoch 22 step 121 loss 1.5541173219680786\n",
            "epoch 22 step 122 loss 1.5270816087722778\n",
            "epoch 22 step 123 loss 1.5190774202346802\n",
            "epoch 22 step 124 loss 1.5223567485809326\n",
            "epoch 22 step 125 loss 1.5179792642593384\n",
            "epoch 22 step 126 loss 1.5114717483520508\n",
            "epoch 22 step 127 loss 1.511109709739685\n",
            "epoch 22 step 128 loss 1.5138448476791382\n",
            "epoch 22 step 129 loss 1.5173048973083496\n",
            "epoch 22 step 130 loss 1.521477222442627\n",
            "epoch 22 step 131 loss 1.504166841506958\n",
            "epoch 22 step 132 loss 1.515413522720337\n",
            "epoch 22 step 133 loss 1.5100244283676147\n",
            "epoch 22 step 134 loss 1.5058879852294922\n",
            "epoch 22 step 135 loss 1.4998893737792969\n",
            "epoch 22 step 136 loss 1.5232703685760498\n",
            "epoch 22 step 137 loss 1.4957151412963867\n",
            "epoch 22 step 138 loss 1.5385961532592773\n",
            "epoch 22 step 139 loss 1.5242563486099243\n",
            "epoch 22 step 140 loss 1.5347620248794556 test_accuracy 73.20000457763672 train_accuracy 97.65625\n",
            "epoch 22 step 141 loss 1.5506036281585693\n",
            "epoch 22 step 142 loss 1.5293872356414795\n",
            "epoch 22 step 143 loss 1.5153447389602661\n",
            "epoch 22 step 144 loss 1.5190006494522095\n",
            "epoch 22 step 145 loss 1.5097546577453613\n",
            "epoch 22 step 146 loss 1.5218665599822998\n",
            "epoch 22 step 147 loss 1.4949722290039062\n",
            "epoch 22 step 148 loss 1.5214296579360962\n",
            "epoch 22 step 149 loss 1.539878487586975\n",
            "epoch 22 step 150 loss 1.5230733156204224\n",
            "epoch 22 step 151 loss 1.5359491109848022\n",
            "epoch 22 step 152 loss 1.5011459589004517\n",
            "epoch 22 step 153 loss 1.4954442977905273\n",
            "epoch 22 step 154 loss 1.5365421772003174\n",
            "epoch 22 step 155 loss 1.4952536821365356\n",
            "epoch 22 step 156 loss 1.500876784324646\n",
            "epoch 22 step 157 loss 1.482028603553772\n",
            "epoch 22 step 158 loss 1.5473994016647339\n",
            "epoch 22 step 159 loss 1.5171922445297241\n",
            "epoch 22 step 160 loss 1.5255018472671509 test_accuracy 73.4000015258789 train_accuracy 94.53125\n",
            "epoch 22 step 161 loss 1.4974907636642456\n",
            "epoch 22 step 162 loss 1.503193974494934\n",
            "epoch 22 step 163 loss 1.523694634437561\n",
            "epoch 22 step 164 loss 1.5283868312835693\n",
            "epoch 22 step 165 loss 1.513569951057434\n",
            "epoch 22 step 166 loss 1.5386146306991577\n",
            "epoch 22 step 167 loss 1.5393558740615845\n",
            "epoch 22 step 168 loss 1.5644110441207886\n",
            "epoch 22 step 169 loss 1.4958690404891968\n",
            "epoch 22 step 170 loss 1.5346907377243042\n",
            "epoch 22 step 171 loss 1.528496265411377\n",
            "epoch 22 step 172 loss 1.5416194200515747\n",
            "epoch 22 step 173 loss 1.5100103616714478\n",
            "epoch 22 step 174 loss 1.5496158599853516\n",
            "epoch 22 step 175 loss 1.502411961555481\n",
            "epoch 22 step 176 loss 1.5019521713256836\n",
            "epoch 22 step 177 loss 1.4983559846878052\n",
            "epoch 22 step 178 loss 1.486538052558899\n",
            "epoch 22 step 179 loss 1.5029512643814087\n",
            "epoch 22 step 180 loss 1.520638108253479 test_accuracy 73.60000610351562 train_accuracy 93.75\n",
            "epoch 22 step 181 loss 1.509516954421997\n",
            "epoch 22 step 182 loss 1.5511491298675537\n",
            "epoch 22 step 183 loss 1.527739405632019\n",
            "epoch 22 step 184 loss 1.5212417840957642\n",
            "epoch 22 step 185 loss 1.5288071632385254\n",
            "epoch 23 step 0 loss 1.5202041864395142 test_accuracy 73.20000457763672 train_accuracy 94.53125\n",
            "epoch 23 step 1 loss 1.5051904916763306\n",
            "epoch 23 step 2 loss 1.4958221912384033\n",
            "epoch 23 step 3 loss 1.4932022094726562\n",
            "epoch 23 step 4 loss 1.522626280784607\n",
            "epoch 23 step 5 loss 1.5437841415405273\n",
            "epoch 23 step 6 loss 1.4809354543685913\n",
            "epoch 23 step 7 loss 1.5489922761917114\n",
            "epoch 23 step 8 loss 1.4996850490570068\n",
            "epoch 23 step 9 loss 1.5136083364486694\n",
            "epoch 23 step 10 loss 1.5356510877609253\n",
            "epoch 23 step 11 loss 1.5120071172714233\n",
            "epoch 23 step 12 loss 1.4804496765136719\n",
            "epoch 23 step 13 loss 1.5548690557479858\n",
            "epoch 23 step 14 loss 1.5091129541397095\n",
            "epoch 23 step 15 loss 1.5211430788040161\n",
            "epoch 23 step 16 loss 1.500287413597107\n",
            "epoch 23 step 17 loss 1.5252019166946411\n",
            "epoch 23 step 18 loss 1.5112172365188599\n",
            "epoch 23 step 19 loss 1.5563476085662842\n",
            "epoch 23 step 20 loss 1.567600131034851 test_accuracy 72.60000610351562 train_accuracy 94.53125\n",
            "epoch 23 step 21 loss 1.5210357904434204\n",
            "epoch 23 step 22 loss 1.5092453956604004\n",
            "epoch 23 step 23 loss 1.5269358158111572\n",
            "epoch 23 step 24 loss 1.511579155921936\n",
            "epoch 23 step 25 loss 1.4873676300048828\n",
            "epoch 23 step 26 loss 1.5102801322937012\n",
            "epoch 23 step 27 loss 1.506759762763977\n",
            "epoch 23 step 28 loss 1.4966474771499634\n",
            "epoch 23 step 29 loss 1.4879108667373657\n",
            "epoch 23 step 30 loss 1.5112990140914917\n",
            "epoch 23 step 31 loss 1.4895377159118652\n",
            "epoch 23 step 32 loss 1.4886717796325684\n",
            "epoch 23 step 33 loss 1.5095868110656738\n",
            "epoch 23 step 34 loss 1.4847346544265747\n",
            "epoch 23 step 35 loss 1.5450215339660645\n",
            "epoch 23 step 36 loss 1.5140759944915771\n",
            "epoch 23 step 37 loss 1.514102816581726\n",
            "epoch 23 step 38 loss 1.4853180646896362\n",
            "epoch 23 step 39 loss 1.5116873979568481\n",
            "epoch 23 step 40 loss 1.5435856580734253 test_accuracy 73.20000457763672 train_accuracy 97.65625\n",
            "epoch 23 step 41 loss 1.5247151851654053\n",
            "epoch 23 step 42 loss 1.5110523700714111\n",
            "epoch 23 step 43 loss 1.5153414011001587\n",
            "epoch 23 step 44 loss 1.515303134918213\n",
            "epoch 23 step 45 loss 1.4937729835510254\n",
            "epoch 23 step 46 loss 1.5054011344909668\n",
            "epoch 23 step 47 loss 1.5234605073928833\n",
            "epoch 23 step 48 loss 1.4966422319412231\n",
            "epoch 23 step 49 loss 1.5067650079727173\n",
            "epoch 23 step 50 loss 1.5100709199905396\n",
            "epoch 23 step 51 loss 1.5109864473342896\n",
            "epoch 23 step 52 loss 1.4786728620529175\n",
            "epoch 23 step 53 loss 1.5251489877700806\n",
            "epoch 23 step 54 loss 1.5023852586746216\n",
            "epoch 23 step 55 loss 1.5219557285308838\n",
            "epoch 23 step 56 loss 1.5483766794204712\n",
            "epoch 23 step 57 loss 1.5190775394439697\n",
            "epoch 23 step 58 loss 1.523351788520813\n",
            "epoch 23 step 59 loss 1.4969156980514526\n",
            "epoch 23 step 60 loss 1.515657663345337 test_accuracy 72.60000610351562 train_accuracy 96.875\n",
            "epoch 23 step 61 loss 1.4878991842269897\n",
            "epoch 23 step 62 loss 1.5112957954406738\n",
            "epoch 23 step 63 loss 1.5140653848648071\n",
            "epoch 23 step 64 loss 1.5214368104934692\n",
            "epoch 23 step 65 loss 1.517090916633606\n",
            "epoch 23 step 66 loss 1.5201733112335205\n",
            "epoch 23 step 67 loss 1.4916317462921143\n",
            "epoch 23 step 68 loss 1.5272650718688965\n",
            "epoch 23 step 69 loss 1.5328747034072876\n",
            "epoch 23 step 70 loss 1.5229237079620361\n",
            "epoch 23 step 71 loss 1.4917141199111938\n",
            "epoch 23 step 72 loss 1.5084091424942017\n",
            "epoch 23 step 73 loss 1.5004401206970215\n",
            "epoch 23 step 74 loss 1.5133923292160034\n",
            "epoch 23 step 75 loss 1.488493800163269\n",
            "epoch 23 step 76 loss 1.5188387632369995\n",
            "epoch 23 step 77 loss 1.5107165575027466\n",
            "epoch 23 step 78 loss 1.5093135833740234\n",
            "epoch 23 step 79 loss 1.488032341003418\n",
            "epoch 23 step 80 loss 1.4859882593154907 test_accuracy 73.4000015258789 train_accuracy 92.1875\n",
            "epoch 23 step 81 loss 1.5212123394012451\n",
            "epoch 23 step 82 loss 1.5085351467132568\n",
            "epoch 23 step 83 loss 1.5167948007583618\n",
            "epoch 23 step 84 loss 1.515891432762146\n",
            "epoch 23 step 85 loss 1.5491046905517578\n",
            "epoch 23 step 86 loss 1.4954248666763306\n",
            "epoch 23 step 87 loss 1.5142645835876465\n",
            "epoch 23 step 88 loss 1.5007977485656738\n",
            "epoch 23 step 89 loss 1.5037833452224731\n",
            "epoch 23 step 90 loss 1.49776029586792\n",
            "epoch 23 step 91 loss 1.516194224357605\n",
            "epoch 23 step 92 loss 1.518031120300293\n",
            "epoch 23 step 93 loss 1.5093969106674194\n",
            "epoch 23 step 94 loss 1.5122568607330322\n",
            "epoch 23 step 95 loss 1.527053713798523\n",
            "epoch 23 step 96 loss 1.5197027921676636\n",
            "epoch 23 step 97 loss 1.484649419784546\n",
            "epoch 23 step 98 loss 1.5303782224655151\n",
            "epoch 23 step 99 loss 1.5708529949188232\n",
            "epoch 23 step 100 loss 1.4947257041931152 test_accuracy 73.20000457763672 train_accuracy 96.875\n",
            "epoch 23 step 101 loss 1.491803526878357\n",
            "epoch 23 step 102 loss 1.5243287086486816\n",
            "epoch 23 step 103 loss 1.499638319015503\n",
            "epoch 23 step 104 loss 1.4866756200790405\n",
            "epoch 23 step 105 loss 1.5373560190200806\n",
            "epoch 23 step 106 loss 1.533785104751587\n",
            "epoch 23 step 107 loss 1.549280047416687\n",
            "epoch 23 step 108 loss 1.5323435068130493\n",
            "epoch 23 step 109 loss 1.5018553733825684\n",
            "epoch 23 step 110 loss 1.511351227760315\n",
            "epoch 23 step 111 loss 1.5369317531585693\n",
            "epoch 23 step 112 loss 1.5625044107437134\n",
            "epoch 23 step 113 loss 1.5033190250396729\n",
            "epoch 23 step 114 loss 1.484034776687622\n",
            "epoch 23 step 115 loss 1.5220856666564941\n",
            "epoch 23 step 116 loss 1.5548990964889526\n",
            "epoch 23 step 117 loss 1.5137228965759277\n",
            "epoch 23 step 118 loss 1.4964061975479126\n",
            "epoch 23 step 119 loss 1.523479700088501\n",
            "epoch 23 step 120 loss 1.515836477279663 test_accuracy 73.4000015258789 train_accuracy 98.4375\n",
            "epoch 23 step 121 loss 1.5285060405731201\n",
            "epoch 23 step 122 loss 1.5300846099853516\n",
            "epoch 23 step 123 loss 1.5289280414581299\n",
            "epoch 23 step 124 loss 1.5034420490264893\n",
            "epoch 23 step 125 loss 1.539529800415039\n",
            "epoch 23 step 126 loss 1.5078363418579102\n",
            "epoch 23 step 127 loss 1.4957516193389893\n",
            "epoch 23 step 128 loss 1.519521713256836\n",
            "epoch 23 step 129 loss 1.533569097518921\n",
            "epoch 23 step 130 loss 1.485205888748169\n",
            "epoch 23 step 131 loss 1.5047346353530884\n",
            "epoch 23 step 132 loss 1.5261006355285645\n",
            "epoch 23 step 133 loss 1.4823520183563232\n",
            "epoch 23 step 134 loss 1.4775625467300415\n",
            "epoch 23 step 135 loss 1.5076171159744263\n",
            "epoch 23 step 136 loss 1.5358123779296875\n",
            "epoch 23 step 137 loss 1.5128499269485474\n",
            "epoch 23 step 138 loss 1.5008207559585571\n",
            "epoch 23 step 139 loss 1.5473365783691406\n",
            "epoch 23 step 140 loss 1.5299397706985474 test_accuracy 73.20000457763672 train_accuracy 96.875\n",
            "epoch 23 step 141 loss 1.5503016710281372\n",
            "epoch 23 step 142 loss 1.510501503944397\n",
            "epoch 23 step 143 loss 1.515199065208435\n",
            "epoch 23 step 144 loss 1.537815809249878\n",
            "epoch 23 step 145 loss 1.492964267730713\n",
            "epoch 23 step 146 loss 1.5356703996658325\n",
            "epoch 23 step 147 loss 1.5125652551651\n",
            "epoch 23 step 148 loss 1.5044399499893188\n",
            "epoch 23 step 149 loss 1.5511749982833862\n",
            "epoch 23 step 150 loss 1.5042119026184082\n",
            "epoch 23 step 151 loss 1.5031859874725342\n",
            "epoch 23 step 152 loss 1.528235912322998\n",
            "epoch 23 step 153 loss 1.5123461484909058\n",
            "epoch 23 step 154 loss 1.5276106595993042\n",
            "epoch 23 step 155 loss 1.5192015171051025\n",
            "epoch 23 step 156 loss 1.5557529926300049\n",
            "epoch 23 step 157 loss 1.5006041526794434\n",
            "epoch 23 step 158 loss 1.4975049495697021\n",
            "epoch 23 step 159 loss 1.507563591003418\n",
            "epoch 23 step 160 loss 1.522795557975769 test_accuracy 73.20000457763672 train_accuracy 96.875\n",
            "epoch 23 step 161 loss 1.5135585069656372\n",
            "epoch 23 step 162 loss 1.5015720129013062\n",
            "epoch 23 step 163 loss 1.4980453252792358\n",
            "epoch 23 step 164 loss 1.525180459022522\n",
            "epoch 23 step 165 loss 1.506076693534851\n",
            "epoch 23 step 166 loss 1.5392674207687378\n",
            "epoch 23 step 167 loss 1.5336114168167114\n",
            "epoch 23 step 168 loss 1.526363492012024\n",
            "epoch 23 step 169 loss 1.5349012613296509\n",
            "epoch 23 step 170 loss 1.497310757637024\n",
            "epoch 23 step 171 loss 1.5200295448303223\n",
            "epoch 23 step 172 loss 1.496035099029541\n",
            "epoch 23 step 173 loss 1.5009453296661377\n",
            "epoch 23 step 174 loss 1.4990992546081543\n",
            "epoch 23 step 175 loss 1.489517092704773\n",
            "epoch 23 step 176 loss 1.4972912073135376\n",
            "epoch 23 step 177 loss 1.5319939851760864\n",
            "epoch 23 step 178 loss 1.482925295829773\n",
            "epoch 23 step 179 loss 1.5231417417526245\n",
            "epoch 23 step 180 loss 1.5074293613433838 test_accuracy 73.60000610351562 train_accuracy 95.3125\n",
            "epoch 23 step 181 loss 1.4954233169555664\n",
            "epoch 23 step 182 loss 1.4936233758926392\n",
            "epoch 23 step 183 loss 1.522157073020935\n",
            "epoch 23 step 184 loss 1.5310512781143188\n",
            "epoch 23 step 185 loss 1.4648096561431885\n",
            "epoch 24 step 0 loss 1.5319843292236328 test_accuracy 73.4000015258789 train_accuracy 96.09375\n",
            "epoch 24 step 1 loss 1.4861712455749512\n",
            "epoch 24 step 2 loss 1.5033859014511108\n",
            "epoch 24 step 3 loss 1.515548586845398\n",
            "epoch 24 step 4 loss 1.5129255056381226\n",
            "epoch 24 step 5 loss 1.4965505599975586\n",
            "epoch 24 step 6 loss 1.4856503009796143\n",
            "epoch 24 step 7 loss 1.5191220045089722\n",
            "epoch 24 step 8 loss 1.4938364028930664\n",
            "epoch 24 step 9 loss 1.5322154760360718\n",
            "epoch 24 step 10 loss 1.5177040100097656\n",
            "epoch 24 step 11 loss 1.4799165725708008\n",
            "epoch 24 step 12 loss 1.4857079982757568\n",
            "epoch 24 step 13 loss 1.5043734312057495\n",
            "epoch 24 step 14 loss 1.5073285102844238\n",
            "epoch 24 step 15 loss 1.510269045829773\n",
            "epoch 24 step 16 loss 1.5040066242218018\n",
            "epoch 24 step 17 loss 1.4974141120910645\n",
            "epoch 24 step 18 loss 1.5337886810302734\n",
            "epoch 24 step 19 loss 1.501002311706543\n",
            "epoch 24 step 20 loss 1.5061275959014893 test_accuracy 73.80000305175781 train_accuracy 95.3125\n",
            "epoch 24 step 21 loss 1.51615571975708\n",
            "epoch 24 step 22 loss 1.551872730255127\n",
            "epoch 24 step 23 loss 1.5268157720565796\n",
            "epoch 24 step 24 loss 1.52491295337677\n",
            "epoch 24 step 25 loss 1.4876753091812134\n",
            "epoch 24 step 26 loss 1.5029213428497314\n",
            "epoch 24 step 27 loss 1.5192689895629883\n",
            "epoch 24 step 28 loss 1.507605791091919\n",
            "epoch 24 step 29 loss 1.5193458795547485\n",
            "epoch 24 step 30 loss 1.5086278915405273\n",
            "epoch 24 step 31 loss 1.4850841760635376\n",
            "epoch 24 step 32 loss 1.5121244192123413\n",
            "epoch 24 step 33 loss 1.4833147525787354\n",
            "epoch 24 step 34 loss 1.5407406091690063\n",
            "epoch 24 step 35 loss 1.5599873065948486\n",
            "epoch 24 step 36 loss 1.4917352199554443\n",
            "epoch 24 step 37 loss 1.4884681701660156\n",
            "epoch 24 step 38 loss 1.4939390420913696\n",
            "epoch 24 step 39 loss 1.507380485534668\n",
            "epoch 24 step 40 loss 1.5034756660461426 test_accuracy 73.4000015258789 train_accuracy 95.3125\n",
            "epoch 24 step 41 loss 1.5142825841903687\n",
            "epoch 24 step 42 loss 1.5094892978668213\n",
            "epoch 24 step 43 loss 1.494118094444275\n",
            "epoch 24 step 44 loss 1.5313656330108643\n",
            "epoch 24 step 45 loss 1.509962558746338\n",
            "epoch 24 step 46 loss 1.5183426141738892\n",
            "epoch 24 step 47 loss 1.5436170101165771\n",
            "epoch 24 step 48 loss 1.5028584003448486\n",
            "epoch 24 step 49 loss 1.5221582651138306\n",
            "epoch 24 step 50 loss 1.5204848051071167\n",
            "epoch 24 step 51 loss 1.494328260421753\n",
            "epoch 24 step 52 loss 1.509270429611206\n",
            "epoch 24 step 53 loss 1.4844731092453003\n",
            "epoch 24 step 54 loss 1.5111501216888428\n",
            "epoch 24 step 55 loss 1.5145213603973389\n",
            "epoch 24 step 56 loss 1.5085753202438354\n",
            "epoch 24 step 57 loss 1.5071992874145508\n",
            "epoch 24 step 58 loss 1.508348822593689\n",
            "epoch 24 step 59 loss 1.4860984086990356\n",
            "epoch 24 step 60 loss 1.5204381942749023 test_accuracy 72.20000457763672 train_accuracy 96.875\n",
            "epoch 24 step 61 loss 1.5231531858444214\n",
            "epoch 24 step 62 loss 1.5157588720321655\n",
            "epoch 24 step 63 loss 1.503139853477478\n",
            "epoch 24 step 64 loss 1.5019400119781494\n",
            "epoch 24 step 65 loss 1.5044583082199097\n",
            "epoch 24 step 66 loss 1.5032960176467896\n",
            "epoch 24 step 67 loss 1.507741093635559\n",
            "epoch 24 step 68 loss 1.556820034980774\n",
            "epoch 24 step 69 loss 1.510716199874878\n",
            "epoch 24 step 70 loss 1.511760950088501\n",
            "epoch 24 step 71 loss 1.4962553977966309\n",
            "epoch 24 step 72 loss 1.497756838798523\n",
            "epoch 24 step 73 loss 1.5323853492736816\n",
            "epoch 24 step 74 loss 1.5241780281066895\n",
            "epoch 24 step 75 loss 1.5358680486679077\n",
            "epoch 24 step 76 loss 1.516446828842163\n",
            "epoch 24 step 77 loss 1.523696780204773\n",
            "epoch 24 step 78 loss 1.5226765871047974\n",
            "epoch 24 step 79 loss 1.4903712272644043\n",
            "epoch 24 step 80 loss 1.5034452676773071 test_accuracy 73.80000305175781 train_accuracy 98.4375\n",
            "epoch 24 step 81 loss 1.5229637622833252\n",
            "epoch 24 step 82 loss 1.5049680471420288\n",
            "epoch 24 step 83 loss 1.5533418655395508\n",
            "epoch 24 step 84 loss 1.5023928880691528\n",
            "epoch 24 step 85 loss 1.5260066986083984\n",
            "epoch 24 step 86 loss 1.5314942598342896\n",
            "epoch 24 step 87 loss 1.511899471282959\n",
            "epoch 24 step 88 loss 1.4746276140213013\n",
            "epoch 24 step 89 loss 1.517303466796875\n",
            "epoch 24 step 90 loss 1.4820799827575684\n",
            "epoch 24 step 91 loss 1.4990301132202148\n",
            "epoch 24 step 92 loss 1.5359125137329102\n",
            "epoch 24 step 93 loss 1.509723424911499\n",
            "epoch 24 step 94 loss 1.522513508796692\n",
            "epoch 24 step 95 loss 1.5120363235473633\n",
            "epoch 24 step 96 loss 1.5355738401412964\n",
            "epoch 24 step 97 loss 1.5325322151184082\n",
            "epoch 24 step 98 loss 1.5357396602630615\n",
            "epoch 24 step 99 loss 1.5345138311386108\n",
            "epoch 24 step 100 loss 1.5718942880630493 test_accuracy 73.4000015258789 train_accuracy 93.75\n",
            "epoch 24 step 101 loss 1.4854085445404053\n",
            "epoch 24 step 102 loss 1.5137535333633423\n",
            "epoch 24 step 103 loss 1.5394964218139648\n",
            "epoch 24 step 104 loss 1.5435092449188232\n",
            "epoch 24 step 105 loss 1.6029819250106812\n",
            "epoch 24 step 106 loss 1.5000072717666626\n",
            "epoch 24 step 107 loss 1.5455853939056396\n",
            "epoch 24 step 108 loss 1.504141092300415\n",
            "epoch 24 step 109 loss 1.5401722192764282\n",
            "epoch 24 step 110 loss 1.4930250644683838\n",
            "epoch 24 step 111 loss 1.5235389471054077\n",
            "epoch 24 step 112 loss 1.4935765266418457\n",
            "epoch 24 step 113 loss 1.5258204936981201\n",
            "epoch 24 step 114 loss 1.5343480110168457\n",
            "epoch 24 step 115 loss 1.5040732622146606\n",
            "epoch 24 step 116 loss 1.498518943786621\n",
            "epoch 24 step 117 loss 1.5281891822814941\n",
            "epoch 24 step 118 loss 1.4988397359848022\n",
            "epoch 24 step 119 loss 1.5269650220870972\n",
            "epoch 24 step 120 loss 1.5090047121047974 test_accuracy 73.20000457763672 train_accuracy 96.09375\n",
            "epoch 24 step 121 loss 1.5331765413284302\n",
            "epoch 24 step 122 loss 1.51272451877594\n",
            "epoch 24 step 123 loss 1.4768633842468262\n",
            "epoch 24 step 124 loss 1.5514371395111084\n",
            "epoch 24 step 125 loss 1.4848253726959229\n",
            "epoch 24 step 126 loss 1.511435866355896\n",
            "epoch 24 step 127 loss 1.5172605514526367\n",
            "epoch 24 step 128 loss 1.5150338411331177\n",
            "epoch 24 step 129 loss 1.5367283821105957\n",
            "epoch 24 step 130 loss 1.5235204696655273\n",
            "epoch 24 step 131 loss 1.5349215269088745\n",
            "epoch 24 step 132 loss 1.5302764177322388\n",
            "epoch 24 step 133 loss 1.5033644437789917\n",
            "epoch 24 step 134 loss 1.4997140169143677\n",
            "epoch 24 step 135 loss 1.5482937097549438\n",
            "epoch 24 step 136 loss 1.5353494882583618\n",
            "epoch 24 step 137 loss 1.5424542427062988\n",
            "epoch 24 step 138 loss 1.4711980819702148\n",
            "epoch 24 step 139 loss 1.5078600645065308\n",
            "epoch 24 step 140 loss 1.5251461267471313 test_accuracy 74.4000015258789 train_accuracy 96.875\n",
            "epoch 24 step 141 loss 1.4882813692092896\n",
            "epoch 24 step 142 loss 1.5163230895996094\n",
            "epoch 24 step 143 loss 1.5139305591583252\n",
            "epoch 24 step 144 loss 1.4914417266845703\n",
            "epoch 24 step 145 loss 1.4939814805984497\n",
            "epoch 24 step 146 loss 1.5402988195419312\n",
            "epoch 24 step 147 loss 1.5161255598068237\n",
            "epoch 24 step 148 loss 1.5334820747375488\n",
            "epoch 24 step 149 loss 1.538164734840393\n",
            "epoch 24 step 150 loss 1.5285751819610596\n",
            "epoch 24 step 151 loss 1.5254578590393066\n",
            "epoch 24 step 152 loss 1.5315752029418945\n",
            "epoch 24 step 153 loss 1.5202124118804932\n",
            "epoch 24 step 154 loss 1.5305354595184326\n",
            "epoch 24 step 155 loss 1.4822593927383423\n",
            "epoch 24 step 156 loss 1.5428657531738281\n",
            "epoch 24 step 157 loss 1.497022032737732\n",
            "epoch 24 step 158 loss 1.505237340927124\n",
            "epoch 24 step 159 loss 1.4898375272750854\n",
            "epoch 24 step 160 loss 1.4822551012039185 test_accuracy 74.0 train_accuracy 95.3125\n",
            "epoch 24 step 161 loss 1.5102108716964722\n",
            "epoch 24 step 162 loss 1.515179991722107\n",
            "epoch 24 step 163 loss 1.5429173707962036\n",
            "epoch 24 step 164 loss 1.5169099569320679\n",
            "epoch 24 step 165 loss 1.4914182424545288\n",
            "epoch 24 step 166 loss 1.5255614519119263\n",
            "epoch 24 step 167 loss 1.5060455799102783\n",
            "epoch 24 step 168 loss 1.4873899221420288\n",
            "epoch 24 step 169 loss 1.5043798685073853\n",
            "epoch 24 step 170 loss 1.5408196449279785\n",
            "epoch 24 step 171 loss 1.5177850723266602\n",
            "epoch 24 step 172 loss 1.5159207582473755\n",
            "epoch 24 step 173 loss 1.5499873161315918\n",
            "epoch 24 step 174 loss 1.5071336030960083\n",
            "epoch 24 step 175 loss 1.5344301462173462\n",
            "epoch 24 step 176 loss 1.5028557777404785\n",
            "epoch 24 step 177 loss 1.5180766582489014\n",
            "epoch 24 step 178 loss 1.5005992650985718\n",
            "epoch 24 step 179 loss 1.4844995737075806\n",
            "epoch 24 step 180 loss 1.5307430028915405 test_accuracy 73.60000610351562 train_accuracy 96.09375\n",
            "epoch 24 step 181 loss 1.4772279262542725\n",
            "epoch 24 step 182 loss 1.4811238050460815\n",
            "epoch 24 step 183 loss 1.5244935750961304\n",
            "epoch 24 step 184 loss 1.5167051553726196\n",
            "epoch 24 step 185 loss 1.5314677953720093\n",
            "epoch 25 step 0 loss 1.4989479780197144 test_accuracy 73.60000610351562 train_accuracy 93.75\n",
            "epoch 25 step 1 loss 1.4918533563613892\n",
            "epoch 25 step 2 loss 1.523821473121643\n",
            "epoch 25 step 3 loss 1.5190123319625854\n",
            "epoch 25 step 4 loss 1.486356258392334\n",
            "epoch 25 step 5 loss 1.5361812114715576\n",
            "epoch 25 step 6 loss 1.4939653873443604\n",
            "epoch 25 step 7 loss 1.5039536952972412\n",
            "epoch 25 step 8 loss 1.5149898529052734\n",
            "epoch 25 step 9 loss 1.5167771577835083\n",
            "epoch 25 step 10 loss 1.555259346961975\n",
            "epoch 25 step 11 loss 1.517587661743164\n",
            "epoch 25 step 12 loss 1.5226389169692993\n",
            "epoch 25 step 13 loss 1.4986580610275269\n",
            "epoch 25 step 14 loss 1.4810124635696411\n",
            "epoch 25 step 15 loss 1.5568572282791138\n",
            "epoch 25 step 16 loss 1.5041062831878662\n",
            "epoch 25 step 17 loss 1.542217493057251\n",
            "epoch 25 step 18 loss 1.521454930305481\n",
            "epoch 25 step 19 loss 1.525211215019226\n",
            "epoch 25 step 20 loss 1.5116158723831177 test_accuracy 73.4000015258789 train_accuracy 96.09375\n",
            "epoch 25 step 21 loss 1.4906766414642334\n",
            "epoch 25 step 22 loss 1.495634913444519\n",
            "epoch 25 step 23 loss 1.5089370012283325\n",
            "epoch 25 step 24 loss 1.5091055631637573\n",
            "epoch 25 step 25 loss 1.500888466835022\n",
            "epoch 25 step 26 loss 1.4925240278244019\n",
            "epoch 25 step 27 loss 1.4894834756851196\n",
            "epoch 25 step 28 loss 1.4984445571899414\n",
            "epoch 25 step 29 loss 1.5447713136672974\n",
            "epoch 25 step 30 loss 1.5545434951782227\n",
            "epoch 25 step 31 loss 1.5497487783432007\n",
            "epoch 25 step 32 loss 1.488839030265808\n",
            "epoch 25 step 33 loss 1.4910436868667603\n",
            "epoch 25 step 34 loss 1.5122127532958984\n",
            "epoch 25 step 35 loss 1.5313149690628052\n",
            "epoch 25 step 36 loss 1.493025779724121\n",
            "epoch 25 step 37 loss 1.5226956605911255\n",
            "epoch 25 step 38 loss 1.5071038007736206\n",
            "epoch 25 step 39 loss 1.5019965171813965\n",
            "epoch 25 step 40 loss 1.4953820705413818 test_accuracy 73.4000015258789 train_accuracy 95.3125\n",
            "epoch 25 step 41 loss 1.5028908252716064\n",
            "epoch 25 step 42 loss 1.5250579118728638\n",
            "epoch 25 step 43 loss 1.5349962711334229\n",
            "epoch 25 step 44 loss 1.4992612600326538\n",
            "epoch 25 step 45 loss 1.5148215293884277\n",
            "epoch 25 step 46 loss 1.5204161405563354\n",
            "epoch 25 step 47 loss 1.4893860816955566\n",
            "epoch 25 step 48 loss 1.5125253200531006\n",
            "epoch 25 step 49 loss 1.4960730075836182\n",
            "epoch 25 step 50 loss 1.500320553779602\n",
            "epoch 25 step 51 loss 1.523208737373352\n",
            "epoch 25 step 52 loss 1.4972151517868042\n",
            "epoch 25 step 53 loss 1.4974151849746704\n",
            "epoch 25 step 54 loss 1.4992618560791016\n",
            "epoch 25 step 55 loss 1.5208593606948853\n",
            "epoch 25 step 56 loss 1.5294166803359985\n",
            "epoch 25 step 57 loss 1.487143874168396\n",
            "epoch 25 step 58 loss 1.4973807334899902\n",
            "epoch 25 step 59 loss 1.4849178791046143\n",
            "epoch 25 step 60 loss 1.4930099248886108 test_accuracy 73.20000457763672 train_accuracy 96.875\n",
            "epoch 25 step 61 loss 1.4924908876419067\n",
            "epoch 25 step 62 loss 1.5125879049301147\n",
            "epoch 25 step 63 loss 1.534839391708374\n",
            "epoch 25 step 64 loss 1.5357325077056885\n",
            "epoch 25 step 65 loss 1.5334752798080444\n",
            "epoch 25 step 66 loss 1.516330599784851\n",
            "epoch 25 step 67 loss 1.5214688777923584\n",
            "epoch 25 step 68 loss 1.4935542345046997\n",
            "epoch 25 step 69 loss 1.4778491258621216\n",
            "epoch 25 step 70 loss 1.515995979309082\n",
            "epoch 25 step 71 loss 1.5164635181427002\n",
            "epoch 25 step 72 loss 1.5488477945327759\n",
            "epoch 25 step 73 loss 1.5011816024780273\n",
            "epoch 25 step 74 loss 1.5488039255142212\n",
            "epoch 25 step 75 loss 1.5144282579421997\n",
            "epoch 25 step 76 loss 1.4913088083267212\n",
            "epoch 25 step 77 loss 1.491268515586853\n",
            "epoch 25 step 78 loss 1.5297737121582031\n",
            "epoch 25 step 79 loss 1.4896899461746216\n",
            "epoch 25 step 80 loss 1.509090542793274 test_accuracy 73.80000305175781 train_accuracy 91.40625\n",
            "epoch 25 step 81 loss 1.4783601760864258\n",
            "epoch 25 step 82 loss 1.492980718612671\n",
            "epoch 25 step 83 loss 1.4821146726608276\n",
            "epoch 25 step 84 loss 1.5144002437591553\n",
            "epoch 25 step 85 loss 1.4977844953536987\n",
            "epoch 25 step 86 loss 1.551044225692749\n",
            "epoch 25 step 87 loss 1.5172849893569946\n",
            "epoch 25 step 88 loss 1.4994620084762573\n",
            "epoch 25 step 89 loss 1.514196515083313\n",
            "epoch 25 step 90 loss 1.517102837562561\n",
            "epoch 25 step 91 loss 1.5145721435546875\n",
            "epoch 25 step 92 loss 1.512569546699524\n",
            "epoch 25 step 93 loss 1.5235021114349365\n",
            "epoch 25 step 94 loss 1.5080864429473877\n",
            "epoch 25 step 95 loss 1.5179548263549805\n",
            "epoch 25 step 96 loss 1.4954532384872437\n",
            "epoch 25 step 97 loss 1.5380321741104126\n",
            "epoch 25 step 98 loss 1.4928131103515625\n",
            "epoch 25 step 99 loss 1.5260169506072998\n",
            "epoch 25 step 100 loss 1.5218102931976318 test_accuracy 73.60000610351562 train_accuracy 96.875\n",
            "epoch 25 step 101 loss 1.4903690814971924\n",
            "epoch 25 step 102 loss 1.4998807907104492\n",
            "epoch 25 step 103 loss 1.5185108184814453\n",
            "epoch 25 step 104 loss 1.4860669374465942\n",
            "epoch 25 step 105 loss 1.5406122207641602\n",
            "epoch 25 step 106 loss 1.4965182542800903\n",
            "epoch 25 step 107 loss 1.5034834146499634\n",
            "epoch 25 step 108 loss 1.5017197132110596\n",
            "epoch 25 step 109 loss 1.5518782138824463\n",
            "epoch 25 step 110 loss 1.5288004875183105\n",
            "epoch 25 step 111 loss 1.4988043308258057\n",
            "epoch 25 step 112 loss 1.569441318511963\n",
            "epoch 25 step 113 loss 1.5514156818389893\n",
            "epoch 25 step 114 loss 1.5295567512512207\n",
            "epoch 25 step 115 loss 1.5108104944229126\n",
            "epoch 25 step 116 loss 1.5165966749191284\n",
            "epoch 25 step 117 loss 1.50356125831604\n",
            "epoch 25 step 118 loss 1.547236442565918\n",
            "epoch 25 step 119 loss 1.4962648153305054\n",
            "epoch 25 step 120 loss 1.507420301437378 test_accuracy 74.20000457763672 train_accuracy 98.4375\n",
            "epoch 25 step 121 loss 1.5029757022857666\n",
            "epoch 25 step 122 loss 1.4945074319839478\n",
            "epoch 25 step 123 loss 1.5310102701187134\n",
            "epoch 25 step 124 loss 1.5148487091064453\n",
            "epoch 25 step 125 loss 1.510437250137329\n",
            "epoch 25 step 126 loss 1.5055601596832275\n",
            "epoch 25 step 127 loss 1.531954050064087\n",
            "epoch 25 step 128 loss 1.5320733785629272\n",
            "epoch 25 step 129 loss 1.5131312608718872\n",
            "epoch 25 step 130 loss 1.5279333591461182\n",
            "epoch 25 step 131 loss 1.5754735469818115\n",
            "epoch 25 step 132 loss 1.5300179719924927\n",
            "epoch 25 step 133 loss 1.5212440490722656\n",
            "epoch 25 step 134 loss 1.4912092685699463\n",
            "epoch 25 step 135 loss 1.525052547454834\n",
            "epoch 25 step 136 loss 1.494009017944336\n",
            "epoch 25 step 137 loss 1.5484522581100464\n",
            "epoch 25 step 138 loss 1.5122431516647339\n",
            "epoch 25 step 139 loss 1.5360535383224487\n",
            "epoch 25 step 140 loss 1.5210016965866089 test_accuracy 74.4000015258789 train_accuracy 96.875\n",
            "epoch 25 step 141 loss 1.5333521366119385\n",
            "epoch 25 step 142 loss 1.517226219177246\n",
            "epoch 25 step 143 loss 1.502159833908081\n",
            "epoch 25 step 144 loss 1.497424602508545\n",
            "epoch 25 step 145 loss 1.5289517641067505\n",
            "epoch 25 step 146 loss 1.486940622329712\n",
            "epoch 25 step 147 loss 1.512137770652771\n",
            "epoch 25 step 148 loss 1.5289384126663208\n",
            "epoch 25 step 149 loss 1.5012527704238892\n",
            "epoch 25 step 150 loss 1.5667341947555542\n",
            "epoch 25 step 151 loss 1.4939905405044556\n",
            "epoch 25 step 152 loss 1.542548656463623\n",
            "epoch 25 step 153 loss 1.50166654586792\n",
            "epoch 25 step 154 loss 1.50200617313385\n",
            "epoch 25 step 155 loss 1.5246440172195435\n",
            "epoch 25 step 156 loss 1.494122862815857\n",
            "epoch 25 step 157 loss 1.497058629989624\n",
            "epoch 25 step 158 loss 1.5339007377624512\n",
            "epoch 25 step 159 loss 1.5235222578048706\n",
            "epoch 25 step 160 loss 1.5210596323013306 test_accuracy 74.0 train_accuracy 97.65625\n",
            "epoch 25 step 161 loss 1.4992786645889282\n",
            "epoch 25 step 162 loss 1.5202884674072266\n",
            "epoch 25 step 163 loss 1.5502269268035889\n",
            "epoch 25 step 164 loss 1.5213474035263062\n",
            "epoch 25 step 165 loss 1.518972396850586\n",
            "epoch 25 step 166 loss 1.5145059823989868\n",
            "epoch 25 step 167 loss 1.5081356763839722\n",
            "epoch 25 step 168 loss 1.5414667129516602\n",
            "epoch 25 step 169 loss 1.5452516078948975\n",
            "epoch 25 step 170 loss 1.5159611701965332\n",
            "epoch 25 step 171 loss 1.5112247467041016\n",
            "epoch 25 step 172 loss 1.5354740619659424\n",
            "epoch 25 step 173 loss 1.524591326713562\n",
            "epoch 25 step 174 loss 1.5333473682403564\n",
            "epoch 25 step 175 loss 1.53020179271698\n",
            "epoch 25 step 176 loss 1.539029836654663\n",
            "epoch 25 step 177 loss 1.5297894477844238\n",
            "epoch 25 step 178 loss 1.48935067653656\n",
            "epoch 25 step 179 loss 1.4984477758407593\n",
            "epoch 25 step 180 loss 1.5356884002685547 test_accuracy 74.0 train_accuracy 96.875\n",
            "epoch 25 step 181 loss 1.5214979648590088\n",
            "epoch 25 step 182 loss 1.511467695236206\n",
            "epoch 25 step 183 loss 1.4967639446258545\n",
            "epoch 25 step 184 loss 1.5312294960021973\n",
            "epoch 25 step 185 loss 1.4909179210662842\n",
            "epoch 26 step 0 loss 1.4886482954025269 test_accuracy 74.0 train_accuracy 96.09375\n",
            "epoch 26 step 1 loss 1.5094119310379028\n",
            "epoch 26 step 2 loss 1.5016744136810303\n",
            "epoch 26 step 3 loss 1.4994933605194092\n",
            "epoch 26 step 4 loss 1.519992709159851\n",
            "epoch 26 step 5 loss 1.5120452642440796\n",
            "epoch 26 step 6 loss 1.5209715366363525\n",
            "epoch 26 step 7 loss 1.5194838047027588\n",
            "epoch 26 step 8 loss 1.5001673698425293\n",
            "epoch 26 step 9 loss 1.5259795188903809\n",
            "epoch 26 step 10 loss 1.527453064918518\n",
            "epoch 26 step 11 loss 1.5319368839263916\n",
            "epoch 26 step 12 loss 1.522792935371399\n",
            "epoch 26 step 13 loss 1.515427589416504\n",
            "epoch 26 step 14 loss 1.5442451238632202\n",
            "epoch 26 step 15 loss 1.5757173299789429\n",
            "epoch 26 step 16 loss 1.5166428089141846\n",
            "epoch 26 step 17 loss 1.5213884115219116\n",
            "epoch 26 step 18 loss 1.5151675939559937\n",
            "epoch 26 step 19 loss 1.5093965530395508\n",
            "epoch 26 step 20 loss 1.516083836555481 test_accuracy 74.80000305175781 train_accuracy 91.40625\n",
            "epoch 26 step 21 loss 1.5260157585144043\n",
            "epoch 26 step 22 loss 1.5180519819259644\n",
            "epoch 26 step 23 loss 1.535730004310608\n",
            "epoch 26 step 24 loss 1.5122615098953247\n",
            "epoch 26 step 25 loss 1.4905668497085571\n",
            "epoch 26 step 26 loss 1.5073413848876953\n",
            "epoch 26 step 27 loss 1.5142266750335693\n",
            "epoch 26 step 28 loss 1.4998843669891357\n",
            "epoch 26 step 29 loss 1.5158337354660034\n",
            "epoch 26 step 30 loss 1.5486338138580322\n",
            "epoch 26 step 31 loss 1.5114949941635132\n",
            "epoch 26 step 32 loss 1.4789502620697021\n",
            "epoch 26 step 33 loss 1.5033618211746216\n",
            "epoch 26 step 34 loss 1.5212287902832031\n",
            "epoch 26 step 35 loss 1.534732699394226\n",
            "epoch 26 step 36 loss 1.5071803331375122\n",
            "epoch 26 step 37 loss 1.516599416732788\n",
            "epoch 26 step 38 loss 1.5198774337768555\n",
            "epoch 26 step 39 loss 1.5345970392227173\n",
            "epoch 26 step 40 loss 1.5194884538650513 test_accuracy 74.0 train_accuracy 96.875\n",
            "epoch 26 step 41 loss 1.5044962167739868\n",
            "epoch 26 step 42 loss 1.485050916671753\n",
            "epoch 26 step 43 loss 1.5255413055419922\n",
            "epoch 26 step 44 loss 1.529571294784546\n",
            "epoch 26 step 45 loss 1.4909090995788574\n",
            "epoch 26 step 46 loss 1.5397592782974243\n",
            "epoch 26 step 47 loss 1.4931223392486572\n",
            "epoch 26 step 48 loss 1.5136164426803589\n",
            "epoch 26 step 49 loss 1.5508460998535156\n",
            "epoch 26 step 50 loss 1.5056178569793701\n",
            "epoch 26 step 51 loss 1.5087602138519287\n",
            "epoch 26 step 52 loss 1.4971567392349243\n",
            "epoch 26 step 53 loss 1.5108102560043335\n",
            "epoch 26 step 54 loss 1.5005850791931152\n",
            "epoch 26 step 55 loss 1.5327204465866089\n",
            "epoch 26 step 56 loss 1.4876527786254883\n",
            "epoch 26 step 57 loss 1.502228856086731\n",
            "epoch 26 step 58 loss 1.5024250745773315\n",
            "epoch 26 step 59 loss 1.5174459218978882\n",
            "epoch 26 step 60 loss 1.505881905555725 test_accuracy 74.20000457763672 train_accuracy 96.875\n",
            "epoch 26 step 61 loss 1.5247963666915894\n",
            "epoch 26 step 62 loss 1.5027729272842407\n",
            "epoch 26 step 63 loss 1.5289207696914673\n",
            "epoch 26 step 64 loss 1.4997564554214478\n",
            "epoch 26 step 65 loss 1.5280542373657227\n",
            "epoch 26 step 66 loss 1.5391507148742676\n",
            "epoch 26 step 67 loss 1.510298252105713\n",
            "epoch 26 step 68 loss 1.5264005661010742\n",
            "epoch 26 step 69 loss 1.4865307807922363\n",
            "epoch 26 step 70 loss 1.5018737316131592\n",
            "epoch 26 step 71 loss 1.5187311172485352\n",
            "epoch 26 step 72 loss 1.511073112487793\n",
            "epoch 26 step 73 loss 1.516281008720398\n",
            "epoch 26 step 74 loss 1.4980337619781494\n",
            "epoch 26 step 75 loss 1.4842607975006104\n",
            "epoch 26 step 76 loss 1.534394383430481\n",
            "epoch 26 step 77 loss 1.4955803155899048\n",
            "epoch 26 step 78 loss 1.5178890228271484\n",
            "epoch 26 step 79 loss 1.5181125402450562\n",
            "epoch 26 step 80 loss 1.523951530456543 test_accuracy 74.20000457763672 train_accuracy 96.875\n",
            "epoch 26 step 81 loss 1.4916077852249146\n",
            "epoch 26 step 82 loss 1.511814832687378\n",
            "epoch 26 step 83 loss 1.5101886987686157\n",
            "epoch 26 step 84 loss 1.4981858730316162\n",
            "epoch 26 step 85 loss 1.5061174631118774\n",
            "epoch 26 step 86 loss 1.5213342905044556\n",
            "epoch 26 step 87 loss 1.4921354055404663\n",
            "epoch 26 step 88 loss 1.5028752088546753\n",
            "epoch 26 step 89 loss 1.509507179260254\n",
            "epoch 26 step 90 loss 1.5178253650665283\n",
            "epoch 26 step 91 loss 1.5492157936096191\n",
            "epoch 26 step 92 loss 1.5193514823913574\n",
            "epoch 26 step 93 loss 1.5122694969177246\n",
            "epoch 26 step 94 loss 1.5247548818588257\n",
            "epoch 26 step 95 loss 1.5088257789611816\n",
            "epoch 26 step 96 loss 1.5161149501800537\n",
            "epoch 26 step 97 loss 1.478653073310852\n",
            "epoch 26 step 98 loss 1.488448143005371\n",
            "epoch 26 step 99 loss 1.5215198993682861\n",
            "epoch 26 step 100 loss 1.536634087562561 test_accuracy 74.0 train_accuracy 96.09375\n",
            "epoch 26 step 101 loss 1.50188148021698\n",
            "epoch 26 step 102 loss 1.4820904731750488\n",
            "epoch 26 step 103 loss 1.5020248889923096\n",
            "epoch 26 step 104 loss 1.499722957611084\n",
            "epoch 26 step 105 loss 1.5522470474243164\n",
            "epoch 26 step 106 loss 1.4879649877548218\n",
            "epoch 26 step 107 loss 1.5343775749206543\n",
            "epoch 26 step 108 loss 1.5241940021514893\n",
            "epoch 26 step 109 loss 1.5190914869308472\n",
            "epoch 26 step 110 loss 1.4820762872695923\n",
            "epoch 26 step 111 loss 1.4911043643951416\n",
            "epoch 26 step 112 loss 1.5084288120269775\n",
            "epoch 26 step 113 loss 1.51624596118927\n",
            "epoch 26 step 114 loss 1.5135328769683838\n",
            "epoch 26 step 115 loss 1.4930180311203003\n",
            "epoch 26 step 116 loss 1.5196412801742554\n",
            "epoch 26 step 117 loss 1.4995791912078857\n",
            "epoch 26 step 118 loss 1.5306367874145508\n",
            "epoch 26 step 119 loss 1.4840463399887085\n",
            "epoch 26 step 120 loss 1.5265179872512817 test_accuracy 74.0 train_accuracy 95.3125\n",
            "epoch 26 step 121 loss 1.5045197010040283\n",
            "epoch 26 step 122 loss 1.5016379356384277\n",
            "epoch 26 step 123 loss 1.5038938522338867\n",
            "epoch 26 step 124 loss 1.51841402053833\n",
            "epoch 26 step 125 loss 1.5200618505477905\n",
            "epoch 26 step 126 loss 1.5374205112457275\n",
            "epoch 26 step 127 loss 1.5365726947784424\n",
            "epoch 26 step 128 loss 1.4777077436447144\n",
            "epoch 26 step 129 loss 1.4758087396621704\n",
            "epoch 26 step 130 loss 1.514710545539856\n",
            "epoch 26 step 131 loss 1.509237289428711\n",
            "epoch 26 step 132 loss 1.5069620609283447\n",
            "epoch 26 step 133 loss 1.4928041696548462\n",
            "epoch 26 step 134 loss 1.5261540412902832\n",
            "epoch 26 step 135 loss 1.522158145904541\n",
            "epoch 26 step 136 loss 1.5290766954421997\n",
            "epoch 26 step 137 loss 1.5247039794921875\n",
            "epoch 26 step 138 loss 1.5208605527877808\n",
            "epoch 26 step 139 loss 1.534056305885315\n",
            "epoch 26 step 140 loss 1.5335993766784668 test_accuracy 74.20000457763672 train_accuracy 95.3125\n",
            "epoch 26 step 141 loss 1.5084052085876465\n",
            "epoch 26 step 142 loss 1.5323537588119507\n",
            "epoch 26 step 143 loss 1.5057685375213623\n",
            "epoch 26 step 144 loss 1.4902369976043701\n",
            "epoch 26 step 145 loss 1.4809038639068604\n",
            "epoch 26 step 146 loss 1.5282137393951416\n",
            "epoch 26 step 147 loss 1.502342939376831\n",
            "epoch 26 step 148 loss 1.509265422821045\n",
            "epoch 26 step 149 loss 1.4967914819717407\n",
            "epoch 26 step 150 loss 1.507250189781189\n",
            "epoch 26 step 151 loss 1.5568678379058838\n",
            "epoch 26 step 152 loss 1.4913649559020996\n",
            "epoch 26 step 153 loss 1.512115716934204\n",
            "epoch 26 step 154 loss 1.5388147830963135\n",
            "epoch 26 step 155 loss 1.5560171604156494\n",
            "epoch 26 step 156 loss 1.5383167266845703\n",
            "epoch 26 step 157 loss 1.4803770780563354\n",
            "epoch 26 step 158 loss 1.5293219089508057\n",
            "epoch 26 step 159 loss 1.5112323760986328\n",
            "epoch 26 step 160 loss 1.4942710399627686 test_accuracy 74.0 train_accuracy 98.4375\n",
            "epoch 26 step 161 loss 1.4903539419174194\n",
            "epoch 26 step 162 loss 1.4853627681732178\n",
            "epoch 26 step 163 loss 1.5022459030151367\n",
            "epoch 26 step 164 loss 1.479141354560852\n",
            "epoch 26 step 165 loss 1.4894864559173584\n",
            "epoch 26 step 166 loss 1.5245075225830078\n",
            "epoch 26 step 167 loss 1.5044236183166504\n",
            "epoch 26 step 168 loss 1.5440019369125366\n",
            "epoch 26 step 169 loss 1.5231170654296875\n",
            "epoch 26 step 170 loss 1.5310078859329224\n",
            "epoch 26 step 171 loss 1.50821852684021\n",
            "epoch 26 step 172 loss 1.5089142322540283\n",
            "epoch 26 step 173 loss 1.4912210702896118\n",
            "epoch 26 step 174 loss 1.5198487043380737\n",
            "epoch 26 step 175 loss 1.5264170169830322\n",
            "epoch 26 step 176 loss 1.4954179525375366\n",
            "epoch 26 step 177 loss 1.5066828727722168\n",
            "epoch 26 step 178 loss 1.514466643333435\n",
            "epoch 26 step 179 loss 1.5396349430084229\n",
            "epoch 26 step 180 loss 1.5095726251602173 test_accuracy 74.60000610351562 train_accuracy 92.96875\n",
            "epoch 26 step 181 loss 1.5009413957595825\n",
            "epoch 26 step 182 loss 1.5284814834594727\n",
            "epoch 26 step 183 loss 1.5147992372512817\n",
            "epoch 26 step 184 loss 1.5128159523010254\n",
            "epoch 26 step 185 loss 1.5202205181121826\n",
            "epoch 27 step 0 loss 1.4870977401733398 test_accuracy 74.4000015258789 train_accuracy 96.875\n",
            "epoch 27 step 1 loss 1.4900325536727905\n",
            "epoch 27 step 2 loss 1.5198297500610352\n",
            "epoch 27 step 3 loss 1.4926899671554565\n",
            "epoch 27 step 4 loss 1.496159315109253\n",
            "epoch 27 step 5 loss 1.5096789598464966\n",
            "epoch 27 step 6 loss 1.4903337955474854\n",
            "epoch 27 step 7 loss 1.5480914115905762\n",
            "epoch 27 step 8 loss 1.5127861499786377\n",
            "epoch 27 step 9 loss 1.5152021646499634\n",
            "epoch 27 step 10 loss 1.5225328207015991\n",
            "epoch 27 step 11 loss 1.5321929454803467\n",
            "epoch 27 step 12 loss 1.587004542350769\n",
            "epoch 27 step 13 loss 1.5281873941421509\n",
            "epoch 27 step 14 loss 1.5120726823806763\n",
            "epoch 27 step 15 loss 1.4772284030914307\n",
            "epoch 27 step 16 loss 1.514841914176941\n",
            "epoch 27 step 17 loss 1.5192205905914307\n",
            "epoch 27 step 18 loss 1.511143684387207\n",
            "epoch 27 step 19 loss 1.5232741832733154\n",
            "epoch 27 step 20 loss 1.4951770305633545 test_accuracy 74.20000457763672 train_accuracy 96.09375\n",
            "epoch 27 step 21 loss 1.5139063596725464\n",
            "epoch 27 step 22 loss 1.4853228330612183\n",
            "epoch 27 step 23 loss 1.4771190881729126\n",
            "epoch 27 step 24 loss 1.507174015045166\n",
            "epoch 27 step 25 loss 1.512295126914978\n",
            "epoch 27 step 26 loss 1.4909071922302246\n",
            "epoch 27 step 27 loss 1.5501669645309448\n",
            "epoch 27 step 28 loss 1.5365803241729736\n",
            "epoch 27 step 29 loss 1.5059326887130737\n",
            "epoch 27 step 30 loss 1.5003299713134766\n",
            "epoch 27 step 31 loss 1.5474964380264282\n",
            "epoch 27 step 32 loss 1.511130452156067\n",
            "epoch 27 step 33 loss 1.478841781616211\n",
            "epoch 27 step 34 loss 1.5089163780212402\n",
            "epoch 27 step 35 loss 1.5393556356430054\n",
            "epoch 27 step 36 loss 1.498159646987915\n",
            "epoch 27 step 37 loss 1.4922581911087036\n",
            "epoch 27 step 38 loss 1.5146220922470093\n",
            "epoch 27 step 39 loss 1.5152839422225952\n",
            "epoch 27 step 40 loss 1.5362313985824585 test_accuracy 74.0 train_accuracy 95.3125\n",
            "epoch 27 step 41 loss 1.5191529989242554\n",
            "epoch 27 step 42 loss 1.5113273859024048\n",
            "epoch 27 step 43 loss 1.5187581777572632\n",
            "epoch 27 step 44 loss 1.5366395711898804\n",
            "epoch 27 step 45 loss 1.526512622833252\n",
            "epoch 27 step 46 loss 1.5253667831420898\n",
            "epoch 27 step 47 loss 1.4956737756729126\n",
            "epoch 27 step 48 loss 1.5038986206054688\n",
            "epoch 27 step 49 loss 1.499018669128418\n",
            "epoch 27 step 50 loss 1.5197598934173584\n",
            "epoch 27 step 51 loss 1.5393656492233276\n",
            "epoch 27 step 52 loss 1.5028350353240967\n",
            "epoch 27 step 53 loss 1.5325360298156738\n",
            "epoch 27 step 54 loss 1.490206241607666\n",
            "epoch 27 step 55 loss 1.5218356847763062\n",
            "epoch 27 step 56 loss 1.5066208839416504\n",
            "epoch 27 step 57 loss 1.5151104927062988\n",
            "epoch 27 step 58 loss 1.5338654518127441\n",
            "epoch 27 step 59 loss 1.5168794393539429\n",
            "epoch 27 step 60 loss 1.4920334815979004 test_accuracy 74.20000457763672 train_accuracy 97.65625\n",
            "epoch 27 step 61 loss 1.4867677688598633\n",
            "epoch 27 step 62 loss 1.5075703859329224\n",
            "epoch 27 step 63 loss 1.4868857860565186\n",
            "epoch 27 step 64 loss 1.5363785028457642\n",
            "epoch 27 step 65 loss 1.5350059270858765\n",
            "epoch 27 step 66 loss 1.5051541328430176\n",
            "epoch 27 step 67 loss 1.5067170858383179\n",
            "epoch 27 step 68 loss 1.5462524890899658\n",
            "epoch 27 step 69 loss 1.522302508354187\n",
            "epoch 27 step 70 loss 1.4886730909347534\n",
            "epoch 27 step 71 loss 1.5214436054229736\n",
            "epoch 27 step 72 loss 1.520902156829834\n",
            "epoch 27 step 73 loss 1.5229747295379639\n",
            "epoch 27 step 74 loss 1.495427131652832\n",
            "epoch 27 step 75 loss 1.5039174556732178\n",
            "epoch 27 step 76 loss 1.5083979368209839\n",
            "epoch 27 step 77 loss 1.513064980506897\n",
            "epoch 27 step 78 loss 1.5710657835006714\n",
            "epoch 27 step 79 loss 1.5056313276290894\n",
            "epoch 27 step 80 loss 1.5163848400115967 test_accuracy 74.0 train_accuracy 92.96875\n",
            "epoch 27 step 81 loss 1.5253266096115112\n",
            "epoch 27 step 82 loss 1.4971275329589844\n",
            "epoch 27 step 83 loss 1.4942703247070312\n",
            "epoch 27 step 84 loss 1.5365867614746094\n",
            "epoch 27 step 85 loss 1.5100009441375732\n",
            "epoch 27 step 86 loss 1.5228041410446167\n",
            "epoch 27 step 87 loss 1.5028393268585205\n",
            "epoch 27 step 88 loss 1.5471478700637817\n",
            "epoch 27 step 89 loss 1.470180869102478\n",
            "epoch 27 step 90 loss 1.5167410373687744\n",
            "epoch 27 step 91 loss 1.4986885786056519\n",
            "epoch 27 step 92 loss 1.5558956861495972\n",
            "epoch 27 step 93 loss 1.5068036317825317\n",
            "epoch 27 step 94 loss 1.5346282720565796\n",
            "epoch 27 step 95 loss 1.4860026836395264\n",
            "epoch 27 step 96 loss 1.509634017944336\n",
            "epoch 27 step 97 loss 1.5096712112426758\n",
            "epoch 27 step 98 loss 1.563393473625183\n",
            "epoch 27 step 99 loss 1.5224382877349854\n",
            "epoch 27 step 100 loss 1.5345628261566162 test_accuracy 74.20000457763672 train_accuracy 96.09375\n",
            "epoch 27 step 101 loss 1.520287275314331\n",
            "epoch 27 step 102 loss 1.5133440494537354\n",
            "epoch 27 step 103 loss 1.5086557865142822\n",
            "epoch 27 step 104 loss 1.514792561531067\n",
            "epoch 27 step 105 loss 1.4903559684753418\n",
            "epoch 27 step 106 loss 1.4997843503952026\n",
            "epoch 27 step 107 loss 1.4954808950424194\n",
            "epoch 27 step 108 loss 1.5292433500289917\n",
            "epoch 27 step 109 loss 1.5033811330795288\n",
            "epoch 27 step 110 loss 1.5239717960357666\n",
            "epoch 27 step 111 loss 1.4971011877059937\n",
            "epoch 27 step 112 loss 1.53244149684906\n",
            "epoch 27 step 113 loss 1.5485343933105469\n",
            "epoch 27 step 114 loss 1.5329009294509888\n",
            "epoch 27 step 115 loss 1.5008875131607056\n",
            "epoch 27 step 116 loss 1.5229319334030151\n",
            "epoch 27 step 117 loss 1.495890498161316\n",
            "epoch 27 step 118 loss 1.5403847694396973\n",
            "epoch 27 step 119 loss 1.5001788139343262\n",
            "epoch 27 step 120 loss 1.5189604759216309 test_accuracy 74.20000457763672 train_accuracy 97.65625\n",
            "epoch 27 step 121 loss 1.5108147859573364\n",
            "epoch 27 step 122 loss 1.5113242864608765\n",
            "epoch 27 step 123 loss 1.5171067714691162\n",
            "epoch 27 step 124 loss 1.5010321140289307\n",
            "epoch 27 step 125 loss 1.475250005722046\n",
            "epoch 27 step 126 loss 1.5330007076263428\n",
            "epoch 27 step 127 loss 1.5280698537826538\n",
            "epoch 27 step 128 loss 1.5048695802688599\n",
            "epoch 27 step 129 loss 1.49006986618042\n",
            "epoch 27 step 130 loss 1.5105421543121338\n",
            "epoch 27 step 131 loss 1.4855146408081055\n",
            "epoch 27 step 132 loss 1.5122394561767578\n",
            "epoch 27 step 133 loss 1.5107817649841309\n",
            "epoch 27 step 134 loss 1.541245460510254\n",
            "epoch 27 step 135 loss 1.5062744617462158\n",
            "epoch 27 step 136 loss 1.4949244260787964\n",
            "epoch 27 step 137 loss 1.5072839260101318\n",
            "epoch 27 step 138 loss 1.515568733215332\n",
            "epoch 27 step 139 loss 1.5043755769729614\n",
            "epoch 27 step 140 loss 1.5236848592758179 test_accuracy 74.4000015258789 train_accuracy 92.96875\n",
            "epoch 27 step 141 loss 1.5140767097473145\n",
            "epoch 27 step 142 loss 1.544769287109375\n",
            "epoch 27 step 143 loss 1.5219268798828125\n",
            "epoch 27 step 144 loss 1.5034998655319214\n",
            "epoch 27 step 145 loss 1.4775878190994263\n",
            "epoch 27 step 146 loss 1.5148732662200928\n",
            "epoch 27 step 147 loss 1.4995564222335815\n",
            "epoch 27 step 148 loss 1.4841307401657104\n",
            "epoch 27 step 149 loss 1.5263243913650513\n",
            "epoch 27 step 150 loss 1.556749701499939\n",
            "epoch 27 step 151 loss 1.4996960163116455\n",
            "epoch 27 step 152 loss 1.5142743587493896\n",
            "epoch 27 step 153 loss 1.4913408756256104\n",
            "epoch 27 step 154 loss 1.5435991287231445\n",
            "epoch 27 step 155 loss 1.5037561655044556\n",
            "epoch 27 step 156 loss 1.5109065771102905\n",
            "epoch 27 step 157 loss 1.493604302406311\n",
            "epoch 27 step 158 loss 1.5205689668655396\n",
            "epoch 27 step 159 loss 1.5367214679718018\n",
            "epoch 27 step 160 loss 1.500823974609375 test_accuracy 74.4000015258789 train_accuracy 94.53125\n",
            "epoch 27 step 161 loss 1.5036040544509888\n",
            "epoch 27 step 162 loss 1.5017354488372803\n",
            "epoch 27 step 163 loss 1.5279326438903809\n",
            "epoch 27 step 164 loss 1.5258979797363281\n",
            "epoch 27 step 165 loss 1.5255365371704102\n",
            "epoch 27 step 166 loss 1.5182833671569824\n",
            "epoch 27 step 167 loss 1.5095806121826172\n",
            "epoch 27 step 168 loss 1.5123631954193115\n",
            "epoch 27 step 169 loss 1.4833855628967285\n",
            "epoch 27 step 170 loss 1.5184848308563232\n",
            "epoch 27 step 171 loss 1.5014399290084839\n",
            "epoch 27 step 172 loss 1.5012201070785522\n",
            "epoch 27 step 173 loss 1.4863380193710327\n",
            "epoch 27 step 174 loss 1.5170695781707764\n",
            "epoch 27 step 175 loss 1.509921908378601\n",
            "epoch 27 step 176 loss 1.5119796991348267\n",
            "epoch 27 step 177 loss 1.4965739250183105\n",
            "epoch 27 step 178 loss 1.5333714485168457\n",
            "epoch 27 step 179 loss 1.495045781135559\n",
            "epoch 27 step 180 loss 1.526044249534607 test_accuracy 74.4000015258789 train_accuracy 96.09375\n",
            "epoch 27 step 181 loss 1.4876015186309814\n",
            "epoch 27 step 182 loss 1.512077808380127\n",
            "epoch 27 step 183 loss 1.5105453729629517\n",
            "epoch 27 step 184 loss 1.5174130201339722\n",
            "epoch 27 step 185 loss 1.577243685722351\n",
            "epoch 28 step 0 loss 1.5175367593765259 test_accuracy 74.4000015258789 train_accuracy 96.09375\n",
            "epoch 28 step 1 loss 1.4943032264709473\n",
            "epoch 28 step 2 loss 1.5369279384613037\n",
            "epoch 28 step 3 loss 1.5242986679077148\n",
            "epoch 28 step 4 loss 1.5451784133911133\n",
            "epoch 28 step 5 loss 1.5057473182678223\n",
            "epoch 28 step 6 loss 1.5635427236557007\n",
            "epoch 28 step 7 loss 1.5046000480651855\n",
            "epoch 28 step 8 loss 1.4834517240524292\n",
            "epoch 28 step 9 loss 1.4854388236999512\n",
            "epoch 28 step 10 loss 1.4946091175079346\n",
            "epoch 28 step 11 loss 1.5213007926940918\n",
            "epoch 28 step 12 loss 1.5182369947433472\n",
            "epoch 28 step 13 loss 1.4791127443313599\n",
            "epoch 28 step 14 loss 1.517997145652771\n",
            "epoch 28 step 15 loss 1.528328537940979\n",
            "epoch 28 step 16 loss 1.4927233457565308\n",
            "epoch 28 step 17 loss 1.5125867128372192\n",
            "epoch 28 step 18 loss 1.5007836818695068\n",
            "epoch 28 step 19 loss 1.5356606245040894\n",
            "epoch 28 step 20 loss 1.4750698804855347 test_accuracy 74.0 train_accuracy 96.875\n",
            "epoch 28 step 21 loss 1.520538568496704\n",
            "epoch 28 step 22 loss 1.5065566301345825\n",
            "epoch 28 step 23 loss 1.5106580257415771\n",
            "epoch 28 step 24 loss 1.4943538904190063\n",
            "epoch 28 step 25 loss 1.4872361421585083\n",
            "epoch 28 step 26 loss 1.4944477081298828\n",
            "epoch 28 step 27 loss 1.5173864364624023\n",
            "epoch 28 step 28 loss 1.511183261871338\n",
            "epoch 28 step 29 loss 1.4962916374206543\n",
            "epoch 28 step 30 loss 1.4992344379425049\n",
            "epoch 28 step 31 loss 1.5224250555038452\n",
            "epoch 28 step 32 loss 1.5042526721954346\n",
            "epoch 28 step 33 loss 1.4885389804840088\n",
            "epoch 28 step 34 loss 1.48567533493042\n",
            "epoch 28 step 35 loss 1.5033429861068726\n",
            "epoch 28 step 36 loss 1.4852389097213745\n",
            "epoch 28 step 37 loss 1.4900074005126953\n",
            "epoch 28 step 38 loss 1.5291048288345337\n",
            "epoch 28 step 39 loss 1.484232783317566\n",
            "epoch 28 step 40 loss 1.5047458410263062 test_accuracy 74.60000610351562 train_accuracy 95.3125\n",
            "epoch 28 step 41 loss 1.5111335515975952\n",
            "epoch 28 step 42 loss 1.5060781240463257\n",
            "epoch 28 step 43 loss 1.536867380142212\n",
            "epoch 28 step 44 loss 1.5323184728622437\n",
            "epoch 28 step 45 loss 1.509796380996704\n",
            "epoch 28 step 46 loss 1.493675708770752\n",
            "epoch 28 step 47 loss 1.5072178840637207\n",
            "epoch 28 step 48 loss 1.525201678276062\n",
            "epoch 28 step 49 loss 1.5058261156082153\n",
            "epoch 28 step 50 loss 1.5103975534439087\n",
            "epoch 28 step 51 loss 1.5035182237625122\n",
            "epoch 28 step 52 loss 1.5232013463974\n",
            "epoch 28 step 53 loss 1.532812237739563\n",
            "epoch 28 step 54 loss 1.4856088161468506\n",
            "epoch 28 step 55 loss 1.516831398010254\n",
            "epoch 28 step 56 loss 1.5135891437530518\n",
            "epoch 28 step 57 loss 1.5146019458770752\n",
            "epoch 28 step 58 loss 1.5668482780456543\n",
            "epoch 28 step 59 loss 1.4788857698440552\n",
            "epoch 28 step 60 loss 1.5300508737564087 test_accuracy 74.4000015258789 train_accuracy 95.3125\n",
            "epoch 28 step 61 loss 1.5081788301467896\n",
            "epoch 28 step 62 loss 1.4884073734283447\n",
            "epoch 28 step 63 loss 1.4924854040145874\n",
            "epoch 28 step 64 loss 1.4655133485794067\n",
            "epoch 28 step 65 loss 1.5006970167160034\n",
            "epoch 28 step 66 loss 1.4987857341766357\n",
            "epoch 28 step 67 loss 1.5350743532180786\n",
            "epoch 28 step 68 loss 1.5410242080688477\n",
            "epoch 28 step 69 loss 1.5031287670135498\n",
            "epoch 28 step 70 loss 1.524923324584961\n",
            "epoch 28 step 71 loss 1.5077811479568481\n",
            "epoch 28 step 72 loss 1.5426849126815796\n",
            "epoch 28 step 73 loss 1.503882646560669\n",
            "epoch 28 step 74 loss 1.505239486694336\n",
            "epoch 28 step 75 loss 1.5028499364852905\n",
            "epoch 28 step 76 loss 1.5010426044464111\n",
            "epoch 28 step 77 loss 1.5195807218551636\n",
            "epoch 28 step 78 loss 1.5189781188964844\n",
            "epoch 28 step 79 loss 1.528193712234497\n",
            "epoch 28 step 80 loss 1.5459872484207153 test_accuracy 74.60000610351562 train_accuracy 96.875\n",
            "epoch 28 step 81 loss 1.51639723777771\n",
            "epoch 28 step 82 loss 1.5122357606887817\n",
            "epoch 28 step 83 loss 1.4961564540863037\n",
            "epoch 28 step 84 loss 1.5169857740402222\n",
            "epoch 28 step 85 loss 1.5106250047683716\n",
            "epoch 28 step 86 loss 1.5447289943695068\n",
            "epoch 28 step 87 loss 1.5058495998382568\n",
            "epoch 28 step 88 loss 1.5014992952346802\n",
            "epoch 28 step 89 loss 1.5234090089797974\n",
            "epoch 28 step 90 loss 1.5013700723648071\n",
            "epoch 28 step 91 loss 1.5001819133758545\n",
            "epoch 28 step 92 loss 1.5108271837234497\n",
            "epoch 28 step 93 loss 1.5195364952087402\n",
            "epoch 28 step 94 loss 1.5090621709823608\n",
            "epoch 28 step 95 loss 1.4871882200241089\n",
            "epoch 28 step 96 loss 1.497084617614746\n",
            "epoch 28 step 97 loss 1.5171864032745361\n",
            "epoch 28 step 98 loss 1.5087354183197021\n",
            "epoch 28 step 99 loss 1.5290896892547607\n",
            "epoch 28 step 100 loss 1.5308698415756226 test_accuracy 74.20000457763672 train_accuracy 93.75\n",
            "epoch 28 step 101 loss 1.4955934286117554\n",
            "epoch 28 step 102 loss 1.537405014038086\n",
            "epoch 28 step 103 loss 1.5385531187057495\n",
            "epoch 28 step 104 loss 1.5039781332015991\n",
            "epoch 28 step 105 loss 1.4959681034088135\n",
            "epoch 28 step 106 loss 1.5105257034301758\n",
            "epoch 28 step 107 loss 1.5313725471496582\n",
            "epoch 28 step 108 loss 1.5197328329086304\n",
            "epoch 28 step 109 loss 1.5295253992080688\n",
            "epoch 28 step 110 loss 1.5078504085540771\n",
            "epoch 28 step 111 loss 1.5237312316894531\n",
            "epoch 28 step 112 loss 1.5175015926361084\n",
            "epoch 28 step 113 loss 1.527753472328186\n",
            "epoch 28 step 114 loss 1.4865224361419678\n",
            "epoch 28 step 115 loss 1.5154821872711182\n",
            "epoch 28 step 116 loss 1.5114498138427734\n",
            "epoch 28 step 117 loss 1.5159108638763428\n",
            "epoch 28 step 118 loss 1.4929465055465698\n",
            "epoch 28 step 119 loss 1.5138461589813232\n",
            "epoch 28 step 120 loss 1.5083489418029785 test_accuracy 74.4000015258789 train_accuracy 96.09375\n",
            "epoch 28 step 121 loss 1.5015090703964233\n",
            "epoch 28 step 122 loss 1.5127747058868408\n",
            "epoch 28 step 123 loss 1.5052357912063599\n",
            "epoch 28 step 124 loss 1.5430974960327148\n",
            "epoch 28 step 125 loss 1.502366065979004\n",
            "epoch 28 step 126 loss 1.535320520401001\n",
            "epoch 28 step 127 loss 1.5248631238937378\n",
            "epoch 28 step 128 loss 1.5116363763809204\n",
            "epoch 28 step 129 loss 1.5108165740966797\n",
            "epoch 28 step 130 loss 1.5049339532852173\n",
            "epoch 28 step 131 loss 1.5126627683639526\n",
            "epoch 28 step 132 loss 1.4891793727874756\n",
            "epoch 28 step 133 loss 1.493204116821289\n",
            "epoch 28 step 134 loss 1.5257408618927002\n",
            "epoch 28 step 135 loss 1.4896254539489746\n",
            "epoch 28 step 136 loss 1.5258153676986694\n",
            "epoch 28 step 137 loss 1.518250823020935\n",
            "epoch 28 step 138 loss 1.4937193393707275\n",
            "epoch 28 step 139 loss 1.5345706939697266\n",
            "epoch 28 step 140 loss 1.5100595951080322 test_accuracy 74.80000305175781 train_accuracy 94.53125\n",
            "epoch 28 step 141 loss 1.5200003385543823\n",
            "epoch 28 step 142 loss 1.4987690448760986\n",
            "epoch 28 step 143 loss 1.5464638471603394\n",
            "epoch 28 step 144 loss 1.4910210371017456\n",
            "epoch 28 step 145 loss 1.517810583114624\n",
            "epoch 28 step 146 loss 1.5281670093536377\n",
            "epoch 28 step 147 loss 1.4975833892822266\n",
            "epoch 28 step 148 loss 1.5091313123703003\n",
            "epoch 28 step 149 loss 1.5152136087417603\n",
            "epoch 28 step 150 loss 1.505090594291687\n",
            "epoch 28 step 151 loss 1.4972336292266846\n",
            "epoch 28 step 152 loss 1.5052059888839722\n",
            "epoch 28 step 153 loss 1.5166515111923218\n",
            "epoch 28 step 154 loss 1.5058811902999878\n",
            "epoch 28 step 155 loss 1.5198488235473633\n",
            "epoch 28 step 156 loss 1.4978381395339966\n",
            "epoch 28 step 157 loss 1.4968630075454712\n",
            "epoch 28 step 158 loss 1.5015747547149658\n",
            "epoch 28 step 159 loss 1.509207010269165\n",
            "epoch 28 step 160 loss 1.5163873434066772 test_accuracy 74.4000015258789 train_accuracy 96.875\n",
            "epoch 28 step 161 loss 1.5041347742080688\n",
            "epoch 28 step 162 loss 1.5125988721847534\n",
            "epoch 28 step 163 loss 1.4936132431030273\n",
            "epoch 28 step 164 loss 1.5011322498321533\n",
            "epoch 28 step 165 loss 1.499305009841919\n",
            "epoch 28 step 166 loss 1.543558955192566\n",
            "epoch 28 step 167 loss 1.4844393730163574\n",
            "epoch 28 step 168 loss 1.5222201347351074\n",
            "epoch 28 step 169 loss 1.510362148284912\n",
            "epoch 28 step 170 loss 1.4997882843017578\n",
            "epoch 28 step 171 loss 1.5162476301193237\n",
            "epoch 28 step 172 loss 1.5326690673828125\n",
            "epoch 28 step 173 loss 1.5479211807250977\n",
            "epoch 28 step 174 loss 1.5312141180038452\n",
            "epoch 28 step 175 loss 1.5087631940841675\n",
            "epoch 28 step 176 loss 1.490241289138794\n",
            "epoch 28 step 177 loss 1.5101208686828613\n",
            "epoch 28 step 178 loss 1.532175064086914\n",
            "epoch 28 step 179 loss 1.5108330249786377\n",
            "epoch 28 step 180 loss 1.4876819849014282 test_accuracy 74.60000610351562 train_accuracy 98.4375\n",
            "epoch 28 step 181 loss 1.5042513608932495\n",
            "epoch 28 step 182 loss 1.5035457611083984\n",
            "epoch 28 step 183 loss 1.5334255695343018\n",
            "epoch 28 step 184 loss 1.530103325843811\n",
            "epoch 28 step 185 loss 1.4857149124145508\n",
            "epoch 29 step 0 loss 1.476940631866455 test_accuracy 74.4000015258789 train_accuracy 98.4375\n",
            "epoch 29 step 1 loss 1.4973585605621338\n",
            "epoch 29 step 2 loss 1.4901660680770874\n",
            "epoch 29 step 3 loss 1.5318580865859985\n",
            "epoch 29 step 4 loss 1.5160019397735596\n",
            "epoch 29 step 5 loss 1.5036277770996094\n",
            "epoch 29 step 6 loss 1.5096544027328491\n",
            "epoch 29 step 7 loss 1.5085281133651733\n",
            "epoch 29 step 8 loss 1.5179262161254883\n",
            "epoch 29 step 9 loss 1.4998083114624023\n",
            "epoch 29 step 10 loss 1.5155835151672363\n",
            "epoch 29 step 11 loss 1.510813593864441\n",
            "epoch 29 step 12 loss 1.4940111637115479\n",
            "epoch 29 step 13 loss 1.5126800537109375\n",
            "epoch 29 step 14 loss 1.517707347869873\n",
            "epoch 29 step 15 loss 1.4988101720809937\n",
            "epoch 29 step 16 loss 1.5429251194000244\n",
            "epoch 29 step 17 loss 1.4925529956817627\n",
            "epoch 29 step 18 loss 1.507992148399353\n",
            "epoch 29 step 19 loss 1.5141388177871704\n",
            "epoch 29 step 20 loss 1.5367250442504883 test_accuracy 75.0 train_accuracy 96.875\n",
            "epoch 29 step 21 loss 1.5048654079437256\n",
            "epoch 29 step 22 loss 1.501169204711914\n",
            "epoch 29 step 23 loss 1.5522547960281372\n",
            "epoch 29 step 24 loss 1.497758150100708\n",
            "epoch 29 step 25 loss 1.5124614238739014\n",
            "epoch 29 step 26 loss 1.4857157468795776\n",
            "epoch 29 step 27 loss 1.5046720504760742\n",
            "epoch 29 step 28 loss 1.5166865587234497\n",
            "epoch 29 step 29 loss 1.5326898097991943\n",
            "epoch 29 step 30 loss 1.5161374807357788\n",
            "epoch 29 step 31 loss 1.5212225914001465\n",
            "epoch 29 step 32 loss 1.5028889179229736\n",
            "epoch 29 step 33 loss 1.4997750520706177\n",
            "epoch 29 step 34 loss 1.485701084136963\n",
            "epoch 29 step 35 loss 1.5191677808761597\n",
            "epoch 29 step 36 loss 1.5104219913482666\n",
            "epoch 29 step 37 loss 1.5043429136276245\n",
            "epoch 29 step 38 loss 1.4922674894332886\n",
            "epoch 29 step 39 loss 1.51195228099823\n",
            "epoch 29 step 40 loss 1.4813278913497925 test_accuracy 74.60000610351562 train_accuracy 96.09375\n",
            "epoch 29 step 41 loss 1.5253421068191528\n",
            "epoch 29 step 42 loss 1.5031969547271729\n",
            "epoch 29 step 43 loss 1.5088398456573486\n",
            "epoch 29 step 44 loss 1.5264798402786255\n",
            "epoch 29 step 45 loss 1.5316749811172485\n",
            "epoch 29 step 46 loss 1.5017778873443604\n",
            "epoch 29 step 47 loss 1.494236946105957\n",
            "epoch 29 step 48 loss 1.519489049911499\n",
            "epoch 29 step 49 loss 1.5000993013381958\n",
            "epoch 29 step 50 loss 1.5139065980911255\n",
            "epoch 29 step 51 loss 1.5144864320755005\n",
            "epoch 29 step 52 loss 1.496598482131958\n",
            "epoch 29 step 53 loss 1.4830563068389893\n",
            "epoch 29 step 54 loss 1.51430082321167\n",
            "epoch 29 step 55 loss 1.5151900053024292\n",
            "epoch 29 step 56 loss 1.5153716802597046\n",
            "epoch 29 step 57 loss 1.5188391208648682\n",
            "epoch 29 step 58 loss 1.51115882396698\n",
            "epoch 29 step 59 loss 1.5061792135238647\n",
            "epoch 29 step 60 loss 1.5446014404296875 test_accuracy 74.4000015258789 train_accuracy 99.21875\n",
            "epoch 29 step 61 loss 1.5053341388702393\n",
            "epoch 29 step 62 loss 1.4703102111816406\n",
            "epoch 29 step 63 loss 1.5115188360214233\n",
            "epoch 29 step 64 loss 1.519882082939148\n",
            "epoch 29 step 65 loss 1.493640661239624\n",
            "epoch 29 step 66 loss 1.5189013481140137\n",
            "epoch 29 step 67 loss 1.5249803066253662\n",
            "epoch 29 step 68 loss 1.4996514320373535\n",
            "epoch 29 step 69 loss 1.4998016357421875\n",
            "epoch 29 step 70 loss 1.5271294116973877\n",
            "epoch 29 step 71 loss 1.5265214443206787\n",
            "epoch 29 step 72 loss 1.531051516532898\n",
            "epoch 29 step 73 loss 1.5498783588409424\n",
            "epoch 29 step 74 loss 1.4794453382492065\n",
            "epoch 29 step 75 loss 1.559973955154419\n",
            "epoch 29 step 76 loss 1.4964087009429932\n",
            "epoch 29 step 77 loss 1.5225038528442383\n",
            "epoch 29 step 78 loss 1.49281644821167\n",
            "epoch 29 step 79 loss 1.4939825534820557\n",
            "epoch 29 step 80 loss 1.4886057376861572 test_accuracy 75.0 train_accuracy 96.09375\n",
            "epoch 29 step 81 loss 1.5389899015426636\n",
            "epoch 29 step 82 loss 1.4772670269012451\n",
            "epoch 29 step 83 loss 1.5417490005493164\n",
            "epoch 29 step 84 loss 1.5118352174758911\n",
            "epoch 29 step 85 loss 1.5190863609313965\n",
            "epoch 29 step 86 loss 1.4918711185455322\n",
            "epoch 29 step 87 loss 1.49783456325531\n",
            "epoch 29 step 88 loss 1.489091157913208\n",
            "epoch 29 step 89 loss 1.509384036064148\n",
            "epoch 29 step 90 loss 1.5131185054779053\n",
            "epoch 29 step 91 loss 1.4949359893798828\n",
            "epoch 29 step 92 loss 1.521864652633667\n",
            "epoch 29 step 93 loss 1.491143822669983\n",
            "epoch 29 step 94 loss 1.5157712697982788\n",
            "epoch 29 step 95 loss 1.5310934782028198\n",
            "epoch 29 step 96 loss 1.5377211570739746\n",
            "epoch 29 step 97 loss 1.5643136501312256\n",
            "epoch 29 step 98 loss 1.512609601020813\n",
            "epoch 29 step 99 loss 1.5167242288589478\n",
            "epoch 29 step 100 loss 1.5094540119171143 test_accuracy 75.4000015258789 train_accuracy 96.875\n",
            "epoch 29 step 101 loss 1.5131386518478394\n",
            "epoch 29 step 102 loss 1.4961179494857788\n",
            "epoch 29 step 103 loss 1.502328872680664\n",
            "epoch 29 step 104 loss 1.5065690279006958\n",
            "epoch 29 step 105 loss 1.4937388896942139\n",
            "epoch 29 step 106 loss 1.514536738395691\n",
            "epoch 29 step 107 loss 1.4920967817306519\n",
            "epoch 29 step 108 loss 1.5004113912582397\n",
            "epoch 29 step 109 loss 1.481589436531067\n",
            "epoch 29 step 110 loss 1.5272552967071533\n",
            "epoch 29 step 111 loss 1.5267049074172974\n",
            "epoch 29 step 112 loss 1.4867082834243774\n",
            "epoch 29 step 113 loss 1.5152868032455444\n",
            "epoch 29 step 114 loss 1.522639513015747\n",
            "epoch 29 step 115 loss 1.519075870513916\n",
            "epoch 29 step 116 loss 1.4789015054702759\n",
            "epoch 29 step 117 loss 1.4914830923080444\n",
            "epoch 29 step 118 loss 1.4914295673370361\n",
            "epoch 29 step 119 loss 1.5192246437072754\n",
            "epoch 29 step 120 loss 1.5048577785491943 test_accuracy 74.80000305175781 train_accuracy 94.53125\n",
            "epoch 29 step 121 loss 1.5475586652755737\n",
            "epoch 29 step 122 loss 1.5216493606567383\n",
            "epoch 29 step 123 loss 1.4845770597457886\n",
            "epoch 29 step 124 loss 1.5288928747177124\n",
            "epoch 29 step 125 loss 1.528538465499878\n",
            "epoch 29 step 126 loss 1.5093125104904175\n",
            "epoch 29 step 127 loss 1.4978262186050415\n",
            "epoch 29 step 128 loss 1.499928593635559\n",
            "epoch 29 step 129 loss 1.4864048957824707\n",
            "epoch 29 step 130 loss 1.5279591083526611\n",
            "epoch 29 step 131 loss 1.52556574344635\n",
            "epoch 29 step 132 loss 1.5217838287353516\n",
            "epoch 29 step 133 loss 1.4947758913040161\n",
            "epoch 29 step 134 loss 1.5013313293457031\n",
            "epoch 29 step 135 loss 1.5125147104263306\n",
            "epoch 29 step 136 loss 1.5375995635986328\n",
            "epoch 29 step 137 loss 1.5103199481964111\n",
            "epoch 29 step 138 loss 1.5285824537277222\n",
            "epoch 29 step 139 loss 1.5172020196914673\n",
            "epoch 29 step 140 loss 1.511655330657959 test_accuracy 74.80000305175781 train_accuracy 97.65625\n",
            "epoch 29 step 141 loss 1.532982349395752\n",
            "epoch 29 step 142 loss 1.4928728342056274\n",
            "epoch 29 step 143 loss 1.5079666376113892\n",
            "epoch 29 step 144 loss 1.517105221748352\n",
            "epoch 29 step 145 loss 1.4773414134979248\n",
            "epoch 29 step 146 loss 1.5417912006378174\n",
            "epoch 29 step 147 loss 1.520979881286621\n",
            "epoch 29 step 148 loss 1.470633864402771\n",
            "epoch 29 step 149 loss 1.4825375080108643\n",
            "epoch 29 step 150 loss 1.4730980396270752\n",
            "epoch 29 step 151 loss 1.4924355745315552\n",
            "epoch 29 step 152 loss 1.5013774633407593\n",
            "epoch 29 step 153 loss 1.4983958005905151\n",
            "epoch 29 step 154 loss 1.5151102542877197\n",
            "epoch 29 step 155 loss 1.5311883687973022\n",
            "epoch 29 step 156 loss 1.48284912109375\n",
            "epoch 29 step 157 loss 1.503656268119812\n",
            "epoch 29 step 158 loss 1.501628041267395\n",
            "epoch 29 step 159 loss 1.506477952003479\n",
            "epoch 29 step 160 loss 1.5100194215774536 test_accuracy 75.20000457763672 train_accuracy 98.4375\n",
            "epoch 29 step 161 loss 1.5297716856002808\n",
            "epoch 29 step 162 loss 1.494146704673767\n",
            "epoch 29 step 163 loss 1.507169485092163\n",
            "epoch 29 step 164 loss 1.5312309265136719\n",
            "epoch 29 step 165 loss 1.498551607131958\n",
            "epoch 29 step 166 loss 1.5106842517852783\n",
            "epoch 29 step 167 loss 1.5138604640960693\n",
            "epoch 29 step 168 loss 1.5201482772827148\n",
            "epoch 29 step 169 loss 1.5261770486831665\n",
            "epoch 29 step 170 loss 1.5098339319229126\n",
            "epoch 29 step 171 loss 1.5031177997589111\n",
            "epoch 29 step 172 loss 1.5361429452896118\n",
            "epoch 29 step 173 loss 1.5753631591796875\n",
            "epoch 29 step 174 loss 1.4708480834960938\n",
            "epoch 29 step 175 loss 1.4937859773635864\n",
            "epoch 29 step 176 loss 1.4924975633621216\n",
            "epoch 29 step 177 loss 1.5070215463638306\n",
            "epoch 29 step 178 loss 1.5317113399505615\n",
            "epoch 29 step 179 loss 1.4967865943908691\n",
            "epoch 29 step 180 loss 1.5301367044448853 test_accuracy 74.60000610351562 train_accuracy 94.53125\n",
            "epoch 29 step 181 loss 1.5239194631576538\n",
            "epoch 29 step 182 loss 1.5327622890472412\n",
            "epoch 29 step 183 loss 1.5190914869308472\n",
            "epoch 29 step 184 loss 1.5072574615478516\n",
            "epoch 29 step 185 loss 1.489052653312683\n",
            "epoch 30 step 0 loss 1.5350806713104248 test_accuracy 74.60000610351562 train_accuracy 97.65625\n",
            "epoch 30 step 1 loss 1.5474655628204346\n",
            "epoch 30 step 2 loss 1.5222313404083252\n",
            "epoch 30 step 3 loss 1.4971427917480469\n",
            "epoch 30 step 4 loss 1.522696852684021\n",
            "epoch 30 step 5 loss 1.4834930896759033\n",
            "epoch 30 step 6 loss 1.5138341188430786\n",
            "epoch 30 step 7 loss 1.506131649017334\n",
            "epoch 30 step 8 loss 1.5255975723266602\n",
            "epoch 30 step 9 loss 1.506857991218567\n",
            "epoch 30 step 10 loss 1.4990079402923584\n",
            "epoch 30 step 11 loss 1.5121291875839233\n",
            "epoch 30 step 12 loss 1.4915255308151245\n",
            "epoch 30 step 13 loss 1.5064997673034668\n",
            "epoch 30 step 14 loss 1.4933416843414307\n",
            "epoch 30 step 15 loss 1.4961391687393188\n",
            "epoch 30 step 16 loss 1.517863154411316\n",
            "epoch 30 step 17 loss 1.5057700872421265\n",
            "epoch 30 step 18 loss 1.497115969657898\n",
            "epoch 30 step 19 loss 1.5160547494888306\n",
            "epoch 30 step 20 loss 1.5196887254714966 test_accuracy 74.80000305175781 train_accuracy 95.3125\n",
            "epoch 30 step 21 loss 1.5067524909973145\n",
            "epoch 30 step 22 loss 1.5341966152191162\n",
            "epoch 30 step 23 loss 1.5277637243270874\n",
            "epoch 30 step 24 loss 1.4927138090133667\n",
            "epoch 30 step 25 loss 1.490616798400879\n",
            "epoch 30 step 26 loss 1.493975043296814\n",
            "epoch 30 step 27 loss 1.5024735927581787\n",
            "epoch 30 step 28 loss 1.4951212406158447\n",
            "epoch 30 step 29 loss 1.462438702583313\n",
            "epoch 30 step 30 loss 1.4938230514526367\n",
            "epoch 30 step 31 loss 1.528763771057129\n",
            "epoch 30 step 32 loss 1.5358598232269287\n",
            "epoch 30 step 33 loss 1.4849528074264526\n",
            "epoch 30 step 34 loss 1.5091012716293335\n",
            "epoch 30 step 35 loss 1.5094151496887207\n",
            "epoch 30 step 36 loss 1.5001635551452637\n",
            "epoch 30 step 37 loss 1.4962565898895264\n",
            "epoch 30 step 38 loss 1.5050890445709229\n",
            "epoch 30 step 39 loss 1.5013254880905151\n",
            "epoch 30 step 40 loss 1.4924356937408447 test_accuracy 74.80000305175781 train_accuracy 98.4375\n",
            "epoch 30 step 41 loss 1.5418545007705688\n",
            "epoch 30 step 42 loss 1.5238311290740967\n",
            "epoch 30 step 43 loss 1.4903388023376465\n",
            "epoch 30 step 44 loss 1.5323913097381592\n",
            "epoch 30 step 45 loss 1.5092507600784302\n",
            "epoch 30 step 46 loss 1.4733606576919556\n",
            "epoch 30 step 47 loss 1.5176869630813599\n",
            "epoch 30 step 48 loss 1.520835041999817\n",
            "epoch 30 step 49 loss 1.4950705766677856\n",
            "epoch 30 step 50 loss 1.5180109739303589\n",
            "epoch 30 step 51 loss 1.5215893983840942\n",
            "epoch 30 step 52 loss 1.5029841661453247\n",
            "epoch 30 step 53 loss 1.497818112373352\n",
            "epoch 30 step 54 loss 1.4997273683547974\n",
            "epoch 30 step 55 loss 1.5036462545394897\n",
            "epoch 30 step 56 loss 1.5045989751815796\n",
            "epoch 30 step 57 loss 1.4909287691116333\n",
            "epoch 30 step 58 loss 1.4901559352874756\n",
            "epoch 30 step 59 loss 1.4842036962509155\n",
            "epoch 30 step 60 loss 1.5244250297546387 test_accuracy 75.20000457763672 train_accuracy 92.96875\n",
            "epoch 30 step 61 loss 1.5235673189163208\n",
            "epoch 30 step 62 loss 1.522546648979187\n",
            "epoch 30 step 63 loss 1.5237804651260376\n",
            "epoch 30 step 64 loss 1.5111632347106934\n",
            "epoch 30 step 65 loss 1.4980491399765015\n",
            "epoch 30 step 66 loss 1.500138521194458\n",
            "epoch 30 step 67 loss 1.500062108039856\n",
            "epoch 30 step 68 loss 1.5312745571136475\n",
            "epoch 30 step 69 loss 1.5322459936141968\n",
            "epoch 30 step 70 loss 1.5401499271392822\n",
            "epoch 30 step 71 loss 1.5177714824676514\n",
            "epoch 30 step 72 loss 1.5082850456237793\n",
            "epoch 30 step 73 loss 1.490354061126709\n",
            "epoch 30 step 74 loss 1.4966086149215698\n",
            "epoch 30 step 75 loss 1.523451566696167\n",
            "epoch 30 step 76 loss 1.5015243291854858\n",
            "epoch 30 step 77 loss 1.4978281259536743\n",
            "epoch 30 step 78 loss 1.4968109130859375\n",
            "epoch 30 step 79 loss 1.5176496505737305\n",
            "epoch 30 step 80 loss 1.5372503995895386 test_accuracy 74.80000305175781 train_accuracy 98.4375\n",
            "epoch 30 step 81 loss 1.546893835067749\n",
            "epoch 30 step 82 loss 1.51272451877594\n",
            "epoch 30 step 83 loss 1.4919342994689941\n",
            "epoch 30 step 84 loss 1.4954862594604492\n",
            "epoch 30 step 85 loss 1.5028836727142334\n",
            "epoch 30 step 86 loss 1.4878050088882446\n",
            "epoch 30 step 87 loss 1.5019692182540894\n",
            "epoch 30 step 88 loss 1.5367437601089478\n",
            "epoch 30 step 89 loss 1.4936672449111938\n",
            "epoch 30 step 90 loss 1.5243537425994873\n",
            "epoch 30 step 91 loss 1.5272295475006104\n",
            "epoch 30 step 92 loss 1.5299309492111206\n",
            "epoch 30 step 93 loss 1.518507480621338\n",
            "epoch 30 step 94 loss 1.5114144086837769\n",
            "epoch 30 step 95 loss 1.50679612159729\n",
            "epoch 30 step 96 loss 1.543406367301941\n",
            "epoch 30 step 97 loss 1.525374174118042\n",
            "epoch 30 step 98 loss 1.5170745849609375\n",
            "epoch 30 step 99 loss 1.544237494468689\n",
            "epoch 30 step 100 loss 1.5111773014068604 test_accuracy 75.0 train_accuracy 92.1875\n",
            "epoch 30 step 101 loss 1.490415334701538\n",
            "epoch 30 step 102 loss 1.4944703578948975\n",
            "epoch 30 step 103 loss 1.5119792222976685\n",
            "epoch 30 step 104 loss 1.4892666339874268\n",
            "epoch 30 step 105 loss 1.503794550895691\n",
            "epoch 30 step 106 loss 1.509738564491272\n",
            "epoch 30 step 107 loss 1.5371639728546143\n",
            "epoch 30 step 108 loss 1.5023884773254395\n",
            "epoch 30 step 109 loss 1.5251264572143555\n",
            "epoch 30 step 110 loss 1.5115540027618408\n",
            "epoch 30 step 111 loss 1.5007615089416504\n",
            "epoch 30 step 112 loss 1.5433541536331177\n",
            "epoch 30 step 113 loss 1.5285435914993286\n",
            "epoch 30 step 114 loss 1.5205808877944946\n",
            "epoch 30 step 115 loss 1.5130292177200317\n",
            "epoch 30 step 116 loss 1.478421926498413\n",
            "epoch 30 step 117 loss 1.4986844062805176\n",
            "epoch 30 step 118 loss 1.5092459917068481\n",
            "epoch 30 step 119 loss 1.5300967693328857\n",
            "epoch 30 step 120 loss 1.4964945316314697 test_accuracy 74.20000457763672 train_accuracy 95.3125\n",
            "epoch 30 step 121 loss 1.4973911046981812\n",
            "epoch 30 step 122 loss 1.5164713859558105\n",
            "epoch 30 step 123 loss 1.5251163244247437\n",
            "epoch 30 step 124 loss 1.5014244318008423\n",
            "epoch 30 step 125 loss 1.5084127187728882\n",
            "epoch 30 step 126 loss 1.524612307548523\n",
            "epoch 30 step 127 loss 1.5418758392333984\n",
            "epoch 30 step 128 loss 1.491097092628479\n",
            "epoch 30 step 129 loss 1.4930007457733154\n",
            "epoch 30 step 130 loss 1.5149734020233154\n",
            "epoch 30 step 131 loss 1.4817403554916382\n",
            "epoch 30 step 132 loss 1.5053865909576416\n",
            "epoch 30 step 133 loss 1.4728156328201294\n",
            "epoch 30 step 134 loss 1.5092661380767822\n",
            "epoch 30 step 135 loss 1.497635841369629\n",
            "epoch 30 step 136 loss 1.4890034198760986\n",
            "epoch 30 step 137 loss 1.5085936784744263\n",
            "epoch 30 step 138 loss 1.55173921585083\n",
            "epoch 30 step 139 loss 1.50224769115448\n",
            "epoch 30 step 140 loss 1.5191482305526733 test_accuracy 74.4000015258789 train_accuracy 91.40625\n",
            "epoch 30 step 141 loss 1.4970893859863281\n",
            "epoch 30 step 142 loss 1.5201114416122437\n",
            "epoch 30 step 143 loss 1.528969645500183\n",
            "epoch 30 step 144 loss 1.5077719688415527\n",
            "epoch 30 step 145 loss 1.5048785209655762\n",
            "epoch 30 step 146 loss 1.5392718315124512\n",
            "epoch 30 step 147 loss 1.5000401735305786\n",
            "epoch 30 step 148 loss 1.5249983072280884\n",
            "epoch 30 step 149 loss 1.5448939800262451\n",
            "epoch 30 step 150 loss 1.524330973625183\n",
            "epoch 30 step 151 loss 1.523425579071045\n",
            "epoch 30 step 152 loss 1.5242505073547363\n",
            "epoch 30 step 153 loss 1.4752771854400635\n",
            "epoch 30 step 154 loss 1.5029773712158203\n",
            "epoch 30 step 155 loss 1.5349419116973877\n",
            "epoch 30 step 156 loss 1.5078309774398804\n",
            "epoch 30 step 157 loss 1.5060296058654785\n",
            "epoch 30 step 158 loss 1.4913692474365234\n",
            "epoch 30 step 159 loss 1.4924190044403076\n",
            "epoch 30 step 160 loss 1.5241652727127075 test_accuracy 74.80000305175781 train_accuracy 96.09375\n",
            "epoch 30 step 161 loss 1.5256526470184326\n",
            "epoch 30 step 162 loss 1.5183626413345337\n",
            "epoch 30 step 163 loss 1.5204434394836426\n",
            "epoch 30 step 164 loss 1.4943634271621704\n",
            "epoch 30 step 165 loss 1.5221891403198242\n",
            "epoch 30 step 166 loss 1.5354712009429932\n",
            "epoch 30 step 167 loss 1.5178114175796509\n",
            "epoch 30 step 168 loss 1.5011484622955322\n",
            "epoch 30 step 169 loss 1.5087171792984009\n",
            "epoch 30 step 170 loss 1.5151336193084717\n",
            "epoch 30 step 171 loss 1.5231451988220215\n",
            "epoch 30 step 172 loss 1.5110515356063843\n",
            "epoch 30 step 173 loss 1.52870774269104\n",
            "epoch 30 step 174 loss 1.5089670419692993\n",
            "epoch 30 step 175 loss 1.510416030883789\n",
            "epoch 30 step 176 loss 1.506432056427002\n",
            "epoch 30 step 177 loss 1.473299264907837\n",
            "epoch 30 step 178 loss 1.5139538049697876\n",
            "epoch 30 step 179 loss 1.5148608684539795\n",
            "epoch 30 step 180 loss 1.485899806022644 test_accuracy 74.80000305175781 train_accuracy 96.875\n",
            "epoch 30 step 181 loss 1.4994293451309204\n",
            "epoch 30 step 182 loss 1.5053352117538452\n",
            "epoch 30 step 183 loss 1.5407471656799316\n",
            "epoch 30 step 184 loss 1.5405219793319702\n",
            "epoch 30 step 185 loss 1.4627084732055664\n",
            "epoch 31 step 0 loss 1.474338412284851 test_accuracy 74.80000305175781 train_accuracy 98.4375\n",
            "epoch 31 step 1 loss 1.5263409614562988\n",
            "epoch 31 step 2 loss 1.5110900402069092\n",
            "epoch 31 step 3 loss 1.5107381343841553\n",
            "epoch 31 step 4 loss 1.4814356565475464\n",
            "epoch 31 step 5 loss 1.5358805656433105\n",
            "epoch 31 step 6 loss 1.4909863471984863\n",
            "epoch 31 step 7 loss 1.4750404357910156\n",
            "epoch 31 step 8 loss 1.5169209241867065\n",
            "epoch 31 step 9 loss 1.518759846687317\n",
            "epoch 31 step 10 loss 1.5174996852874756\n",
            "epoch 31 step 11 loss 1.511481761932373\n",
            "epoch 31 step 12 loss 1.507897138595581\n",
            "epoch 31 step 13 loss 1.4897921085357666\n",
            "epoch 31 step 14 loss 1.5077277421951294\n",
            "epoch 31 step 15 loss 1.5527820587158203\n",
            "epoch 31 step 16 loss 1.5001754760742188\n",
            "epoch 31 step 17 loss 1.52885901927948\n",
            "epoch 31 step 18 loss 1.5387399196624756\n",
            "epoch 31 step 19 loss 1.5027916431427002\n",
            "epoch 31 step 20 loss 1.4858477115631104 test_accuracy 74.60000610351562 train_accuracy 96.875\n",
            "epoch 31 step 21 loss 1.4977562427520752\n",
            "epoch 31 step 22 loss 1.5061568021774292\n",
            "epoch 31 step 23 loss 1.4996074438095093\n",
            "epoch 31 step 24 loss 1.5389628410339355\n",
            "epoch 31 step 25 loss 1.5032135248184204\n",
            "epoch 31 step 26 loss 1.5102906227111816\n",
            "epoch 31 step 27 loss 1.5379321575164795\n",
            "epoch 31 step 28 loss 1.5042723417282104\n",
            "epoch 31 step 29 loss 1.5215591192245483\n",
            "epoch 31 step 30 loss 1.5431429147720337\n",
            "epoch 31 step 31 loss 1.5232198238372803\n",
            "epoch 31 step 32 loss 1.5129666328430176\n",
            "epoch 31 step 33 loss 1.5047472715377808\n",
            "epoch 31 step 34 loss 1.5039278268814087\n",
            "epoch 31 step 35 loss 1.4961943626403809\n",
            "epoch 31 step 36 loss 1.490820050239563\n",
            "epoch 31 step 37 loss 1.4916919469833374\n",
            "epoch 31 step 38 loss 1.497576117515564\n",
            "epoch 31 step 39 loss 1.4925812482833862\n",
            "epoch 31 step 40 loss 1.5048869848251343 test_accuracy 74.80000305175781 train_accuracy 95.3125\n",
            "epoch 31 step 41 loss 1.5029003620147705\n",
            "epoch 31 step 42 loss 1.495193362236023\n",
            "epoch 31 step 43 loss 1.5395928621292114\n",
            "epoch 31 step 44 loss 1.5063929557800293\n",
            "epoch 31 step 45 loss 1.50168776512146\n",
            "epoch 31 step 46 loss 1.4935297966003418\n",
            "epoch 31 step 47 loss 1.5134735107421875\n",
            "epoch 31 step 48 loss 1.4971171617507935\n",
            "epoch 31 step 49 loss 1.5235263109207153\n",
            "epoch 31 step 50 loss 1.4990756511688232\n",
            "epoch 31 step 51 loss 1.5274009704589844\n",
            "epoch 31 step 52 loss 1.533632755279541\n",
            "epoch 31 step 53 loss 1.5037504434585571\n",
            "epoch 31 step 54 loss 1.5056946277618408\n",
            "epoch 31 step 55 loss 1.4840201139450073\n",
            "epoch 31 step 56 loss 1.4943329095840454\n",
            "epoch 31 step 57 loss 1.5215414762496948\n",
            "epoch 31 step 58 loss 1.535003662109375\n",
            "epoch 31 step 59 loss 1.4945476055145264\n",
            "epoch 31 step 60 loss 1.4976345300674438 test_accuracy 74.60000610351562 train_accuracy 97.65625\n",
            "epoch 31 step 61 loss 1.499495029449463\n",
            "epoch 31 step 62 loss 1.5053356885910034\n",
            "epoch 31 step 63 loss 1.4973461627960205\n",
            "epoch 31 step 64 loss 1.5394004583358765\n",
            "epoch 31 step 65 loss 1.5291450023651123\n",
            "epoch 31 step 66 loss 1.5222519636154175\n",
            "epoch 31 step 67 loss 1.4937100410461426\n",
            "epoch 31 step 68 loss 1.4997119903564453\n",
            "epoch 31 step 69 loss 1.5120813846588135\n",
            "epoch 31 step 70 loss 1.5279823541641235\n",
            "epoch 31 step 71 loss 1.5266199111938477\n",
            "epoch 31 step 72 loss 1.492802619934082\n",
            "epoch 31 step 73 loss 1.522451639175415\n",
            "epoch 31 step 74 loss 1.5433712005615234\n",
            "epoch 31 step 75 loss 1.5017073154449463\n",
            "epoch 31 step 76 loss 1.5060954093933105\n",
            "epoch 31 step 77 loss 1.4935822486877441\n",
            "epoch 31 step 78 loss 1.5265295505523682\n",
            "epoch 31 step 79 loss 1.5113345384597778\n",
            "epoch 31 step 80 loss 1.5210360288619995 test_accuracy 74.80000305175781 train_accuracy 99.21875\n",
            "epoch 31 step 81 loss 1.5041158199310303\n",
            "epoch 31 step 82 loss 1.5390102863311768\n",
            "epoch 31 step 83 loss 1.5004243850708008\n",
            "epoch 31 step 84 loss 1.5293195247650146\n",
            "epoch 31 step 85 loss 1.544379472732544\n",
            "epoch 31 step 86 loss 1.4857275485992432\n",
            "epoch 31 step 87 loss 1.515552282333374\n",
            "epoch 31 step 88 loss 1.4940451383590698\n",
            "epoch 31 step 89 loss 1.525088906288147\n",
            "epoch 31 step 90 loss 1.5089080333709717\n",
            "epoch 31 step 91 loss 1.5116195678710938\n",
            "epoch 31 step 92 loss 1.5023503303527832\n",
            "epoch 31 step 93 loss 1.5180137157440186\n",
            "epoch 31 step 94 loss 1.510541558265686\n",
            "epoch 31 step 95 loss 1.4927960634231567\n",
            "epoch 31 step 96 loss 1.5038795471191406\n",
            "epoch 31 step 97 loss 1.503737211227417\n",
            "epoch 31 step 98 loss 1.5220730304718018\n",
            "epoch 31 step 99 loss 1.5071946382522583\n",
            "epoch 31 step 100 loss 1.4935390949249268 test_accuracy 74.80000305175781 train_accuracy 96.09375\n",
            "epoch 31 step 101 loss 1.5166170597076416\n",
            "epoch 31 step 102 loss 1.5407713651657104\n",
            "epoch 31 step 103 loss 1.5202889442443848\n",
            "epoch 31 step 104 loss 1.5264681577682495\n",
            "epoch 31 step 105 loss 1.5201524496078491\n",
            "epoch 31 step 106 loss 1.4862886667251587\n",
            "epoch 31 step 107 loss 1.512192726135254\n",
            "epoch 31 step 108 loss 1.5084940195083618\n",
            "epoch 31 step 109 loss 1.4841724634170532\n",
            "epoch 31 step 110 loss 1.5035181045532227\n",
            "epoch 31 step 111 loss 1.543084740638733\n",
            "epoch 31 step 112 loss 1.4857548475265503\n",
            "epoch 31 step 113 loss 1.5205957889556885\n",
            "epoch 31 step 114 loss 1.517084002494812\n",
            "epoch 31 step 115 loss 1.4915440082550049\n",
            "epoch 31 step 116 loss 1.5247917175292969\n",
            "epoch 31 step 117 loss 1.481107234954834\n",
            "epoch 31 step 118 loss 1.5122871398925781\n",
            "epoch 31 step 119 loss 1.5137392282485962\n",
            "epoch 31 step 120 loss 1.4894680976867676 test_accuracy 74.80000305175781 train_accuracy 97.65625\n",
            "epoch 31 step 121 loss 1.5100091695785522\n",
            "epoch 31 step 122 loss 1.5549628734588623\n",
            "epoch 31 step 123 loss 1.542885184288025\n",
            "epoch 31 step 124 loss 1.5047836303710938\n",
            "epoch 31 step 125 loss 1.5397089719772339\n",
            "epoch 31 step 126 loss 1.5501898527145386\n",
            "epoch 31 step 127 loss 1.513503074645996\n",
            "epoch 31 step 128 loss 1.5011616945266724\n",
            "epoch 31 step 129 loss 1.5076210498809814\n",
            "epoch 31 step 130 loss 1.497237205505371\n",
            "epoch 31 step 131 loss 1.5064382553100586\n",
            "epoch 31 step 132 loss 1.5109844207763672\n",
            "epoch 31 step 133 loss 1.4919443130493164\n",
            "epoch 31 step 134 loss 1.5201481580734253\n",
            "epoch 31 step 135 loss 1.5257750749588013\n",
            "epoch 31 step 136 loss 1.5115675926208496\n",
            "epoch 31 step 137 loss 1.4936392307281494\n",
            "epoch 31 step 138 loss 1.5077646970748901\n",
            "epoch 31 step 139 loss 1.5211646556854248\n",
            "epoch 31 step 140 loss 1.5437432527542114 test_accuracy 74.80000305175781 train_accuracy 97.65625\n",
            "epoch 31 step 141 loss 1.4927924871444702\n",
            "epoch 31 step 142 loss 1.4821895360946655\n",
            "epoch 31 step 143 loss 1.5094008445739746\n",
            "epoch 31 step 144 loss 1.4940367937088013\n",
            "epoch 31 step 145 loss 1.5082097053527832\n",
            "epoch 31 step 146 loss 1.5136723518371582\n",
            "epoch 31 step 147 loss 1.5145444869995117\n",
            "epoch 31 step 148 loss 1.5330973863601685\n",
            "epoch 31 step 149 loss 1.4802591800689697\n",
            "epoch 31 step 150 loss 1.508237600326538\n",
            "epoch 31 step 151 loss 1.470658779144287\n",
            "epoch 31 step 152 loss 1.501951813697815\n",
            "epoch 31 step 153 loss 1.4943112134933472\n",
            "epoch 31 step 154 loss 1.5149126052856445\n",
            "epoch 31 step 155 loss 1.4963432550430298\n",
            "epoch 31 step 156 loss 1.479429841041565\n",
            "epoch 31 step 157 loss 1.506914734840393\n",
            "epoch 31 step 158 loss 1.5346683263778687\n",
            "epoch 31 step 159 loss 1.5302115678787231\n",
            "epoch 31 step 160 loss 1.5157418251037598 test_accuracy 74.80000305175781 train_accuracy 100.0\n",
            "epoch 31 step 161 loss 1.4924174547195435\n",
            "epoch 31 step 162 loss 1.5112221240997314\n",
            "epoch 31 step 163 loss 1.5030848979949951\n",
            "epoch 31 step 164 loss 1.5045788288116455\n",
            "epoch 31 step 165 loss 1.4908115863800049\n",
            "epoch 31 step 166 loss 1.5096396207809448\n",
            "epoch 31 step 167 loss 1.5061392784118652\n",
            "epoch 31 step 168 loss 1.4921660423278809\n",
            "epoch 31 step 169 loss 1.5161266326904297\n",
            "epoch 31 step 170 loss 1.511558175086975\n",
            "epoch 31 step 171 loss 1.5306639671325684\n",
            "epoch 31 step 172 loss 1.5174530744552612\n",
            "epoch 31 step 173 loss 1.4924650192260742\n",
            "epoch 31 step 174 loss 1.5400936603546143\n",
            "epoch 31 step 175 loss 1.5078400373458862\n",
            "epoch 31 step 176 loss 1.5246009826660156\n",
            "epoch 31 step 177 loss 1.5059586763381958\n",
            "epoch 31 step 178 loss 1.4898738861083984\n",
            "epoch 31 step 179 loss 1.5523006916046143\n",
            "epoch 31 step 180 loss 1.495863914489746 test_accuracy 75.0 train_accuracy 96.875\n",
            "epoch 31 step 181 loss 1.5092169046401978\n",
            "epoch 31 step 182 loss 1.5110446214675903\n",
            "epoch 31 step 183 loss 1.5263895988464355\n",
            "epoch 31 step 184 loss 1.4960720539093018\n",
            "epoch 31 step 185 loss 1.4929677248001099\n",
            "epoch 32 step 0 loss 1.5106310844421387 test_accuracy 74.80000305175781 train_accuracy 97.65625\n",
            "epoch 32 step 1 loss 1.5472133159637451\n",
            "epoch 32 step 2 loss 1.4911683797836304\n",
            "epoch 32 step 3 loss 1.4663701057434082\n",
            "epoch 32 step 4 loss 1.4871907234191895\n",
            "epoch 32 step 5 loss 1.512607216835022\n",
            "epoch 32 step 6 loss 1.567456603050232\n",
            "epoch 32 step 7 loss 1.5022815465927124\n",
            "epoch 32 step 8 loss 1.5107229948043823\n",
            "epoch 32 step 9 loss 1.5642837285995483\n",
            "epoch 32 step 10 loss 1.4954789876937866\n",
            "epoch 32 step 11 loss 1.519416332244873\n",
            "epoch 32 step 12 loss 1.5523452758789062\n",
            "epoch 32 step 13 loss 1.4953733682632446\n",
            "epoch 32 step 14 loss 1.518808126449585\n",
            "epoch 32 step 15 loss 1.496127724647522\n",
            "epoch 32 step 16 loss 1.5189800262451172\n",
            "epoch 32 step 17 loss 1.5004900693893433\n",
            "epoch 32 step 18 loss 1.4700993299484253\n",
            "epoch 32 step 19 loss 1.5091922283172607\n",
            "epoch 32 step 20 loss 1.5160386562347412 test_accuracy 75.0 train_accuracy 95.3125\n",
            "epoch 32 step 21 loss 1.5056253671646118\n",
            "epoch 32 step 22 loss 1.4923779964447021\n",
            "epoch 32 step 23 loss 1.5071477890014648\n",
            "epoch 32 step 24 loss 1.5007926225662231\n",
            "epoch 32 step 25 loss 1.5247825384140015\n",
            "epoch 32 step 26 loss 1.5209249258041382\n",
            "epoch 32 step 27 loss 1.4853310585021973\n",
            "epoch 32 step 28 loss 1.525900959968567\n",
            "epoch 32 step 29 loss 1.5254460573196411\n",
            "epoch 32 step 30 loss 1.4810702800750732\n",
            "epoch 32 step 31 loss 1.5312128067016602\n",
            "epoch 32 step 32 loss 1.499159574508667\n",
            "epoch 32 step 33 loss 1.4864646196365356\n",
            "epoch 32 step 34 loss 1.5380793809890747\n",
            "epoch 32 step 35 loss 1.501874566078186\n",
            "epoch 32 step 36 loss 1.5309841632843018\n",
            "epoch 32 step 37 loss 1.4988563060760498\n",
            "epoch 32 step 38 loss 1.4789390563964844\n",
            "epoch 32 step 39 loss 1.5187368392944336\n",
            "epoch 32 step 40 loss 1.4784646034240723 test_accuracy 75.0 train_accuracy 96.09375\n",
            "epoch 32 step 41 loss 1.5188497304916382\n",
            "epoch 32 step 42 loss 1.5300662517547607\n",
            "epoch 32 step 43 loss 1.5239512920379639\n",
            "epoch 32 step 44 loss 1.5075498819351196\n",
            "epoch 32 step 45 loss 1.514319896697998\n",
            "epoch 32 step 46 loss 1.499585747718811\n",
            "epoch 32 step 47 loss 1.494977355003357\n",
            "epoch 32 step 48 loss 1.4905364513397217\n",
            "epoch 32 step 49 loss 1.5284404754638672\n",
            "epoch 32 step 50 loss 1.5019581317901611\n",
            "epoch 32 step 51 loss 1.5089219808578491\n",
            "epoch 32 step 52 loss 1.4863483905792236\n",
            "epoch 32 step 53 loss 1.5014499425888062\n",
            "epoch 32 step 54 loss 1.513746976852417\n",
            "epoch 32 step 55 loss 1.4921085834503174\n",
            "epoch 32 step 56 loss 1.542946457862854\n",
            "epoch 32 step 57 loss 1.4933820962905884\n",
            "epoch 32 step 58 loss 1.5289431810379028\n",
            "epoch 32 step 59 loss 1.4935784339904785\n",
            "epoch 32 step 60 loss 1.4993382692337036 test_accuracy 74.80000305175781 train_accuracy 95.3125\n",
            "epoch 32 step 61 loss 1.4995980262756348\n",
            "epoch 32 step 62 loss 1.5008594989776611\n",
            "epoch 32 step 63 loss 1.487202763557434\n",
            "epoch 32 step 64 loss 1.5407472848892212\n",
            "epoch 32 step 65 loss 1.5099906921386719\n",
            "epoch 32 step 66 loss 1.4933180809020996\n",
            "epoch 32 step 67 loss 1.5170694589614868\n",
            "epoch 32 step 68 loss 1.507088303565979\n",
            "epoch 32 step 69 loss 1.4906656742095947\n",
            "epoch 32 step 70 loss 1.4899392127990723\n",
            "epoch 32 step 71 loss 1.5326142311096191\n",
            "epoch 32 step 72 loss 1.5010547637939453\n",
            "epoch 32 step 73 loss 1.5469682216644287\n",
            "epoch 32 step 74 loss 1.503167986869812\n",
            "epoch 32 step 75 loss 1.531059980392456\n",
            "epoch 32 step 76 loss 1.4929790496826172\n",
            "epoch 32 step 77 loss 1.4977271556854248\n",
            "epoch 32 step 78 loss 1.5043439865112305\n",
            "epoch 32 step 79 loss 1.5148098468780518\n",
            "epoch 32 step 80 loss 1.5329283475875854 test_accuracy 75.0 train_accuracy 98.4375\n",
            "epoch 32 step 81 loss 1.50037682056427\n",
            "epoch 32 step 82 loss 1.507299542427063\n",
            "epoch 32 step 83 loss 1.5191295146942139\n",
            "epoch 32 step 84 loss 1.4838416576385498\n",
            "epoch 32 step 85 loss 1.5249242782592773\n",
            "epoch 32 step 86 loss 1.4932377338409424\n",
            "epoch 32 step 87 loss 1.5256588459014893\n",
            "epoch 32 step 88 loss 1.5017646551132202\n",
            "epoch 32 step 89 loss 1.5147497653961182\n",
            "epoch 32 step 90 loss 1.4957619905471802\n",
            "epoch 32 step 91 loss 1.503313660621643\n",
            "epoch 32 step 92 loss 1.5502890348434448\n",
            "epoch 32 step 93 loss 1.4960767030715942\n",
            "epoch 32 step 94 loss 1.5023298263549805\n",
            "epoch 32 step 95 loss 1.4935476779937744\n",
            "epoch 32 step 96 loss 1.5277882814407349\n",
            "epoch 32 step 97 loss 1.4972423315048218\n",
            "epoch 32 step 98 loss 1.5256195068359375\n",
            "epoch 32 step 99 loss 1.5607130527496338\n",
            "epoch 32 step 100 loss 1.50962233543396 test_accuracy 75.4000015258789 train_accuracy 96.875\n",
            "epoch 32 step 101 loss 1.5125054121017456\n",
            "epoch 32 step 102 loss 1.50791597366333\n",
            "epoch 32 step 103 loss 1.482717514038086\n",
            "epoch 32 step 104 loss 1.528684139251709\n",
            "epoch 32 step 105 loss 1.4955942630767822\n",
            "epoch 32 step 106 loss 1.5518451929092407\n",
            "epoch 32 step 107 loss 1.5185322761535645\n",
            "epoch 32 step 108 loss 1.4961591958999634\n",
            "epoch 32 step 109 loss 1.5085535049438477\n",
            "epoch 32 step 110 loss 1.4874217510223389\n",
            "epoch 32 step 111 loss 1.4970600605010986\n",
            "epoch 32 step 112 loss 1.508435845375061\n",
            "epoch 32 step 113 loss 1.523128628730774\n",
            "epoch 32 step 114 loss 1.501137614250183\n",
            "epoch 32 step 115 loss 1.4829035997390747\n",
            "epoch 32 step 116 loss 1.5072121620178223\n",
            "epoch 32 step 117 loss 1.4942768812179565\n",
            "epoch 32 step 118 loss 1.5167012214660645\n",
            "epoch 32 step 119 loss 1.5242913961410522\n",
            "epoch 32 step 120 loss 1.4970632791519165 test_accuracy 75.4000015258789 train_accuracy 94.53125\n",
            "epoch 32 step 121 loss 1.5011869668960571\n",
            "epoch 32 step 122 loss 1.51065194606781\n",
            "epoch 32 step 123 loss 1.5252141952514648\n",
            "epoch 32 step 124 loss 1.5115740299224854\n",
            "epoch 32 step 125 loss 1.5654516220092773\n",
            "epoch 32 step 126 loss 1.502758502960205\n",
            "epoch 32 step 127 loss 1.510438323020935\n",
            "epoch 32 step 128 loss 1.512675166130066\n",
            "epoch 32 step 129 loss 1.5451334714889526\n",
            "epoch 32 step 130 loss 1.537931203842163\n",
            "epoch 32 step 131 loss 1.4860150814056396\n",
            "epoch 32 step 132 loss 1.5012073516845703\n",
            "epoch 32 step 133 loss 1.5067507028579712\n",
            "epoch 32 step 134 loss 1.499154806137085\n",
            "epoch 32 step 135 loss 1.5098824501037598\n",
            "epoch 32 step 136 loss 1.5504761934280396\n",
            "epoch 32 step 137 loss 1.4908758401870728\n",
            "epoch 32 step 138 loss 1.5114610195159912\n",
            "epoch 32 step 139 loss 1.5254127979278564\n",
            "epoch 32 step 140 loss 1.5030920505523682 test_accuracy 75.4000015258789 train_accuracy 95.3125\n",
            "epoch 32 step 141 loss 1.4864158630371094\n",
            "epoch 32 step 142 loss 1.5439250469207764\n",
            "epoch 32 step 143 loss 1.5152486562728882\n",
            "epoch 32 step 144 loss 1.5069056749343872\n",
            "epoch 32 step 145 loss 1.5003528594970703\n",
            "epoch 32 step 146 loss 1.4867806434631348\n",
            "epoch 32 step 147 loss 1.5010077953338623\n",
            "epoch 32 step 148 loss 1.5581573247909546\n",
            "epoch 32 step 149 loss 1.4975852966308594\n",
            "epoch 32 step 150 loss 1.520824909210205\n",
            "epoch 32 step 151 loss 1.489218831062317\n",
            "epoch 32 step 152 loss 1.498402714729309\n",
            "epoch 32 step 153 loss 1.5086537599563599\n",
            "epoch 32 step 154 loss 1.5071059465408325\n",
            "epoch 32 step 155 loss 1.4994478225708008\n",
            "epoch 32 step 156 loss 1.5097273588180542\n",
            "epoch 32 step 157 loss 1.5036567449569702\n",
            "epoch 32 step 158 loss 1.5095436573028564\n",
            "epoch 32 step 159 loss 1.523618459701538\n",
            "epoch 32 step 160 loss 1.4936072826385498 test_accuracy 75.60000610351562 train_accuracy 93.75\n",
            "epoch 32 step 161 loss 1.4892621040344238\n",
            "epoch 32 step 162 loss 1.517462968826294\n",
            "epoch 32 step 163 loss 1.4864723682403564\n",
            "epoch 32 step 164 loss 1.5158801078796387\n",
            "epoch 32 step 165 loss 1.4986358880996704\n",
            "epoch 32 step 166 loss 1.4806139469146729\n",
            "epoch 32 step 167 loss 1.503956913948059\n",
            "epoch 32 step 168 loss 1.501036524772644\n",
            "epoch 32 step 169 loss 1.5115609169006348\n",
            "epoch 32 step 170 loss 1.485788345336914\n",
            "epoch 32 step 171 loss 1.5242557525634766\n",
            "epoch 32 step 172 loss 1.5042552947998047\n",
            "epoch 32 step 173 loss 1.5317466259002686\n",
            "epoch 32 step 174 loss 1.5138295888900757\n",
            "epoch 32 step 175 loss 1.4938955307006836\n",
            "epoch 32 step 176 loss 1.481673002243042\n",
            "epoch 32 step 177 loss 1.5292097330093384\n",
            "epoch 32 step 178 loss 1.516912579536438\n",
            "epoch 32 step 179 loss 1.494554877281189\n",
            "epoch 32 step 180 loss 1.503641963005066 test_accuracy 75.4000015258789 train_accuracy 96.09375\n",
            "epoch 32 step 181 loss 1.5055142641067505\n",
            "epoch 32 step 182 loss 1.4690589904785156\n",
            "epoch 32 step 183 loss 1.502571702003479\n",
            "epoch 32 step 184 loss 1.5253734588623047\n",
            "epoch 32 step 185 loss 1.4912872314453125\n",
            "epoch 33 step 0 loss 1.5151621103286743 test_accuracy 75.60000610351562 train_accuracy 98.4375\n",
            "epoch 33 step 1 loss 1.5148340463638306\n",
            "epoch 33 step 2 loss 1.501114010810852\n",
            "epoch 33 step 3 loss 1.5086052417755127\n",
            "epoch 33 step 4 loss 1.505022644996643\n",
            "epoch 33 step 5 loss 1.492681860923767\n",
            "epoch 33 step 6 loss 1.4943468570709229\n",
            "epoch 33 step 7 loss 1.511616587638855\n",
            "epoch 33 step 8 loss 1.5038642883300781\n",
            "epoch 33 step 9 loss 1.484379768371582\n",
            "epoch 33 step 10 loss 1.5011475086212158\n",
            "epoch 33 step 11 loss 1.5028256177902222\n",
            "epoch 33 step 12 loss 1.5087136030197144\n",
            "epoch 33 step 13 loss 1.5201258659362793\n",
            "epoch 33 step 14 loss 1.495166540145874\n",
            "epoch 33 step 15 loss 1.5413116216659546\n",
            "epoch 33 step 16 loss 1.5351219177246094\n",
            "epoch 33 step 17 loss 1.5075888633728027\n",
            "epoch 33 step 18 loss 1.4991836547851562\n",
            "epoch 33 step 19 loss 1.5104225873947144\n",
            "epoch 33 step 20 loss 1.4893604516983032 test_accuracy 75.4000015258789 train_accuracy 98.4375\n",
            "epoch 33 step 21 loss 1.4985171556472778\n",
            "epoch 33 step 22 loss 1.5170080661773682\n",
            "epoch 33 step 23 loss 1.497948169708252\n",
            "epoch 33 step 24 loss 1.505873441696167\n",
            "epoch 33 step 25 loss 1.519139051437378\n",
            "epoch 33 step 26 loss 1.5303627252578735\n",
            "epoch 33 step 27 loss 1.5028811693191528\n",
            "epoch 33 step 28 loss 1.5135055780410767\n",
            "epoch 33 step 29 loss 1.4891897439956665\n",
            "epoch 33 step 30 loss 1.5385193824768066\n",
            "epoch 33 step 31 loss 1.5084177255630493\n",
            "epoch 33 step 32 loss 1.5129190683364868\n",
            "epoch 33 step 33 loss 1.5269333124160767\n",
            "epoch 33 step 34 loss 1.5035200119018555\n",
            "epoch 33 step 35 loss 1.5317988395690918\n",
            "epoch 33 step 36 loss 1.5047837495803833\n",
            "epoch 33 step 37 loss 1.503646969795227\n",
            "epoch 33 step 38 loss 1.5280609130859375\n",
            "epoch 33 step 39 loss 1.539946436882019\n",
            "epoch 33 step 40 loss 1.5195763111114502 test_accuracy 75.4000015258789 train_accuracy 97.65625\n",
            "epoch 33 step 41 loss 1.4878430366516113\n",
            "epoch 33 step 42 loss 1.4763668775558472\n",
            "epoch 33 step 43 loss 1.5367915630340576\n",
            "epoch 33 step 44 loss 1.4853917360305786\n",
            "epoch 33 step 45 loss 1.5125858783721924\n",
            "epoch 33 step 46 loss 1.5087368488311768\n",
            "epoch 33 step 47 loss 1.495540976524353\n",
            "epoch 33 step 48 loss 1.5189319849014282\n",
            "epoch 33 step 49 loss 1.5135517120361328\n",
            "epoch 33 step 50 loss 1.5127222537994385\n",
            "epoch 33 step 51 loss 1.5042688846588135\n",
            "epoch 33 step 52 loss 1.5137875080108643\n",
            "epoch 33 step 53 loss 1.5219390392303467\n",
            "epoch 33 step 54 loss 1.4793955087661743\n",
            "epoch 33 step 55 loss 1.5136057138442993\n",
            "epoch 33 step 56 loss 1.5103480815887451\n",
            "epoch 33 step 57 loss 1.512809157371521\n",
            "epoch 33 step 58 loss 1.4874049425125122\n",
            "epoch 33 step 59 loss 1.5217138528823853\n",
            "epoch 33 step 60 loss 1.4744163751602173 test_accuracy 75.0 train_accuracy 96.09375\n",
            "epoch 33 step 61 loss 1.5156551599502563\n",
            "epoch 33 step 62 loss 1.518152117729187\n",
            "epoch 33 step 63 loss 1.5076179504394531\n",
            "epoch 33 step 64 loss 1.5040451288223267\n",
            "epoch 33 step 65 loss 1.509264588356018\n",
            "epoch 33 step 66 loss 1.4898450374603271\n",
            "epoch 33 step 67 loss 1.4938193559646606\n",
            "epoch 33 step 68 loss 1.5167651176452637\n",
            "epoch 33 step 69 loss 1.5171630382537842\n",
            "epoch 33 step 70 loss 1.48483145236969\n",
            "epoch 33 step 71 loss 1.5317671298980713\n",
            "epoch 33 step 72 loss 1.5193666219711304\n",
            "epoch 33 step 73 loss 1.5173007249832153\n",
            "epoch 33 step 74 loss 1.491428017616272\n",
            "epoch 33 step 75 loss 1.5013388395309448\n",
            "epoch 33 step 76 loss 1.524888515472412\n",
            "epoch 33 step 77 loss 1.5031988620758057\n",
            "epoch 33 step 78 loss 1.5144051313400269\n",
            "epoch 33 step 79 loss 1.506688117980957\n",
            "epoch 33 step 80 loss 1.507729411125183 test_accuracy 75.0 train_accuracy 97.65625\n",
            "epoch 33 step 81 loss 1.512338638305664\n",
            "epoch 33 step 82 loss 1.5197460651397705\n",
            "epoch 33 step 83 loss 1.495470404624939\n",
            "epoch 33 step 84 loss 1.4796992540359497\n",
            "epoch 33 step 85 loss 1.4752674102783203\n",
            "epoch 33 step 86 loss 1.4962735176086426\n",
            "epoch 33 step 87 loss 1.5188136100769043\n",
            "epoch 33 step 88 loss 1.5147391557693481\n",
            "epoch 33 step 89 loss 1.5478025674819946\n",
            "epoch 33 step 90 loss 1.4810394048690796\n",
            "epoch 33 step 91 loss 1.4953548908233643\n",
            "epoch 33 step 92 loss 1.5198651552200317\n",
            "epoch 33 step 93 loss 1.4962809085845947\n",
            "epoch 33 step 94 loss 1.5183255672454834\n",
            "epoch 33 step 95 loss 1.540233850479126\n",
            "epoch 33 step 96 loss 1.5141228437423706\n",
            "epoch 33 step 97 loss 1.5036306381225586\n",
            "epoch 33 step 98 loss 1.4877015352249146\n",
            "epoch 33 step 99 loss 1.5091334581375122\n",
            "epoch 33 step 100 loss 1.5127710103988647 test_accuracy 75.20000457763672 train_accuracy 96.875\n",
            "epoch 33 step 101 loss 1.4935789108276367\n",
            "epoch 33 step 102 loss 1.5121124982833862\n",
            "epoch 33 step 103 loss 1.4862651824951172\n",
            "epoch 33 step 104 loss 1.503056287765503\n",
            "epoch 33 step 105 loss 1.5360901355743408\n",
            "epoch 33 step 106 loss 1.556246042251587\n",
            "epoch 33 step 107 loss 1.4957541227340698\n",
            "epoch 33 step 108 loss 1.5332587957382202\n",
            "epoch 33 step 109 loss 1.5028972625732422\n",
            "epoch 33 step 110 loss 1.5082001686096191\n",
            "epoch 33 step 111 loss 1.4853354692459106\n",
            "epoch 33 step 112 loss 1.5075868368148804\n",
            "epoch 33 step 113 loss 1.4865689277648926\n",
            "epoch 33 step 114 loss 1.4931336641311646\n",
            "epoch 33 step 115 loss 1.5066567659378052\n",
            "epoch 33 step 116 loss 1.5304702520370483\n",
            "epoch 33 step 117 loss 1.4897876977920532\n",
            "epoch 33 step 118 loss 1.4854503870010376\n",
            "epoch 33 step 119 loss 1.4784350395202637\n",
            "epoch 33 step 120 loss 1.5435835123062134 test_accuracy 75.20000457763672 train_accuracy 96.875\n",
            "epoch 33 step 121 loss 1.5183079242706299\n",
            "epoch 33 step 122 loss 1.4944711923599243\n",
            "epoch 33 step 123 loss 1.5096253156661987\n",
            "epoch 33 step 124 loss 1.519633412361145\n",
            "epoch 33 step 125 loss 1.5010831356048584\n",
            "epoch 33 step 126 loss 1.5303772687911987\n",
            "epoch 33 step 127 loss 1.4830973148345947\n",
            "epoch 33 step 128 loss 1.5304731130599976\n",
            "epoch 33 step 129 loss 1.5146286487579346\n",
            "epoch 33 step 130 loss 1.4979075193405151\n",
            "epoch 33 step 131 loss 1.4911538362503052\n",
            "epoch 33 step 132 loss 1.521000623703003\n",
            "epoch 33 step 133 loss 1.5180296897888184\n",
            "epoch 33 step 134 loss 1.5389131307601929\n",
            "epoch 33 step 135 loss 1.5224970579147339\n",
            "epoch 33 step 136 loss 1.5114355087280273\n",
            "epoch 33 step 137 loss 1.528256893157959\n",
            "epoch 33 step 138 loss 1.4856092929840088\n",
            "epoch 33 step 139 loss 1.543903112411499\n",
            "epoch 33 step 140 loss 1.484269142150879 test_accuracy 75.4000015258789 train_accuracy 98.4375\n",
            "epoch 33 step 141 loss 1.5078901052474976\n",
            "epoch 33 step 142 loss 1.4998888969421387\n",
            "epoch 33 step 143 loss 1.4977003335952759\n",
            "epoch 33 step 144 loss 1.555484414100647\n",
            "epoch 33 step 145 loss 1.5346941947937012\n",
            "epoch 33 step 146 loss 1.505666732788086\n",
            "epoch 33 step 147 loss 1.496100664138794\n",
            "epoch 33 step 148 loss 1.5065151453018188\n",
            "epoch 33 step 149 loss 1.5262874364852905\n",
            "epoch 33 step 150 loss 1.490553855895996\n",
            "epoch 33 step 151 loss 1.5251611471176147\n",
            "epoch 33 step 152 loss 1.4806873798370361\n",
            "epoch 33 step 153 loss 1.5126549005508423\n",
            "epoch 33 step 154 loss 1.4962079524993896\n",
            "epoch 33 step 155 loss 1.5251342058181763\n",
            "epoch 33 step 156 loss 1.513951063156128\n",
            "epoch 33 step 157 loss 1.4934310913085938\n",
            "epoch 33 step 158 loss 1.5116318464279175\n",
            "epoch 33 step 159 loss 1.4959663152694702\n",
            "epoch 33 step 160 loss 1.550956130027771 test_accuracy 75.20000457763672 train_accuracy 98.4375\n",
            "epoch 33 step 161 loss 1.4960854053497314\n",
            "epoch 33 step 162 loss 1.5085184574127197\n",
            "epoch 33 step 163 loss 1.4943958520889282\n",
            "epoch 33 step 164 loss 1.4947994947433472\n",
            "epoch 33 step 165 loss 1.4763208627700806\n",
            "epoch 33 step 166 loss 1.5087939500808716\n",
            "epoch 33 step 167 loss 1.5634562969207764\n",
            "epoch 33 step 168 loss 1.4878841638565063\n",
            "epoch 33 step 169 loss 1.5098838806152344\n",
            "epoch 33 step 170 loss 1.5042304992675781\n",
            "epoch 33 step 171 loss 1.5055677890777588\n",
            "epoch 33 step 172 loss 1.5319756269454956\n",
            "epoch 33 step 173 loss 1.5223907232284546\n",
            "epoch 33 step 174 loss 1.5109683275222778\n",
            "epoch 33 step 175 loss 1.5123611688613892\n",
            "epoch 33 step 176 loss 1.5025138854980469\n",
            "epoch 33 step 177 loss 1.4988337755203247\n",
            "epoch 33 step 178 loss 1.5123668909072876\n",
            "epoch 33 step 179 loss 1.5503947734832764\n",
            "epoch 33 step 180 loss 1.5037723779678345 test_accuracy 75.60000610351562 train_accuracy 98.4375\n",
            "epoch 33 step 181 loss 1.5154246091842651\n",
            "epoch 33 step 182 loss 1.5406792163848877\n",
            "epoch 33 step 183 loss 1.5019121170043945\n",
            "epoch 33 step 184 loss 1.4814003705978394\n",
            "epoch 33 step 185 loss 1.5801060199737549\n",
            "epoch 34 step 0 loss 1.5268324613571167 test_accuracy 75.60000610351562 train_accuracy 96.875\n",
            "epoch 34 step 1 loss 1.4830121994018555\n",
            "epoch 34 step 2 loss 1.5032151937484741\n",
            "epoch 34 step 3 loss 1.5124409198760986\n",
            "epoch 34 step 4 loss 1.534022331237793\n",
            "epoch 34 step 5 loss 1.5004574060440063\n",
            "epoch 34 step 6 loss 1.5103740692138672\n",
            "epoch 34 step 7 loss 1.5065737962722778\n",
            "epoch 34 step 8 loss 1.5301151275634766\n",
            "epoch 34 step 9 loss 1.510652780532837\n",
            "epoch 34 step 10 loss 1.540927767753601\n",
            "epoch 34 step 11 loss 1.5168430805206299\n",
            "epoch 34 step 12 loss 1.5164278745651245\n",
            "epoch 34 step 13 loss 1.5054316520690918\n",
            "epoch 34 step 14 loss 1.5134913921356201\n",
            "epoch 34 step 15 loss 1.4762316942214966\n",
            "epoch 34 step 16 loss 1.4918324947357178\n",
            "epoch 34 step 17 loss 1.506962537765503\n",
            "epoch 34 step 18 loss 1.4892696142196655\n",
            "epoch 34 step 19 loss 1.534136176109314\n",
            "epoch 34 step 20 loss 1.5019862651824951 test_accuracy 75.4000015258789 train_accuracy 94.53125\n",
            "epoch 34 step 21 loss 1.5165526866912842\n",
            "epoch 34 step 22 loss 1.516768455505371\n",
            "epoch 34 step 23 loss 1.4835338592529297\n",
            "epoch 34 step 24 loss 1.5320038795471191\n",
            "epoch 34 step 25 loss 1.5202162265777588\n",
            "epoch 34 step 26 loss 1.4965332746505737\n",
            "epoch 34 step 27 loss 1.479638934135437\n",
            "epoch 34 step 28 loss 1.5059986114501953\n",
            "epoch 34 step 29 loss 1.485862135887146\n",
            "epoch 34 step 30 loss 1.5189921855926514\n",
            "epoch 34 step 31 loss 1.5150083303451538\n",
            "epoch 34 step 32 loss 1.51117742061615\n",
            "epoch 34 step 33 loss 1.4988807439804077\n",
            "epoch 34 step 34 loss 1.492920994758606\n",
            "epoch 34 step 35 loss 1.5263850688934326\n",
            "epoch 34 step 36 loss 1.5127257108688354\n",
            "epoch 34 step 37 loss 1.5191471576690674\n",
            "epoch 34 step 38 loss 1.542810082435608\n",
            "epoch 34 step 39 loss 1.525376319885254\n",
            "epoch 34 step 40 loss 1.4943088293075562 test_accuracy 75.80000305175781 train_accuracy 97.65625\n",
            "epoch 34 step 41 loss 1.5356636047363281\n",
            "epoch 34 step 42 loss 1.4941624402999878\n",
            "epoch 34 step 43 loss 1.522266149520874\n",
            "epoch 34 step 44 loss 1.4752970933914185\n",
            "epoch 34 step 45 loss 1.5121145248413086\n",
            "epoch 34 step 46 loss 1.5132676362991333\n",
            "epoch 34 step 47 loss 1.533481478691101\n",
            "epoch 34 step 48 loss 1.489166021347046\n",
            "epoch 34 step 49 loss 1.513272762298584\n",
            "epoch 34 step 50 loss 1.5129178762435913\n",
            "epoch 34 step 51 loss 1.4852595329284668\n",
            "epoch 34 step 52 loss 1.5124998092651367\n",
            "epoch 34 step 53 loss 1.5506925582885742\n",
            "epoch 34 step 54 loss 1.5321062803268433\n",
            "epoch 34 step 55 loss 1.4946788549423218\n",
            "epoch 34 step 56 loss 1.5361833572387695\n",
            "epoch 34 step 57 loss 1.470445990562439\n",
            "epoch 34 step 58 loss 1.5396435260772705\n",
            "epoch 34 step 59 loss 1.4858450889587402\n",
            "epoch 34 step 60 loss 1.4860785007476807 test_accuracy 75.80000305175781 train_accuracy 96.09375\n",
            "epoch 34 step 61 loss 1.5186545848846436\n",
            "epoch 34 step 62 loss 1.5143928527832031\n",
            "epoch 34 step 63 loss 1.5165772438049316\n",
            "epoch 34 step 64 loss 1.4914932250976562\n",
            "epoch 34 step 65 loss 1.502439022064209\n",
            "epoch 34 step 66 loss 1.5043973922729492\n",
            "epoch 34 step 67 loss 1.4849388599395752\n",
            "epoch 34 step 68 loss 1.5154554843902588\n",
            "epoch 34 step 69 loss 1.5187249183654785\n",
            "epoch 34 step 70 loss 1.5188876390457153\n",
            "epoch 34 step 71 loss 1.5279066562652588\n",
            "epoch 34 step 72 loss 1.510036587715149\n",
            "epoch 34 step 73 loss 1.5104365348815918\n",
            "epoch 34 step 74 loss 1.4908692836761475\n",
            "epoch 34 step 75 loss 1.4884430170059204\n",
            "epoch 34 step 76 loss 1.528257966041565\n",
            "epoch 34 step 77 loss 1.4967155456542969\n",
            "epoch 34 step 78 loss 1.4830304384231567\n",
            "epoch 34 step 79 loss 1.5009196996688843\n",
            "epoch 34 step 80 loss 1.4843307733535767 test_accuracy 76.0 train_accuracy 98.4375\n",
            "epoch 34 step 81 loss 1.5304275751113892\n",
            "epoch 34 step 82 loss 1.5200976133346558\n",
            "epoch 34 step 83 loss 1.526768684387207\n",
            "epoch 34 step 84 loss 1.5229765176773071\n",
            "epoch 34 step 85 loss 1.4953844547271729\n",
            "epoch 34 step 86 loss 1.5020289421081543\n",
            "epoch 34 step 87 loss 1.513611912727356\n",
            "epoch 34 step 88 loss 1.4901057481765747\n",
            "epoch 34 step 89 loss 1.554598331451416\n",
            "epoch 34 step 90 loss 1.4823426008224487\n",
            "epoch 34 step 91 loss 1.5271556377410889\n",
            "epoch 34 step 92 loss 1.4972105026245117\n",
            "epoch 34 step 93 loss 1.509643316268921\n",
            "epoch 34 step 94 loss 1.5044726133346558\n",
            "epoch 34 step 95 loss 1.501651644706726\n",
            "epoch 34 step 96 loss 1.5403008460998535\n",
            "epoch 34 step 97 loss 1.5303699970245361\n",
            "epoch 34 step 98 loss 1.5046309232711792\n",
            "epoch 34 step 99 loss 1.4821454286575317\n",
            "epoch 34 step 100 loss 1.4996201992034912 test_accuracy 76.20000457763672 train_accuracy 99.21875\n",
            "epoch 34 step 101 loss 1.4990516901016235\n",
            "epoch 34 step 102 loss 1.4912251234054565\n",
            "epoch 34 step 103 loss 1.5062180757522583\n",
            "epoch 34 step 104 loss 1.5034276247024536\n",
            "epoch 34 step 105 loss 1.5356166362762451\n",
            "epoch 34 step 106 loss 1.5368881225585938\n",
            "epoch 34 step 107 loss 1.4973983764648438\n",
            "epoch 34 step 108 loss 1.5317715406417847\n",
            "epoch 34 step 109 loss 1.5192315578460693\n",
            "epoch 34 step 110 loss 1.4895960092544556\n",
            "epoch 34 step 111 loss 1.502184510231018\n",
            "epoch 34 step 112 loss 1.5032329559326172\n",
            "epoch 34 step 113 loss 1.5068227052688599\n",
            "epoch 34 step 114 loss 1.493269920349121\n",
            "epoch 34 step 115 loss 1.5400363206863403\n",
            "epoch 34 step 116 loss 1.5186452865600586\n",
            "epoch 34 step 117 loss 1.5014903545379639\n",
            "epoch 34 step 118 loss 1.5157922506332397\n",
            "epoch 34 step 119 loss 1.4730218648910522\n",
            "epoch 34 step 120 loss 1.5178370475769043 test_accuracy 75.60000610351562 train_accuracy 94.53125\n",
            "epoch 34 step 121 loss 1.522374153137207\n",
            "epoch 34 step 122 loss 1.5315181016921997\n",
            "epoch 34 step 123 loss 1.5011348724365234\n",
            "epoch 34 step 124 loss 1.5003615617752075\n",
            "epoch 34 step 125 loss 1.4973654747009277\n",
            "epoch 34 step 126 loss 1.5257564783096313\n",
            "epoch 34 step 127 loss 1.5130585432052612\n",
            "epoch 34 step 128 loss 1.4852882623672485\n",
            "epoch 34 step 129 loss 1.4823691844940186\n",
            "epoch 34 step 130 loss 1.5322567224502563\n",
            "epoch 34 step 131 loss 1.476757287979126\n",
            "epoch 34 step 132 loss 1.490857720375061\n",
            "epoch 34 step 133 loss 1.500625491142273\n",
            "epoch 34 step 134 loss 1.5489106178283691\n",
            "epoch 34 step 135 loss 1.51972496509552\n",
            "epoch 34 step 136 loss 1.5300345420837402\n",
            "epoch 34 step 137 loss 1.5036892890930176\n",
            "epoch 34 step 138 loss 1.4953590631484985\n",
            "epoch 34 step 139 loss 1.5124067068099976\n",
            "epoch 34 step 140 loss 1.4911129474639893 test_accuracy 76.0 train_accuracy 97.65625\n",
            "epoch 34 step 141 loss 1.5115318298339844\n",
            "epoch 34 step 142 loss 1.4705168008804321\n",
            "epoch 34 step 143 loss 1.4877747297286987\n",
            "epoch 34 step 144 loss 1.4990253448486328\n",
            "epoch 34 step 145 loss 1.483878493309021\n",
            "epoch 34 step 146 loss 1.485066533088684\n",
            "epoch 34 step 147 loss 1.5391300916671753\n",
            "epoch 34 step 148 loss 1.5169169902801514\n",
            "epoch 34 step 149 loss 1.51197350025177\n",
            "epoch 34 step 150 loss 1.5348703861236572\n",
            "epoch 34 step 151 loss 1.4762115478515625\n",
            "epoch 34 step 152 loss 1.5071879625320435\n",
            "epoch 34 step 153 loss 1.495873212814331\n",
            "epoch 34 step 154 loss 1.5117655992507935\n",
            "epoch 34 step 155 loss 1.5087391138076782\n",
            "epoch 34 step 156 loss 1.482499599456787\n",
            "epoch 34 step 157 loss 1.5101699829101562\n",
            "epoch 34 step 158 loss 1.5064164400100708\n",
            "epoch 34 step 159 loss 1.524472951889038\n",
            "epoch 34 step 160 loss 1.4625791311264038 test_accuracy 75.60000610351562 train_accuracy 94.53125\n",
            "epoch 34 step 161 loss 1.5263919830322266\n",
            "epoch 34 step 162 loss 1.4936946630477905\n",
            "epoch 34 step 163 loss 1.522324800491333\n",
            "epoch 34 step 164 loss 1.5095845460891724\n",
            "epoch 34 step 165 loss 1.5383920669555664\n",
            "epoch 34 step 166 loss 1.503111720085144\n",
            "epoch 34 step 167 loss 1.495788335800171\n",
            "epoch 34 step 168 loss 1.5292158126831055\n",
            "epoch 34 step 169 loss 1.4855163097381592\n",
            "epoch 34 step 170 loss 1.512069582939148\n",
            "epoch 34 step 171 loss 1.5015288591384888\n",
            "epoch 34 step 172 loss 1.5054014921188354\n",
            "epoch 34 step 173 loss 1.5119682550430298\n",
            "epoch 34 step 174 loss 1.5121780633926392\n",
            "epoch 34 step 175 loss 1.5009187459945679\n",
            "epoch 34 step 176 loss 1.5030324459075928\n",
            "epoch 34 step 177 loss 1.5032744407653809\n",
            "epoch 34 step 178 loss 1.510816216468811\n",
            "epoch 34 step 179 loss 1.5220576524734497\n",
            "epoch 34 step 180 loss 1.5186604261398315 test_accuracy 76.0 train_accuracy 96.09375\n",
            "epoch 34 step 181 loss 1.4982500076293945\n",
            "epoch 34 step 182 loss 1.5369657278060913\n",
            "epoch 34 step 183 loss 1.521203637123108\n",
            "epoch 34 step 184 loss 1.537272334098816\n",
            "epoch 34 step 185 loss 1.4885603189468384\n",
            "epoch 35 step 0 loss 1.5348803997039795 test_accuracy 75.60000610351562 train_accuracy 95.3125\n",
            "epoch 35 step 1 loss 1.5933735370635986\n",
            "epoch 35 step 2 loss 1.5209256410598755\n",
            "epoch 35 step 3 loss 1.5122575759887695\n",
            "epoch 35 step 4 loss 1.511690616607666\n",
            "epoch 35 step 5 loss 1.4841303825378418\n",
            "epoch 35 step 6 loss 1.4881430864334106\n",
            "epoch 35 step 7 loss 1.5205533504486084\n",
            "epoch 35 step 8 loss 1.5138812065124512\n",
            "epoch 35 step 9 loss 1.4794424772262573\n",
            "epoch 35 step 10 loss 1.5142889022827148\n",
            "epoch 35 step 11 loss 1.5198357105255127\n",
            "epoch 35 step 12 loss 1.4988036155700684\n",
            "epoch 35 step 13 loss 1.492337942123413\n",
            "epoch 35 step 14 loss 1.5116256475448608\n",
            "epoch 35 step 15 loss 1.5310605764389038\n",
            "epoch 35 step 16 loss 1.5198086500167847\n",
            "epoch 35 step 17 loss 1.5151034593582153\n",
            "epoch 35 step 18 loss 1.498117446899414\n",
            "epoch 35 step 19 loss 1.5035935640335083\n",
            "epoch 35 step 20 loss 1.488145112991333 test_accuracy 76.0 train_accuracy 99.21875\n",
            "epoch 35 step 21 loss 1.487248182296753\n",
            "epoch 35 step 22 loss 1.5179953575134277\n",
            "epoch 35 step 23 loss 1.5077370405197144\n",
            "epoch 35 step 24 loss 1.501233696937561\n",
            "epoch 35 step 25 loss 1.5408272743225098\n",
            "epoch 35 step 26 loss 1.5159491300582886\n",
            "epoch 35 step 27 loss 1.521443247795105\n",
            "epoch 35 step 28 loss 1.4790147542953491\n",
            "epoch 35 step 29 loss 1.5207395553588867\n",
            "epoch 35 step 30 loss 1.4975321292877197\n",
            "epoch 35 step 31 loss 1.515084981918335\n",
            "epoch 35 step 32 loss 1.5073868036270142\n",
            "epoch 35 step 33 loss 1.5058274269104004\n",
            "epoch 35 step 34 loss 1.480303406715393\n",
            "epoch 35 step 35 loss 1.4958066940307617\n",
            "epoch 35 step 36 loss 1.495194673538208\n",
            "epoch 35 step 37 loss 1.4880566596984863\n",
            "epoch 35 step 38 loss 1.4718914031982422\n",
            "epoch 35 step 39 loss 1.4956086874008179\n",
            "epoch 35 step 40 loss 1.5138390064239502 test_accuracy 76.0 train_accuracy 95.3125\n",
            "epoch 35 step 41 loss 1.526871919631958\n",
            "epoch 35 step 42 loss 1.5169025659561157\n",
            "epoch 35 step 43 loss 1.4906766414642334\n",
            "epoch 35 step 44 loss 1.5027899742126465\n",
            "epoch 35 step 45 loss 1.470168948173523\n",
            "epoch 35 step 46 loss 1.4818248748779297\n",
            "epoch 35 step 47 loss 1.5194485187530518\n",
            "epoch 35 step 48 loss 1.4895938634872437\n",
            "epoch 35 step 49 loss 1.5214736461639404\n",
            "epoch 35 step 50 loss 1.513387680053711\n",
            "epoch 35 step 51 loss 1.5035127401351929\n",
            "epoch 35 step 52 loss 1.4974929094314575\n",
            "epoch 35 step 53 loss 1.5128943920135498\n",
            "epoch 35 step 54 loss 1.4775439500808716\n",
            "epoch 35 step 55 loss 1.485898733139038\n",
            "epoch 35 step 56 loss 1.4854532480239868\n",
            "epoch 35 step 57 loss 1.481411337852478\n",
            "epoch 35 step 58 loss 1.5197778940200806\n",
            "epoch 35 step 59 loss 1.5172549486160278\n",
            "epoch 35 step 60 loss 1.5037355422973633 test_accuracy 75.80000305175781 train_accuracy 97.65625\n",
            "epoch 35 step 61 loss 1.5199867486953735\n",
            "epoch 35 step 62 loss 1.4747260808944702\n",
            "epoch 35 step 63 loss 1.5049777030944824\n",
            "epoch 35 step 64 loss 1.5136414766311646\n",
            "epoch 35 step 65 loss 1.5017951726913452\n",
            "epoch 35 step 66 loss 1.5409718751907349\n",
            "epoch 35 step 67 loss 1.531905174255371\n",
            "epoch 35 step 68 loss 1.4905911684036255\n",
            "epoch 35 step 69 loss 1.5124367475509644\n",
            "epoch 35 step 70 loss 1.528908371925354\n",
            "epoch 35 step 71 loss 1.5307190418243408\n",
            "epoch 35 step 72 loss 1.5210939645767212\n",
            "epoch 35 step 73 loss 1.5170855522155762\n",
            "epoch 35 step 74 loss 1.5246448516845703\n",
            "epoch 35 step 75 loss 1.4885454177856445\n",
            "epoch 35 step 76 loss 1.5210243463516235\n",
            "epoch 35 step 77 loss 1.5005366802215576\n",
            "epoch 35 step 78 loss 1.5153180360794067\n",
            "epoch 35 step 79 loss 1.5129871368408203\n",
            "epoch 35 step 80 loss 1.5254181623458862 test_accuracy 76.0 train_accuracy 96.875\n",
            "epoch 35 step 81 loss 1.4827468395233154\n",
            "epoch 35 step 82 loss 1.5085182189941406\n",
            "epoch 35 step 83 loss 1.5080806016921997\n",
            "epoch 35 step 84 loss 1.5210438966751099\n",
            "epoch 35 step 85 loss 1.5379825830459595\n",
            "epoch 35 step 86 loss 1.5387572050094604\n",
            "epoch 35 step 87 loss 1.523245096206665\n",
            "epoch 35 step 88 loss 1.5193839073181152\n",
            "epoch 35 step 89 loss 1.5402919054031372\n",
            "epoch 35 step 90 loss 1.4990990161895752\n",
            "epoch 35 step 91 loss 1.5064315795898438\n",
            "epoch 35 step 92 loss 1.5173763036727905\n",
            "epoch 35 step 93 loss 1.4865061044692993\n",
            "epoch 35 step 94 loss 1.5371065139770508\n",
            "epoch 35 step 95 loss 1.5188617706298828\n",
            "epoch 35 step 96 loss 1.5290718078613281\n",
            "epoch 35 step 97 loss 1.506680965423584\n",
            "epoch 35 step 98 loss 1.5163934230804443\n",
            "epoch 35 step 99 loss 1.49628484249115\n",
            "epoch 35 step 100 loss 1.5383071899414062 test_accuracy 76.20000457763672 train_accuracy 96.09375\n",
            "epoch 35 step 101 loss 1.5178124904632568\n",
            "epoch 35 step 102 loss 1.4951390027999878\n",
            "epoch 35 step 103 loss 1.4931490421295166\n",
            "epoch 35 step 104 loss 1.513418436050415\n",
            "epoch 35 step 105 loss 1.514519214630127\n",
            "epoch 35 step 106 loss 1.500487208366394\n",
            "epoch 35 step 107 loss 1.4832345247268677\n",
            "epoch 35 step 108 loss 1.5077402591705322\n",
            "epoch 35 step 109 loss 1.522430419921875\n",
            "epoch 35 step 110 loss 1.503577470779419\n",
            "epoch 35 step 111 loss 1.5310592651367188\n",
            "epoch 35 step 112 loss 1.4958709478378296\n",
            "epoch 35 step 113 loss 1.5019832849502563\n",
            "epoch 35 step 114 loss 1.4961086511611938\n",
            "epoch 35 step 115 loss 1.522692322731018\n",
            "epoch 35 step 116 loss 1.4898730516433716\n",
            "epoch 35 step 117 loss 1.4964832067489624\n",
            "epoch 35 step 118 loss 1.5454713106155396\n",
            "epoch 35 step 119 loss 1.4778964519500732\n",
            "epoch 35 step 120 loss 1.4875978231430054 test_accuracy 75.4000015258789 train_accuracy 94.53125\n",
            "epoch 35 step 121 loss 1.5334500074386597\n",
            "epoch 35 step 122 loss 1.5016813278198242\n",
            "epoch 35 step 123 loss 1.5195001363754272\n",
            "epoch 35 step 124 loss 1.501381754875183\n",
            "epoch 35 step 125 loss 1.5014231204986572\n",
            "epoch 35 step 126 loss 1.508531093597412\n",
            "epoch 35 step 127 loss 1.5161991119384766\n",
            "epoch 35 step 128 loss 1.523380160331726\n",
            "epoch 35 step 129 loss 1.4925915002822876\n",
            "epoch 35 step 130 loss 1.494587779045105\n",
            "epoch 35 step 131 loss 1.4919674396514893\n",
            "epoch 35 step 132 loss 1.5037373304367065\n",
            "epoch 35 step 133 loss 1.5024492740631104\n",
            "epoch 35 step 134 loss 1.547710657119751\n",
            "epoch 35 step 135 loss 1.526193380355835\n",
            "epoch 35 step 136 loss 1.490254282951355\n",
            "epoch 35 step 137 loss 1.5055097341537476\n",
            "epoch 35 step 138 loss 1.4979006052017212\n",
            "epoch 35 step 139 loss 1.4943373203277588\n",
            "epoch 35 step 140 loss 1.5332380533218384 test_accuracy 76.0 train_accuracy 95.3125\n",
            "epoch 35 step 141 loss 1.500982403755188\n",
            "epoch 35 step 142 loss 1.4896936416625977\n",
            "epoch 35 step 143 loss 1.493283748626709\n",
            "epoch 35 step 144 loss 1.5054045915603638\n",
            "epoch 35 step 145 loss 1.4947052001953125\n",
            "epoch 35 step 146 loss 1.5032241344451904\n",
            "epoch 35 step 147 loss 1.5063385963439941\n",
            "epoch 35 step 148 loss 1.5146112442016602\n",
            "epoch 35 step 149 loss 1.4813376665115356\n",
            "epoch 35 step 150 loss 1.5012258291244507\n",
            "epoch 35 step 151 loss 1.4742580652236938\n",
            "epoch 35 step 152 loss 1.493890404701233\n",
            "epoch 35 step 153 loss 1.4613847732543945\n",
            "epoch 35 step 154 loss 1.5352299213409424\n",
            "epoch 35 step 155 loss 1.5098093748092651\n",
            "epoch 35 step 156 loss 1.5093902349472046\n",
            "epoch 35 step 157 loss 1.4833974838256836\n",
            "epoch 35 step 158 loss 1.5166610479354858\n",
            "epoch 35 step 159 loss 1.4854657649993896\n",
            "epoch 35 step 160 loss 1.5368458032608032 test_accuracy 76.4000015258789 train_accuracy 97.65625\n",
            "epoch 35 step 161 loss 1.5133534669876099\n",
            "epoch 35 step 162 loss 1.4971052408218384\n",
            "epoch 35 step 163 loss 1.4870238304138184\n",
            "epoch 35 step 164 loss 1.4878273010253906\n",
            "epoch 35 step 165 loss 1.5117709636688232\n",
            "epoch 35 step 166 loss 1.5052881240844727\n",
            "epoch 35 step 167 loss 1.5294164419174194\n",
            "epoch 35 step 168 loss 1.525025725364685\n",
            "epoch 35 step 169 loss 1.5019397735595703\n",
            "epoch 35 step 170 loss 1.524158239364624\n",
            "epoch 35 step 171 loss 1.5314749479293823\n",
            "epoch 35 step 172 loss 1.5070171356201172\n",
            "epoch 35 step 173 loss 1.491358995437622\n",
            "epoch 35 step 174 loss 1.5277212858200073\n",
            "epoch 35 step 175 loss 1.547903299331665\n",
            "epoch 35 step 176 loss 1.522816777229309\n",
            "epoch 35 step 177 loss 1.5332916975021362\n",
            "epoch 35 step 178 loss 1.5020244121551514\n",
            "epoch 35 step 179 loss 1.50927734375\n",
            "epoch 35 step 180 loss 1.4993144273757935 test_accuracy 75.80000305175781 train_accuracy 94.53125\n",
            "epoch 35 step 181 loss 1.5585086345672607\n",
            "epoch 35 step 182 loss 1.5104314088821411\n",
            "epoch 35 step 183 loss 1.5109190940856934\n",
            "epoch 35 step 184 loss 1.554430603981018\n",
            "epoch 35 step 185 loss 1.490240216255188\n",
            "epoch 36 step 0 loss 1.5151606798171997 test_accuracy 76.0 train_accuracy 95.3125\n",
            "epoch 36 step 1 loss 1.5139347314834595\n",
            "epoch 36 step 2 loss 1.5327544212341309\n",
            "epoch 36 step 3 loss 1.4927419424057007\n",
            "epoch 36 step 4 loss 1.5040630102157593\n",
            "epoch 36 step 5 loss 1.5179152488708496\n",
            "epoch 36 step 6 loss 1.5019140243530273\n",
            "epoch 36 step 7 loss 1.5463098287582397\n",
            "epoch 36 step 8 loss 1.5238752365112305\n",
            "epoch 36 step 9 loss 1.4996237754821777\n",
            "epoch 36 step 10 loss 1.516756534576416\n",
            "epoch 36 step 11 loss 1.5088164806365967\n",
            "epoch 36 step 12 loss 1.4964940547943115\n",
            "epoch 36 step 13 loss 1.5087366104125977\n",
            "epoch 36 step 14 loss 1.4901177883148193\n",
            "epoch 36 step 15 loss 1.5287327766418457\n",
            "epoch 36 step 16 loss 1.4994491338729858\n",
            "epoch 36 step 17 loss 1.4834134578704834\n",
            "epoch 36 step 18 loss 1.5082097053527832\n",
            "epoch 36 step 19 loss 1.4882206916809082\n",
            "epoch 36 step 20 loss 1.5036044120788574 test_accuracy 75.80000305175781 train_accuracy 96.875\n",
            "epoch 36 step 21 loss 1.52377450466156\n",
            "epoch 36 step 22 loss 1.4939075708389282\n",
            "epoch 36 step 23 loss 1.5034130811691284\n",
            "epoch 36 step 24 loss 1.5123815536499023\n",
            "epoch 36 step 25 loss 1.522629737854004\n",
            "epoch 36 step 26 loss 1.5081409215927124\n",
            "epoch 36 step 27 loss 1.4966837167739868\n",
            "epoch 36 step 28 loss 1.4912703037261963\n",
            "epoch 36 step 29 loss 1.5394344329833984\n",
            "epoch 36 step 30 loss 1.478980541229248\n",
            "epoch 36 step 31 loss 1.5184156894683838\n",
            "epoch 36 step 32 loss 1.5151951313018799\n",
            "epoch 36 step 33 loss 1.5130910873413086\n",
            "epoch 36 step 34 loss 1.5297961235046387\n",
            "epoch 36 step 35 loss 1.5024765729904175\n",
            "epoch 36 step 36 loss 1.5242910385131836\n",
            "epoch 36 step 37 loss 1.503348708152771\n",
            "epoch 36 step 38 loss 1.4953830242156982\n",
            "epoch 36 step 39 loss 1.5621447563171387\n",
            "epoch 36 step 40 loss 1.5237752199172974 test_accuracy 76.20000457763672 train_accuracy 95.3125\n",
            "epoch 36 step 41 loss 1.5199381113052368\n",
            "epoch 36 step 42 loss 1.522377371788025\n",
            "epoch 36 step 43 loss 1.500464916229248\n",
            "epoch 36 step 44 loss 1.5025357007980347\n",
            "epoch 36 step 45 loss 1.5291714668273926\n",
            "epoch 36 step 46 loss 1.5233347415924072\n",
            "epoch 36 step 47 loss 1.5197046995162964\n",
            "epoch 36 step 48 loss 1.5353050231933594\n",
            "epoch 36 step 49 loss 1.5312188863754272\n",
            "epoch 36 step 50 loss 1.4853297472000122\n",
            "epoch 36 step 51 loss 1.5422452688217163\n",
            "epoch 36 step 52 loss 1.5177315473556519\n",
            "epoch 36 step 53 loss 1.4945930242538452\n",
            "epoch 36 step 54 loss 1.4969964027404785\n",
            "epoch 36 step 55 loss 1.5137187242507935\n",
            "epoch 36 step 56 loss 1.4703645706176758\n",
            "epoch 36 step 57 loss 1.505145788192749\n",
            "epoch 36 step 58 loss 1.5100083351135254\n",
            "epoch 36 step 59 loss 1.523376226425171\n",
            "epoch 36 step 60 loss 1.4942489862442017 test_accuracy 76.20000457763672 train_accuracy 97.65625\n",
            "epoch 36 step 61 loss 1.511617660522461\n",
            "epoch 36 step 62 loss 1.4798359870910645\n",
            "epoch 36 step 63 loss 1.4900391101837158\n",
            "epoch 36 step 64 loss 1.5152547359466553\n",
            "epoch 36 step 65 loss 1.495375633239746\n",
            "epoch 36 step 66 loss 1.4930535554885864\n",
            "epoch 36 step 67 loss 1.487642526626587\n",
            "epoch 36 step 68 loss 1.5126363039016724\n",
            "epoch 36 step 69 loss 1.557163953781128\n",
            "epoch 36 step 70 loss 1.5007178783416748\n",
            "epoch 36 step 71 loss 1.5326799154281616\n",
            "epoch 36 step 72 loss 1.5300567150115967\n",
            "epoch 36 step 73 loss 1.5641164779663086\n",
            "epoch 36 step 74 loss 1.486732006072998\n",
            "epoch 36 step 75 loss 1.498189091682434\n",
            "epoch 36 step 76 loss 1.5273382663726807\n",
            "epoch 36 step 77 loss 1.4886436462402344\n",
            "epoch 36 step 78 loss 1.5323331356048584\n",
            "epoch 36 step 79 loss 1.5252760648727417\n",
            "epoch 36 step 80 loss 1.5019917488098145 test_accuracy 75.4000015258789 train_accuracy 96.875\n",
            "epoch 36 step 81 loss 1.5243775844573975\n",
            "epoch 36 step 82 loss 1.4994760751724243\n",
            "epoch 36 step 83 loss 1.4733953475952148\n",
            "epoch 36 step 84 loss 1.5153160095214844\n",
            "epoch 36 step 85 loss 1.4982606172561646\n",
            "epoch 36 step 86 loss 1.5082870721817017\n",
            "epoch 36 step 87 loss 1.5101096630096436\n",
            "epoch 36 step 88 loss 1.4967631101608276\n",
            "epoch 36 step 89 loss 1.475314736366272\n",
            "epoch 36 step 90 loss 1.5093610286712646\n",
            "epoch 36 step 91 loss 1.492999792098999\n",
            "epoch 36 step 92 loss 1.509644865989685\n",
            "epoch 36 step 93 loss 1.49125337600708\n",
            "epoch 36 step 94 loss 1.51860511302948\n",
            "epoch 36 step 95 loss 1.502034068107605\n",
            "epoch 36 step 96 loss 1.482286810874939\n",
            "epoch 36 step 97 loss 1.4810185432434082\n",
            "epoch 36 step 98 loss 1.497999906539917\n",
            "epoch 36 step 99 loss 1.4789739847183228\n",
            "epoch 36 step 100 loss 1.5097389221191406 test_accuracy 76.20000457763672 train_accuracy 97.65625\n",
            "epoch 36 step 101 loss 1.543480634689331\n",
            "epoch 36 step 102 loss 1.5214762687683105\n",
            "epoch 36 step 103 loss 1.4905872344970703\n",
            "epoch 36 step 104 loss 1.5077364444732666\n",
            "epoch 36 step 105 loss 1.4916282892227173\n",
            "epoch 36 step 106 loss 1.5308842658996582\n",
            "epoch 36 step 107 loss 1.5030583143234253\n",
            "epoch 36 step 108 loss 1.5353554487228394\n",
            "epoch 36 step 109 loss 1.5214463472366333\n",
            "epoch 36 step 110 loss 1.4928598403930664\n",
            "epoch 36 step 111 loss 1.5117580890655518\n",
            "epoch 36 step 112 loss 1.5032873153686523\n",
            "epoch 36 step 113 loss 1.5083028078079224\n",
            "epoch 36 step 114 loss 1.4950666427612305\n",
            "epoch 36 step 115 loss 1.5373804569244385\n",
            "epoch 36 step 116 loss 1.5091807842254639\n",
            "epoch 36 step 117 loss 1.5269594192504883\n",
            "epoch 36 step 118 loss 1.4800901412963867\n",
            "epoch 36 step 119 loss 1.5428202152252197\n",
            "epoch 36 step 120 loss 1.5285098552703857 test_accuracy 76.20000457763672 train_accuracy 97.65625\n",
            "epoch 36 step 121 loss 1.4918817281723022\n",
            "epoch 36 step 122 loss 1.5151230096817017\n",
            "epoch 36 step 123 loss 1.5183134078979492\n",
            "epoch 36 step 124 loss 1.523484706878662\n",
            "epoch 36 step 125 loss 1.497030258178711\n",
            "epoch 36 step 126 loss 1.4876809120178223\n",
            "epoch 36 step 127 loss 1.5021439790725708\n",
            "epoch 36 step 128 loss 1.5001999139785767\n",
            "epoch 36 step 129 loss 1.509310007095337\n",
            "epoch 36 step 130 loss 1.5085523128509521\n",
            "epoch 36 step 131 loss 1.5015320777893066\n",
            "epoch 36 step 132 loss 1.4921350479125977\n",
            "epoch 36 step 133 loss 1.4973400831222534\n",
            "epoch 36 step 134 loss 1.5193229913711548\n",
            "epoch 36 step 135 loss 1.5194321870803833\n",
            "epoch 36 step 136 loss 1.5128591060638428\n",
            "epoch 36 step 137 loss 1.4837701320648193\n",
            "epoch 36 step 138 loss 1.5015933513641357\n",
            "epoch 36 step 139 loss 1.4857012033462524\n",
            "epoch 36 step 140 loss 1.4940769672393799 test_accuracy 76.0 train_accuracy 96.875\n",
            "epoch 36 step 141 loss 1.4802372455596924\n",
            "epoch 36 step 142 loss 1.5206390619277954\n",
            "epoch 36 step 143 loss 1.5035053491592407\n",
            "epoch 36 step 144 loss 1.500880479812622\n",
            "epoch 36 step 145 loss 1.5378637313842773\n",
            "epoch 36 step 146 loss 1.5052874088287354\n",
            "epoch 36 step 147 loss 1.5040051937103271\n",
            "epoch 36 step 148 loss 1.4943774938583374\n",
            "epoch 36 step 149 loss 1.4977608919143677\n",
            "epoch 36 step 150 loss 1.4709765911102295\n",
            "epoch 36 step 151 loss 1.4982565641403198\n",
            "epoch 36 step 152 loss 1.4887608289718628\n",
            "epoch 36 step 153 loss 1.4838893413543701\n",
            "epoch 36 step 154 loss 1.5075515508651733\n",
            "epoch 36 step 155 loss 1.5088262557983398\n",
            "epoch 36 step 156 loss 1.498094916343689\n",
            "epoch 36 step 157 loss 1.524985671043396\n",
            "epoch 36 step 158 loss 1.5358737707138062\n",
            "epoch 36 step 159 loss 1.5222108364105225\n",
            "epoch 36 step 160 loss 1.5068353414535522 test_accuracy 76.0 train_accuracy 96.875\n",
            "epoch 36 step 161 loss 1.5090693235397339\n",
            "epoch 36 step 162 loss 1.5074164867401123\n",
            "epoch 36 step 163 loss 1.5203360319137573\n",
            "epoch 36 step 164 loss 1.5317963361740112\n",
            "epoch 36 step 165 loss 1.496405005455017\n",
            "epoch 36 step 166 loss 1.5225194692611694\n",
            "epoch 36 step 167 loss 1.504701018333435\n",
            "epoch 36 step 168 loss 1.514734148979187\n",
            "epoch 36 step 169 loss 1.4973303079605103\n",
            "epoch 36 step 170 loss 1.5221043825149536\n",
            "epoch 36 step 171 loss 1.478652834892273\n",
            "epoch 36 step 172 loss 1.5145419836044312\n",
            "epoch 36 step 173 loss 1.4821398258209229\n",
            "epoch 36 step 174 loss 1.5079478025436401\n",
            "epoch 36 step 175 loss 1.5046932697296143\n",
            "epoch 36 step 176 loss 1.5285584926605225\n",
            "epoch 36 step 177 loss 1.521475076675415\n",
            "epoch 36 step 178 loss 1.5100630521774292\n",
            "epoch 36 step 179 loss 1.4943486452102661\n",
            "epoch 36 step 180 loss 1.5223129987716675 test_accuracy 76.4000015258789 train_accuracy 97.65625\n",
            "epoch 36 step 181 loss 1.4881656169891357\n",
            "epoch 36 step 182 loss 1.5044329166412354\n",
            "epoch 36 step 183 loss 1.538952350616455\n",
            "epoch 36 step 184 loss 1.4992828369140625\n",
            "epoch 36 step 185 loss 1.4644125699996948\n",
            "epoch 37 step 0 loss 1.5195648670196533 test_accuracy 76.4000015258789 train_accuracy 95.3125\n",
            "epoch 37 step 1 loss 1.5129902362823486\n",
            "epoch 37 step 2 loss 1.485605239868164\n",
            "epoch 37 step 3 loss 1.5081439018249512\n",
            "epoch 37 step 4 loss 1.5328037738800049\n",
            "epoch 37 step 5 loss 1.4832539558410645\n",
            "epoch 37 step 6 loss 1.502609133720398\n",
            "epoch 37 step 7 loss 1.5092966556549072\n",
            "epoch 37 step 8 loss 1.4780818223953247\n",
            "epoch 37 step 9 loss 1.505106806755066\n",
            "epoch 37 step 10 loss 1.5175367593765259\n",
            "epoch 37 step 11 loss 1.5003631114959717\n",
            "epoch 37 step 12 loss 1.5093361139297485\n",
            "epoch 37 step 13 loss 1.5499616861343384\n",
            "epoch 37 step 14 loss 1.5074424743652344\n",
            "epoch 37 step 15 loss 1.5054807662963867\n",
            "epoch 37 step 16 loss 1.5147470235824585\n",
            "epoch 37 step 17 loss 1.5042526721954346\n",
            "epoch 37 step 18 loss 1.5015382766723633\n",
            "epoch 37 step 19 loss 1.5172022581100464\n",
            "epoch 37 step 20 loss 1.5067559480667114 test_accuracy 76.60000610351562 train_accuracy 94.53125\n",
            "epoch 37 step 21 loss 1.4877179861068726\n",
            "epoch 37 step 22 loss 1.526260256767273\n",
            "epoch 37 step 23 loss 1.4938305616378784\n",
            "epoch 37 step 24 loss 1.5134902000427246\n",
            "epoch 37 step 25 loss 1.5123316049575806\n",
            "epoch 37 step 26 loss 1.510353922843933\n",
            "epoch 37 step 27 loss 1.4804238080978394\n",
            "epoch 37 step 28 loss 1.5016382932662964\n",
            "epoch 37 step 29 loss 1.5082364082336426\n",
            "epoch 37 step 30 loss 1.5186887979507446\n",
            "epoch 37 step 31 loss 1.502443790435791\n",
            "epoch 37 step 32 loss 1.504320502281189\n",
            "epoch 37 step 33 loss 1.5170649290084839\n",
            "epoch 37 step 34 loss 1.5011566877365112\n",
            "epoch 37 step 35 loss 1.541684627532959\n",
            "epoch 37 step 36 loss 1.5241509675979614\n",
            "epoch 37 step 37 loss 1.5365277528762817\n",
            "epoch 37 step 38 loss 1.524754285812378\n",
            "epoch 37 step 39 loss 1.5187923908233643\n",
            "epoch 37 step 40 loss 1.4931641817092896 test_accuracy 76.60000610351562 train_accuracy 95.3125\n",
            "epoch 37 step 41 loss 1.4906843900680542\n",
            "epoch 37 step 42 loss 1.4953434467315674\n",
            "epoch 37 step 43 loss 1.5131336450576782\n",
            "epoch 37 step 44 loss 1.4934252500534058\n",
            "epoch 37 step 45 loss 1.5200198888778687\n",
            "epoch 37 step 46 loss 1.5002119541168213\n",
            "epoch 37 step 47 loss 1.5020595788955688\n",
            "epoch 37 step 48 loss 1.4944113492965698\n",
            "epoch 37 step 49 loss 1.505069375038147\n",
            "epoch 37 step 50 loss 1.571565866470337\n",
            "epoch 37 step 51 loss 1.4921066761016846\n",
            "epoch 37 step 52 loss 1.5049786567687988\n",
            "epoch 37 step 53 loss 1.478163480758667\n",
            "epoch 37 step 54 loss 1.5064860582351685\n",
            "epoch 37 step 55 loss 1.502333402633667\n",
            "epoch 37 step 56 loss 1.5445680618286133\n",
            "epoch 37 step 57 loss 1.4860413074493408\n",
            "epoch 37 step 58 loss 1.491747498512268\n",
            "epoch 37 step 59 loss 1.5214983224868774\n",
            "epoch 37 step 60 loss 1.5187959671020508 test_accuracy 76.0 train_accuracy 95.3125\n",
            "epoch 37 step 61 loss 1.5152443647384644\n",
            "epoch 37 step 62 loss 1.5303997993469238\n",
            "epoch 37 step 63 loss 1.5222878456115723\n",
            "epoch 37 step 64 loss 1.5018589496612549\n",
            "epoch 37 step 65 loss 1.5273634195327759\n",
            "epoch 37 step 66 loss 1.491040825843811\n",
            "epoch 37 step 67 loss 1.503403663635254\n",
            "epoch 37 step 68 loss 1.5042753219604492\n",
            "epoch 37 step 69 loss 1.5077167749404907\n",
            "epoch 37 step 70 loss 1.4811917543411255\n",
            "epoch 37 step 71 loss 1.5306123495101929\n",
            "epoch 37 step 72 loss 1.5019949674606323\n",
            "epoch 37 step 73 loss 1.5285077095031738\n",
            "epoch 37 step 74 loss 1.5005179643630981\n",
            "epoch 37 step 75 loss 1.4975169897079468\n",
            "epoch 37 step 76 loss 1.4787176847457886\n",
            "epoch 37 step 77 loss 1.520903468132019\n",
            "epoch 37 step 78 loss 1.5210487842559814\n",
            "epoch 37 step 79 loss 1.4863831996917725\n",
            "epoch 37 step 80 loss 1.493484377861023 test_accuracy 76.4000015258789 train_accuracy 96.09375\n",
            "epoch 37 step 81 loss 1.4823527336120605\n",
            "epoch 37 step 82 loss 1.5113425254821777\n",
            "epoch 37 step 83 loss 1.502126693725586\n",
            "epoch 37 step 84 loss 1.488001823425293\n",
            "epoch 37 step 85 loss 1.508723497390747\n",
            "epoch 37 step 86 loss 1.5186513662338257\n",
            "epoch 37 step 87 loss 1.500848650932312\n",
            "epoch 37 step 88 loss 1.5304160118103027\n",
            "epoch 37 step 89 loss 1.520364761352539\n",
            "epoch 37 step 90 loss 1.5276468992233276\n",
            "epoch 37 step 91 loss 1.5466846227645874\n",
            "epoch 37 step 92 loss 1.4940603971481323\n",
            "epoch 37 step 93 loss 1.5262845754623413\n",
            "epoch 37 step 94 loss 1.4935415983200073\n",
            "epoch 37 step 95 loss 1.490454912185669\n",
            "epoch 37 step 96 loss 1.4970966577529907\n",
            "epoch 37 step 97 loss 1.4938360452651978\n",
            "epoch 37 step 98 loss 1.5085816383361816\n",
            "epoch 37 step 99 loss 1.5089819431304932\n",
            "epoch 37 step 100 loss 1.5232757329940796 test_accuracy 75.60000610351562 train_accuracy 92.96875\n",
            "epoch 37 step 101 loss 1.492788314819336\n",
            "epoch 37 step 102 loss 1.4979331493377686\n",
            "epoch 37 step 103 loss 1.4988752603530884\n",
            "epoch 37 step 104 loss 1.4925084114074707\n",
            "epoch 37 step 105 loss 1.504037618637085\n",
            "epoch 37 step 106 loss 1.5015180110931396\n",
            "epoch 37 step 107 loss 1.4944740533828735\n",
            "epoch 37 step 108 loss 1.5190231800079346\n",
            "epoch 37 step 109 loss 1.5210561752319336\n",
            "epoch 37 step 110 loss 1.4940338134765625\n",
            "epoch 37 step 111 loss 1.525639533996582\n",
            "epoch 37 step 112 loss 1.4976755380630493\n",
            "epoch 37 step 113 loss 1.4799190759658813\n",
            "epoch 37 step 114 loss 1.517194390296936\n",
            "epoch 37 step 115 loss 1.5021562576293945\n",
            "epoch 37 step 116 loss 1.5060460567474365\n",
            "epoch 37 step 117 loss 1.5183448791503906\n",
            "epoch 37 step 118 loss 1.484241008758545\n",
            "epoch 37 step 119 loss 1.5135719776153564\n",
            "epoch 37 step 120 loss 1.518329381942749 test_accuracy 76.20000457763672 train_accuracy 96.875\n",
            "epoch 37 step 121 loss 1.5165164470672607\n",
            "epoch 37 step 122 loss 1.4937708377838135\n",
            "epoch 37 step 123 loss 1.5123343467712402\n",
            "epoch 37 step 124 loss 1.5041812658309937\n",
            "epoch 37 step 125 loss 1.4996765851974487\n",
            "epoch 37 step 126 loss 1.4930686950683594\n",
            "epoch 37 step 127 loss 1.4871532917022705\n",
            "epoch 37 step 128 loss 1.4836622476577759\n",
            "epoch 37 step 129 loss 1.5158203840255737\n",
            "epoch 37 step 130 loss 1.502819299697876\n",
            "epoch 37 step 131 loss 1.5116918087005615\n",
            "epoch 37 step 132 loss 1.4937231540679932\n",
            "epoch 37 step 133 loss 1.508038878440857\n",
            "epoch 37 step 134 loss 1.5151124000549316\n",
            "epoch 37 step 135 loss 1.5003557205200195\n",
            "epoch 37 step 136 loss 1.4881685972213745\n",
            "epoch 37 step 137 loss 1.5056811571121216\n",
            "epoch 37 step 138 loss 1.4818092584609985\n",
            "epoch 37 step 139 loss 1.4990756511688232\n",
            "epoch 37 step 140 loss 1.4868226051330566 test_accuracy 76.20000457763672 train_accuracy 94.53125\n",
            "epoch 37 step 141 loss 1.4917880296707153\n",
            "epoch 37 step 142 loss 1.4937763214111328\n",
            "epoch 37 step 143 loss 1.510002613067627\n",
            "epoch 37 step 144 loss 1.518283486366272\n",
            "epoch 37 step 145 loss 1.528306484222412\n",
            "epoch 37 step 146 loss 1.521012783050537\n",
            "epoch 37 step 147 loss 1.4863307476043701\n",
            "epoch 37 step 148 loss 1.475504755973816\n",
            "epoch 37 step 149 loss 1.496262788772583\n",
            "epoch 37 step 150 loss 1.4848312139511108\n",
            "epoch 37 step 151 loss 1.5010862350463867\n",
            "epoch 37 step 152 loss 1.4941198825836182\n",
            "epoch 37 step 153 loss 1.5036892890930176\n",
            "epoch 37 step 154 loss 1.5092848539352417\n",
            "epoch 37 step 155 loss 1.5137676000595093\n",
            "epoch 37 step 156 loss 1.52638840675354\n",
            "epoch 37 step 157 loss 1.5112700462341309\n",
            "epoch 37 step 158 loss 1.4923548698425293\n",
            "epoch 37 step 159 loss 1.5354751348495483\n",
            "epoch 37 step 160 loss 1.5128517150878906 test_accuracy 76.4000015258789 train_accuracy 92.96875\n",
            "epoch 37 step 161 loss 1.4797860383987427\n",
            "epoch 37 step 162 loss 1.4874897003173828\n",
            "epoch 37 step 163 loss 1.5027614831924438\n",
            "epoch 37 step 164 loss 1.5108264684677124\n",
            "epoch 37 step 165 loss 1.4990638494491577\n",
            "epoch 37 step 166 loss 1.5352541208267212\n",
            "epoch 37 step 167 loss 1.4923253059387207\n",
            "epoch 37 step 168 loss 1.48707914352417\n",
            "epoch 37 step 169 loss 1.503770351409912\n",
            "epoch 37 step 170 loss 1.5007598400115967\n",
            "epoch 37 step 171 loss 1.4781543016433716\n",
            "epoch 37 step 172 loss 1.5061875581741333\n",
            "epoch 37 step 173 loss 1.5082409381866455\n",
            "epoch 37 step 174 loss 1.4990941286087036\n",
            "epoch 37 step 175 loss 1.5379856824874878\n",
            "epoch 37 step 176 loss 1.5323339700698853\n",
            "epoch 37 step 177 loss 1.5139410495758057\n",
            "epoch 37 step 178 loss 1.5009082555770874\n",
            "epoch 37 step 179 loss 1.504684329032898\n",
            "epoch 37 step 180 loss 1.4932277202606201 test_accuracy 76.80000305175781 train_accuracy 97.65625\n",
            "epoch 37 step 181 loss 1.4961276054382324\n",
            "epoch 37 step 182 loss 1.5489706993103027\n",
            "epoch 37 step 183 loss 1.4959604740142822\n",
            "epoch 37 step 184 loss 1.5426523685455322\n",
            "epoch 37 step 185 loss 1.5595365762710571\n",
            "epoch 38 step 0 loss 1.5175524950027466 test_accuracy 76.80000305175781 train_accuracy 95.3125\n",
            "epoch 38 step 1 loss 1.5248937606811523\n",
            "epoch 38 step 2 loss 1.4772541522979736\n",
            "epoch 38 step 3 loss 1.526352047920227\n",
            "epoch 38 step 4 loss 1.4851118326187134\n",
            "epoch 38 step 5 loss 1.4908009767532349\n",
            "epoch 38 step 6 loss 1.5358834266662598\n",
            "epoch 38 step 7 loss 1.5060675144195557\n",
            "epoch 38 step 8 loss 1.5026391744613647\n",
            "epoch 38 step 9 loss 1.4928646087646484\n",
            "epoch 38 step 10 loss 1.5024828910827637\n",
            "epoch 38 step 11 loss 1.4908053874969482\n",
            "epoch 38 step 12 loss 1.4807389974594116\n",
            "epoch 38 step 13 loss 1.531863808631897\n",
            "epoch 38 step 14 loss 1.5146760940551758\n",
            "epoch 38 step 15 loss 1.4962611198425293\n",
            "epoch 38 step 16 loss 1.5102274417877197\n",
            "epoch 38 step 17 loss 1.487777829170227\n",
            "epoch 38 step 18 loss 1.5102684497833252\n",
            "epoch 38 step 19 loss 1.5340919494628906\n",
            "epoch 38 step 20 loss 1.5421050786972046 test_accuracy 77.20000457763672 train_accuracy 96.09375\n",
            "epoch 38 step 21 loss 1.4895836114883423\n",
            "epoch 38 step 22 loss 1.4777852296829224\n",
            "epoch 38 step 23 loss 1.5118547677993774\n",
            "epoch 38 step 24 loss 1.4851365089416504\n",
            "epoch 38 step 25 loss 1.5011605024337769\n",
            "epoch 38 step 26 loss 1.4798667430877686\n",
            "epoch 38 step 27 loss 1.4780253171920776\n",
            "epoch 38 step 28 loss 1.5009478330612183\n",
            "epoch 38 step 29 loss 1.5221995115280151\n",
            "epoch 38 step 30 loss 1.4931069612503052\n",
            "epoch 38 step 31 loss 1.5150578022003174\n",
            "epoch 38 step 32 loss 1.5188007354736328\n",
            "epoch 38 step 33 loss 1.5368223190307617\n",
            "epoch 38 step 34 loss 1.482744812965393\n",
            "epoch 38 step 35 loss 1.5266050100326538\n",
            "epoch 38 step 36 loss 1.5291709899902344\n",
            "epoch 38 step 37 loss 1.486578106880188\n",
            "epoch 38 step 38 loss 1.4857381582260132\n",
            "epoch 38 step 39 loss 1.4931591749191284\n",
            "epoch 38 step 40 loss 1.508879542350769 test_accuracy 77.0 train_accuracy 96.09375\n",
            "epoch 38 step 41 loss 1.5016443729400635\n",
            "epoch 38 step 42 loss 1.4857456684112549\n",
            "epoch 38 step 43 loss 1.4890450239181519\n",
            "epoch 38 step 44 loss 1.5159295797348022\n",
            "epoch 38 step 45 loss 1.5236049890518188\n",
            "epoch 38 step 46 loss 1.5065573453903198\n",
            "epoch 38 step 47 loss 1.499891996383667\n",
            "epoch 38 step 48 loss 1.5171722173690796\n",
            "epoch 38 step 49 loss 1.5157173871994019\n",
            "epoch 38 step 50 loss 1.4847745895385742\n",
            "epoch 38 step 51 loss 1.5176503658294678\n",
            "epoch 38 step 52 loss 1.4823158979415894\n",
            "epoch 38 step 53 loss 1.5115479230880737\n",
            "epoch 38 step 54 loss 1.525564193725586\n",
            "epoch 38 step 55 loss 1.510272741317749\n",
            "epoch 38 step 56 loss 1.508135437965393\n",
            "epoch 38 step 57 loss 1.5080198049545288\n",
            "epoch 38 step 58 loss 1.5104531049728394\n",
            "epoch 38 step 59 loss 1.522498369216919\n",
            "epoch 38 step 60 loss 1.5163524150848389 test_accuracy 76.80000305175781 train_accuracy 96.09375\n",
            "epoch 38 step 61 loss 1.5172510147094727\n",
            "epoch 38 step 62 loss 1.515147089958191\n",
            "epoch 38 step 63 loss 1.5244168043136597\n",
            "epoch 38 step 64 loss 1.5042345523834229\n",
            "epoch 38 step 65 loss 1.4928004741668701\n",
            "epoch 38 step 66 loss 1.5493285655975342\n",
            "epoch 38 step 67 loss 1.4765921831130981\n",
            "epoch 38 step 68 loss 1.4929983615875244\n",
            "epoch 38 step 69 loss 1.508383870124817\n",
            "epoch 38 step 70 loss 1.523375153541565\n",
            "epoch 38 step 71 loss 1.5314656496047974\n",
            "epoch 38 step 72 loss 1.5083813667297363\n",
            "epoch 38 step 73 loss 1.5102074146270752\n",
            "epoch 38 step 74 loss 1.5091931819915771\n",
            "epoch 38 step 75 loss 1.52955162525177\n",
            "epoch 38 step 76 loss 1.4991883039474487\n",
            "epoch 38 step 77 loss 1.5101779699325562\n",
            "epoch 38 step 78 loss 1.5129621028900146\n",
            "epoch 38 step 79 loss 1.5030267238616943\n",
            "epoch 38 step 80 loss 1.4857040643692017 test_accuracy 76.80000305175781 train_accuracy 94.53125\n",
            "epoch 38 step 81 loss 1.4885685443878174\n",
            "epoch 38 step 82 loss 1.499476671218872\n",
            "epoch 38 step 83 loss 1.5150465965270996\n",
            "epoch 38 step 84 loss 1.4905505180358887\n",
            "epoch 38 step 85 loss 1.5377001762390137\n",
            "epoch 38 step 86 loss 1.4865833520889282\n",
            "epoch 38 step 87 loss 1.5232980251312256\n",
            "epoch 38 step 88 loss 1.5182994604110718\n",
            "epoch 38 step 89 loss 1.4931215047836304\n",
            "epoch 38 step 90 loss 1.4945229291915894\n",
            "epoch 38 step 91 loss 1.5333164930343628\n",
            "epoch 38 step 92 loss 1.4978103637695312\n",
            "epoch 38 step 93 loss 1.5082863569259644\n",
            "epoch 38 step 94 loss 1.4886521100997925\n",
            "epoch 38 step 95 loss 1.5106159448623657\n",
            "epoch 38 step 96 loss 1.5085543394088745\n",
            "epoch 38 step 97 loss 1.4695274829864502\n",
            "epoch 38 step 98 loss 1.5123993158340454\n",
            "epoch 38 step 99 loss 1.507333517074585\n",
            "epoch 38 step 100 loss 1.511162281036377 test_accuracy 77.0 train_accuracy 98.4375\n",
            "epoch 38 step 101 loss 1.5112277269363403\n",
            "epoch 38 step 102 loss 1.5244624614715576\n",
            "epoch 38 step 103 loss 1.4909250736236572\n",
            "epoch 38 step 104 loss 1.4849741458892822\n",
            "epoch 38 step 105 loss 1.513495922088623\n",
            "epoch 38 step 106 loss 1.5205577611923218\n",
            "epoch 38 step 107 loss 1.4983237981796265\n",
            "epoch 38 step 108 loss 1.5017821788787842\n",
            "epoch 38 step 109 loss 1.4981938600540161\n",
            "epoch 38 step 110 loss 1.5230317115783691\n",
            "epoch 38 step 111 loss 1.4787921905517578\n",
            "epoch 38 step 112 loss 1.5164425373077393\n",
            "epoch 38 step 113 loss 1.5245219469070435\n",
            "epoch 38 step 114 loss 1.5023730993270874\n",
            "epoch 38 step 115 loss 1.5288196802139282\n",
            "epoch 38 step 116 loss 1.5225756168365479\n",
            "epoch 38 step 117 loss 1.48177969455719\n",
            "epoch 38 step 118 loss 1.5171772241592407\n",
            "epoch 38 step 119 loss 1.498261570930481\n",
            "epoch 38 step 120 loss 1.5104737281799316 test_accuracy 77.0 train_accuracy 95.3125\n",
            "epoch 38 step 121 loss 1.5123300552368164\n",
            "epoch 38 step 122 loss 1.4776090383529663\n",
            "epoch 38 step 123 loss 1.5147595405578613\n",
            "epoch 38 step 124 loss 1.5369024276733398\n",
            "epoch 38 step 125 loss 1.5140959024429321\n",
            "epoch 38 step 126 loss 1.4787465333938599\n",
            "epoch 38 step 127 loss 1.5131887197494507\n",
            "epoch 38 step 128 loss 1.5141676664352417\n",
            "epoch 38 step 129 loss 1.5120400190353394\n",
            "epoch 38 step 130 loss 1.5007874965667725\n",
            "epoch 38 step 131 loss 1.5283236503601074\n",
            "epoch 38 step 132 loss 1.508404016494751\n",
            "epoch 38 step 133 loss 1.4994269609451294\n",
            "epoch 38 step 134 loss 1.5256422758102417\n",
            "epoch 38 step 135 loss 1.5226600170135498\n",
            "epoch 38 step 136 loss 1.5122745037078857\n",
            "epoch 38 step 137 loss 1.4863735437393188\n",
            "epoch 38 step 138 loss 1.517600417137146\n",
            "epoch 38 step 139 loss 1.5077749490737915\n",
            "epoch 38 step 140 loss 1.508381962776184 test_accuracy 77.0 train_accuracy 97.65625\n",
            "epoch 38 step 141 loss 1.510622262954712\n",
            "epoch 38 step 142 loss 1.519099235534668\n",
            "epoch 38 step 143 loss 1.5118046998977661\n",
            "epoch 38 step 144 loss 1.5064079761505127\n",
            "epoch 38 step 145 loss 1.490805745124817\n",
            "epoch 38 step 146 loss 1.4949029684066772\n",
            "epoch 38 step 147 loss 1.4830341339111328\n",
            "epoch 38 step 148 loss 1.4867839813232422\n",
            "epoch 38 step 149 loss 1.5114524364471436\n",
            "epoch 38 step 150 loss 1.5140389204025269\n",
            "epoch 38 step 151 loss 1.534175992012024\n",
            "epoch 38 step 152 loss 1.5106754302978516\n",
            "epoch 38 step 153 loss 1.526086688041687\n",
            "epoch 38 step 154 loss 1.5159732103347778\n",
            "epoch 38 step 155 loss 1.5029520988464355\n",
            "epoch 38 step 156 loss 1.5011396408081055\n",
            "epoch 38 step 157 loss 1.4859704971313477\n",
            "epoch 38 step 158 loss 1.498557448387146\n",
            "epoch 38 step 159 loss 1.4925309419631958\n",
            "epoch 38 step 160 loss 1.4780125617980957 test_accuracy 76.60000610351562 train_accuracy 96.875\n",
            "epoch 38 step 161 loss 1.5392632484436035\n",
            "epoch 38 step 162 loss 1.5259594917297363\n",
            "epoch 38 step 163 loss 1.5138598680496216\n",
            "epoch 38 step 164 loss 1.52595055103302\n",
            "epoch 38 step 165 loss 1.5007855892181396\n",
            "epoch 38 step 166 loss 1.4859410524368286\n",
            "epoch 38 step 167 loss 1.4874876737594604\n",
            "epoch 38 step 168 loss 1.5412464141845703\n",
            "epoch 38 step 169 loss 1.5254186391830444\n",
            "epoch 38 step 170 loss 1.5114409923553467\n",
            "epoch 38 step 171 loss 1.5307788848876953\n",
            "epoch 38 step 172 loss 1.5086264610290527\n",
            "epoch 38 step 173 loss 1.5046395063400269\n",
            "epoch 38 step 174 loss 1.5352940559387207\n",
            "epoch 38 step 175 loss 1.5164092779159546\n",
            "epoch 38 step 176 loss 1.4946552515029907\n",
            "epoch 38 step 177 loss 1.4791501760482788\n",
            "epoch 38 step 178 loss 1.4787262678146362\n",
            "epoch 38 step 179 loss 1.5257705450057983\n",
            "epoch 38 step 180 loss 1.4995499849319458 test_accuracy 76.80000305175781 train_accuracy 96.09375\n",
            "epoch 38 step 181 loss 1.480239987373352\n",
            "epoch 38 step 182 loss 1.5401469469070435\n",
            "epoch 38 step 183 loss 1.504011869430542\n",
            "epoch 38 step 184 loss 1.4758551120758057\n",
            "epoch 38 step 185 loss 1.491285800933838\n",
            "epoch 39 step 0 loss 1.5061537027359009 test_accuracy 76.80000305175781 train_accuracy 96.09375\n",
            "epoch 39 step 1 loss 1.5254989862442017\n",
            "epoch 39 step 2 loss 1.5021767616271973\n",
            "epoch 39 step 3 loss 1.4942777156829834\n",
            "epoch 39 step 4 loss 1.5180367231369019\n",
            "epoch 39 step 5 loss 1.4928032159805298\n",
            "epoch 39 step 6 loss 1.5197242498397827\n",
            "epoch 39 step 7 loss 1.5081290006637573\n",
            "epoch 39 step 8 loss 1.5118260383605957\n",
            "epoch 39 step 9 loss 1.4924898147583008\n",
            "epoch 39 step 10 loss 1.4787129163742065\n",
            "epoch 39 step 11 loss 1.5080088376998901\n",
            "epoch 39 step 12 loss 1.47140634059906\n",
            "epoch 39 step 13 loss 1.48356032371521\n",
            "epoch 39 step 14 loss 1.5045307874679565\n",
            "epoch 39 step 15 loss 1.5338515043258667\n",
            "epoch 39 step 16 loss 1.4859899282455444\n",
            "epoch 39 step 17 loss 1.4799081087112427\n",
            "epoch 39 step 18 loss 1.5008704662322998\n",
            "epoch 39 step 19 loss 1.5096347332000732\n",
            "epoch 39 step 20 loss 1.5108635425567627 test_accuracy 76.80000305175781 train_accuracy 96.09375\n",
            "epoch 39 step 21 loss 1.516599178314209\n",
            "epoch 39 step 22 loss 1.5319668054580688\n",
            "epoch 39 step 23 loss 1.5089720487594604\n",
            "epoch 39 step 24 loss 1.4956032037734985\n",
            "epoch 39 step 25 loss 1.4944523572921753\n",
            "epoch 39 step 26 loss 1.524983525276184\n",
            "epoch 39 step 27 loss 1.5145078897476196\n",
            "epoch 39 step 28 loss 1.5208767652511597\n",
            "epoch 39 step 29 loss 1.4992551803588867\n",
            "epoch 39 step 30 loss 1.509328842163086\n",
            "epoch 39 step 31 loss 1.4973435401916504\n",
            "epoch 39 step 32 loss 1.5024223327636719\n",
            "epoch 39 step 33 loss 1.5239391326904297\n",
            "epoch 39 step 34 loss 1.5205538272857666\n",
            "epoch 39 step 35 loss 1.490494728088379\n",
            "epoch 39 step 36 loss 1.4878820180892944\n",
            "epoch 39 step 37 loss 1.5112435817718506\n",
            "epoch 39 step 38 loss 1.4948291778564453\n",
            "epoch 39 step 39 loss 1.5179364681243896\n",
            "epoch 39 step 40 loss 1.5166159868240356 test_accuracy 76.80000305175781 train_accuracy 96.09375\n",
            "epoch 39 step 41 loss 1.4883259534835815\n",
            "epoch 39 step 42 loss 1.5061440467834473\n",
            "epoch 39 step 43 loss 1.5260846614837646\n",
            "epoch 39 step 44 loss 1.4794241189956665\n",
            "epoch 39 step 45 loss 1.4821964502334595\n",
            "epoch 39 step 46 loss 1.5179885625839233\n",
            "epoch 39 step 47 loss 1.4928154945373535\n",
            "epoch 39 step 48 loss 1.5014179944992065\n",
            "epoch 39 step 49 loss 1.5390156507492065\n",
            "epoch 39 step 50 loss 1.519008994102478\n",
            "epoch 39 step 51 loss 1.5067873001098633\n",
            "epoch 39 step 52 loss 1.5522191524505615\n",
            "epoch 39 step 53 loss 1.4890121221542358\n",
            "epoch 39 step 54 loss 1.5330462455749512\n",
            "epoch 39 step 55 loss 1.5317744016647339\n",
            "epoch 39 step 56 loss 1.507972240447998\n",
            "epoch 39 step 57 loss 1.5326135158538818\n",
            "epoch 39 step 58 loss 1.5117601156234741\n",
            "epoch 39 step 59 loss 1.5053762197494507\n",
            "epoch 39 step 60 loss 1.5151888132095337 test_accuracy 77.0 train_accuracy 93.75\n",
            "epoch 39 step 61 loss 1.5225902795791626\n",
            "epoch 39 step 62 loss 1.4882351160049438\n",
            "epoch 39 step 63 loss 1.497684359550476\n",
            "epoch 39 step 64 loss 1.5105899572372437\n",
            "epoch 39 step 65 loss 1.5326805114746094\n",
            "epoch 39 step 66 loss 1.4803322553634644\n",
            "epoch 39 step 67 loss 1.5104726552963257\n",
            "epoch 39 step 68 loss 1.4923847913742065\n",
            "epoch 39 step 69 loss 1.502263069152832\n",
            "epoch 39 step 70 loss 1.5167392492294312\n",
            "epoch 39 step 71 loss 1.526304006576538\n",
            "epoch 39 step 72 loss 1.5307918787002563\n",
            "epoch 39 step 73 loss 1.5018244981765747\n",
            "epoch 39 step 74 loss 1.515668272972107\n",
            "epoch 39 step 75 loss 1.5017240047454834\n",
            "epoch 39 step 76 loss 1.508459210395813\n",
            "epoch 39 step 77 loss 1.501965880393982\n",
            "epoch 39 step 78 loss 1.5005388259887695\n",
            "epoch 39 step 79 loss 1.5352783203125\n",
            "epoch 39 step 80 loss 1.4869314432144165 test_accuracy 77.0 train_accuracy 96.875\n",
            "epoch 39 step 81 loss 1.51478910446167\n",
            "epoch 39 step 82 loss 1.5567169189453125\n",
            "epoch 39 step 83 loss 1.534196138381958\n",
            "epoch 39 step 84 loss 1.4936559200286865\n",
            "epoch 39 step 85 loss 1.5274786949157715\n",
            "epoch 39 step 86 loss 1.477649450302124\n",
            "epoch 39 step 87 loss 1.513296127319336\n",
            "epoch 39 step 88 loss 1.4867761135101318\n",
            "epoch 39 step 89 loss 1.494053602218628\n",
            "epoch 39 step 90 loss 1.487361192703247\n",
            "epoch 39 step 91 loss 1.5060055255889893\n",
            "epoch 39 step 92 loss 1.5053173303604126\n",
            "epoch 39 step 93 loss 1.5017154216766357\n",
            "epoch 39 step 94 loss 1.4854247570037842\n",
            "epoch 39 step 95 loss 1.4860965013504028\n",
            "epoch 39 step 96 loss 1.510938048362732\n",
            "epoch 39 step 97 loss 1.5322822332382202\n",
            "epoch 39 step 98 loss 1.5406955480575562\n",
            "epoch 39 step 99 loss 1.5185128450393677\n",
            "epoch 39 step 100 loss 1.5061979293823242 test_accuracy 76.4000015258789 train_accuracy 96.09375\n",
            "epoch 39 step 101 loss 1.4770617485046387\n",
            "epoch 39 step 102 loss 1.5227299928665161\n",
            "epoch 39 step 103 loss 1.5047736167907715\n",
            "epoch 39 step 104 loss 1.512080192565918\n",
            "epoch 39 step 105 loss 1.5339468717575073\n",
            "epoch 39 step 106 loss 1.4969059228897095\n",
            "epoch 39 step 107 loss 1.4926952123641968\n",
            "epoch 39 step 108 loss 1.5201702117919922\n",
            "epoch 39 step 109 loss 1.5193907022476196\n",
            "epoch 39 step 110 loss 1.5295401811599731\n",
            "epoch 39 step 111 loss 1.5045366287231445\n",
            "epoch 39 step 112 loss 1.5006217956542969\n",
            "epoch 39 step 113 loss 1.5165202617645264\n",
            "epoch 39 step 114 loss 1.5030593872070312\n",
            "epoch 39 step 115 loss 1.5521948337554932\n",
            "epoch 39 step 116 loss 1.5041502714157104\n",
            "epoch 39 step 117 loss 1.4856767654418945\n",
            "epoch 39 step 118 loss 1.4864673614501953\n",
            "epoch 39 step 119 loss 1.5001271963119507\n",
            "epoch 39 step 120 loss 1.5119420289993286 test_accuracy 76.4000015258789 train_accuracy 96.875\n",
            "epoch 39 step 121 loss 1.5082321166992188\n",
            "epoch 39 step 122 loss 1.535374402999878\n",
            "epoch 39 step 123 loss 1.507235050201416\n",
            "epoch 39 step 124 loss 1.5048353672027588\n",
            "epoch 39 step 125 loss 1.5397309064865112\n",
            "epoch 39 step 126 loss 1.487937092781067\n",
            "epoch 39 step 127 loss 1.487239122390747\n",
            "epoch 39 step 128 loss 1.4870609045028687\n",
            "epoch 39 step 129 loss 1.512316107749939\n",
            "epoch 39 step 130 loss 1.510299563407898\n",
            "epoch 39 step 131 loss 1.4842703342437744\n",
            "epoch 39 step 132 loss 1.4962553977966309\n",
            "epoch 39 step 133 loss 1.5229309797286987\n",
            "epoch 39 step 134 loss 1.4870182275772095\n",
            "epoch 39 step 135 loss 1.5294514894485474\n",
            "epoch 39 step 136 loss 1.4889596700668335\n",
            "epoch 39 step 137 loss 1.5001025199890137\n",
            "epoch 39 step 138 loss 1.5091006755828857\n",
            "epoch 39 step 139 loss 1.4924075603485107\n",
            "epoch 39 step 140 loss 1.509321928024292 test_accuracy 76.80000305175781 train_accuracy 95.3125\n",
            "epoch 39 step 141 loss 1.4987459182739258\n",
            "epoch 39 step 142 loss 1.5343669652938843\n",
            "epoch 39 step 143 loss 1.4773237705230713\n",
            "epoch 39 step 144 loss 1.5046963691711426\n",
            "epoch 39 step 145 loss 1.4860315322875977\n",
            "epoch 39 step 146 loss 1.5279462337493896\n",
            "epoch 39 step 147 loss 1.5015313625335693\n",
            "epoch 39 step 148 loss 1.5006837844848633\n",
            "epoch 39 step 149 loss 1.5133821964263916\n",
            "epoch 39 step 150 loss 1.4986790418624878\n",
            "epoch 39 step 151 loss 1.4971897602081299\n",
            "epoch 39 step 152 loss 1.5084036588668823\n",
            "epoch 39 step 153 loss 1.4893234968185425\n",
            "epoch 39 step 154 loss 1.479187250137329\n",
            "epoch 39 step 155 loss 1.494946002960205\n",
            "epoch 39 step 156 loss 1.4987971782684326\n",
            "epoch 39 step 157 loss 1.486345648765564\n",
            "epoch 39 step 158 loss 1.477720856666565\n",
            "epoch 39 step 159 loss 1.4866591691970825\n",
            "epoch 39 step 160 loss 1.5014592409133911 test_accuracy 77.0 train_accuracy 94.53125\n",
            "epoch 39 step 161 loss 1.4844313859939575\n",
            "epoch 39 step 162 loss 1.5044541358947754\n",
            "epoch 39 step 163 loss 1.485969066619873\n",
            "epoch 39 step 164 loss 1.4828397035598755\n",
            "epoch 39 step 165 loss 1.5276533365249634\n",
            "epoch 39 step 166 loss 1.4788323640823364\n",
            "epoch 39 step 167 loss 1.4884207248687744\n",
            "epoch 39 step 168 loss 1.524425983428955\n",
            "epoch 39 step 169 loss 1.5022822618484497\n",
            "epoch 39 step 170 loss 1.4858899116516113\n",
            "epoch 39 step 171 loss 1.525223970413208\n",
            "epoch 39 step 172 loss 1.4861736297607422\n",
            "epoch 39 step 173 loss 1.4979937076568604\n",
            "epoch 39 step 174 loss 1.5368363857269287\n",
            "epoch 39 step 175 loss 1.5161360502243042\n",
            "epoch 39 step 176 loss 1.5176128149032593\n",
            "epoch 39 step 177 loss 1.5134929418563843\n",
            "epoch 39 step 178 loss 1.5050677061080933\n",
            "epoch 39 step 179 loss 1.5003035068511963\n",
            "epoch 39 step 180 loss 1.554989218711853 test_accuracy 76.80000305175781 train_accuracy 92.1875\n",
            "epoch 39 step 181 loss 1.5081957578659058\n",
            "epoch 39 step 182 loss 1.4900535345077515\n",
            "epoch 39 step 183 loss 1.4964728355407715\n",
            "epoch 39 step 184 loss 1.4931690692901611\n",
            "epoch 39 step 185 loss 1.5236120223999023\n",
            "epoch 40 step 0 loss 1.5280625820159912 test_accuracy 76.80000305175781 train_accuracy 97.65625\n",
            "epoch 40 step 1 loss 1.509677767753601\n",
            "epoch 40 step 2 loss 1.499984622001648\n",
            "epoch 40 step 3 loss 1.5093587636947632\n",
            "epoch 40 step 4 loss 1.530219316482544\n",
            "epoch 40 step 5 loss 1.520053744316101\n",
            "epoch 40 step 6 loss 1.5178399085998535\n",
            "epoch 40 step 7 loss 1.5085937976837158\n",
            "epoch 40 step 8 loss 1.4858416318893433\n",
            "epoch 40 step 9 loss 1.4901868104934692\n",
            "epoch 40 step 10 loss 1.5026609897613525\n",
            "epoch 40 step 11 loss 1.475978136062622\n",
            "epoch 40 step 12 loss 1.5172125101089478\n",
            "epoch 40 step 13 loss 1.493941068649292\n",
            "epoch 40 step 14 loss 1.484503984451294\n",
            "epoch 40 step 15 loss 1.5233787298202515\n",
            "epoch 40 step 16 loss 1.5021605491638184\n",
            "epoch 40 step 17 loss 1.5141023397445679\n",
            "epoch 40 step 18 loss 1.500318169593811\n",
            "epoch 40 step 19 loss 1.5302354097366333\n",
            "epoch 40 step 20 loss 1.4901378154754639 test_accuracy 77.0 train_accuracy 96.875\n",
            "epoch 40 step 21 loss 1.5325908660888672\n",
            "epoch 40 step 22 loss 1.5077852010726929\n",
            "epoch 40 step 23 loss 1.4868409633636475\n",
            "epoch 40 step 24 loss 1.495620608329773\n",
            "epoch 40 step 25 loss 1.4937059879302979\n",
            "epoch 40 step 26 loss 1.5190281867980957\n",
            "epoch 40 step 27 loss 1.5094202756881714\n",
            "epoch 40 step 28 loss 1.5121965408325195\n",
            "epoch 40 step 29 loss 1.4880419969558716\n",
            "epoch 40 step 30 loss 1.517202377319336\n",
            "epoch 40 step 31 loss 1.4873569011688232\n",
            "epoch 40 step 32 loss 1.4902161359786987\n",
            "epoch 40 step 33 loss 1.5194449424743652\n",
            "epoch 40 step 34 loss 1.5000680685043335\n",
            "epoch 40 step 35 loss 1.4945348501205444\n",
            "epoch 40 step 36 loss 1.4792793989181519\n",
            "epoch 40 step 37 loss 1.5077744722366333\n",
            "epoch 40 step 38 loss 1.5435171127319336\n",
            "epoch 40 step 39 loss 1.5344481468200684\n",
            "epoch 40 step 40 loss 1.4851856231689453 test_accuracy 76.60000610351562 train_accuracy 96.09375\n",
            "epoch 40 step 41 loss 1.496214747428894\n",
            "epoch 40 step 42 loss 1.522355556488037\n",
            "epoch 40 step 43 loss 1.5370244979858398\n",
            "epoch 40 step 44 loss 1.4846813678741455\n",
            "epoch 40 step 45 loss 1.500723123550415\n",
            "epoch 40 step 46 loss 1.5391790866851807\n",
            "epoch 40 step 47 loss 1.5082411766052246\n",
            "epoch 40 step 48 loss 1.5390647649765015\n",
            "epoch 40 step 49 loss 1.4873847961425781\n",
            "epoch 40 step 50 loss 1.510836124420166\n",
            "epoch 40 step 51 loss 1.4878661632537842\n",
            "epoch 40 step 52 loss 1.5244958400726318\n",
            "epoch 40 step 53 loss 1.4935483932495117\n",
            "epoch 40 step 54 loss 1.4992318153381348\n",
            "epoch 40 step 55 loss 1.5006484985351562\n",
            "epoch 40 step 56 loss 1.5035806894302368\n",
            "epoch 40 step 57 loss 1.5110682249069214\n",
            "epoch 40 step 58 loss 1.4777249097824097\n",
            "epoch 40 step 59 loss 1.519879937171936\n",
            "epoch 40 step 60 loss 1.5392751693725586 test_accuracy 76.60000610351562 train_accuracy 94.53125\n",
            "epoch 40 step 61 loss 1.4994345903396606\n",
            "epoch 40 step 62 loss 1.4877867698669434\n",
            "epoch 40 step 63 loss 1.499477505683899\n",
            "epoch 40 step 64 loss 1.5327606201171875\n",
            "epoch 40 step 65 loss 1.5035594701766968\n",
            "epoch 40 step 66 loss 1.493089199066162\n",
            "epoch 40 step 67 loss 1.5181647539138794\n",
            "epoch 40 step 68 loss 1.49745774269104\n",
            "epoch 40 step 69 loss 1.5102038383483887\n",
            "epoch 40 step 70 loss 1.501502275466919\n",
            "epoch 40 step 71 loss 1.5352146625518799\n",
            "epoch 40 step 72 loss 1.5164226293563843\n",
            "epoch 40 step 73 loss 1.5029836893081665\n",
            "epoch 40 step 74 loss 1.488261342048645\n",
            "epoch 40 step 75 loss 1.4741621017456055\n",
            "epoch 40 step 76 loss 1.5364441871643066\n",
            "epoch 40 step 77 loss 1.4900290966033936\n",
            "epoch 40 step 78 loss 1.496403455734253\n",
            "epoch 40 step 79 loss 1.4970663785934448\n",
            "epoch 40 step 80 loss 1.4916588068008423 test_accuracy 76.80000305175781 train_accuracy 96.875\n",
            "epoch 40 step 81 loss 1.5568294525146484\n",
            "epoch 40 step 82 loss 1.526038408279419\n",
            "epoch 40 step 83 loss 1.4996232986450195\n",
            "epoch 40 step 84 loss 1.5013635158538818\n",
            "epoch 40 step 85 loss 1.5018349885940552\n",
            "epoch 40 step 86 loss 1.5011018514633179\n",
            "epoch 40 step 87 loss 1.5181896686553955\n",
            "epoch 40 step 88 loss 1.5467301607131958\n",
            "epoch 40 step 89 loss 1.503504991531372\n",
            "epoch 40 step 90 loss 1.4933143854141235\n",
            "epoch 40 step 91 loss 1.526176929473877\n",
            "epoch 40 step 92 loss 1.494532585144043\n",
            "epoch 40 step 93 loss 1.5091606378555298\n",
            "epoch 40 step 94 loss 1.5237599611282349\n",
            "epoch 40 step 95 loss 1.5028278827667236\n",
            "epoch 40 step 96 loss 1.492676854133606\n",
            "epoch 40 step 97 loss 1.4920480251312256\n",
            "epoch 40 step 98 loss 1.526380181312561\n",
            "epoch 40 step 99 loss 1.4934751987457275\n",
            "epoch 40 step 100 loss 1.4885108470916748 test_accuracy 77.0 train_accuracy 96.875\n",
            "epoch 40 step 101 loss 1.5152482986450195\n",
            "epoch 40 step 102 loss 1.5214331150054932\n",
            "epoch 40 step 103 loss 1.5038349628448486\n",
            "epoch 40 step 104 loss 1.4905263185501099\n",
            "epoch 40 step 105 loss 1.506504774093628\n",
            "epoch 40 step 106 loss 1.5319623947143555\n",
            "epoch 40 step 107 loss 1.517000436782837\n",
            "epoch 40 step 108 loss 1.5037577152252197\n",
            "epoch 40 step 109 loss 1.4796026945114136\n",
            "epoch 40 step 110 loss 1.48439621925354\n",
            "epoch 40 step 111 loss 1.5315498113632202\n",
            "epoch 40 step 112 loss 1.522802710533142\n",
            "epoch 40 step 113 loss 1.4999526739120483\n",
            "epoch 40 step 114 loss 1.4978018999099731\n",
            "epoch 40 step 115 loss 1.5213955640792847\n",
            "epoch 40 step 116 loss 1.5003864765167236\n",
            "epoch 40 step 117 loss 1.5079408884048462\n",
            "epoch 40 step 118 loss 1.5146799087524414\n",
            "epoch 40 step 119 loss 1.5134754180908203\n",
            "epoch 40 step 120 loss 1.477901577949524 test_accuracy 77.0 train_accuracy 92.96875\n",
            "epoch 40 step 121 loss 1.4940317869186401\n",
            "epoch 40 step 122 loss 1.5144448280334473\n",
            "epoch 40 step 123 loss 1.4944764375686646\n",
            "epoch 40 step 124 loss 1.508467197418213\n",
            "epoch 40 step 125 loss 1.539050817489624\n",
            "epoch 40 step 126 loss 1.5068539381027222\n",
            "epoch 40 step 127 loss 1.5057452917099\n",
            "epoch 40 step 128 loss 1.4896459579467773\n",
            "epoch 40 step 129 loss 1.4906549453735352\n",
            "epoch 40 step 130 loss 1.4858940839767456\n",
            "epoch 40 step 131 loss 1.5177732706069946\n",
            "epoch 40 step 132 loss 1.5014934539794922\n",
            "epoch 40 step 133 loss 1.4978835582733154\n",
            "epoch 40 step 134 loss 1.5232402086257935\n",
            "epoch 40 step 135 loss 1.5006684064865112\n",
            "epoch 40 step 136 loss 1.5032364130020142\n",
            "epoch 40 step 137 loss 1.4981275796890259\n",
            "epoch 40 step 138 loss 1.4892358779907227\n",
            "epoch 40 step 139 loss 1.4917171001434326\n",
            "epoch 40 step 140 loss 1.5110549926757812 test_accuracy 77.0 train_accuracy 98.4375\n",
            "epoch 40 step 141 loss 1.5224820375442505\n",
            "epoch 40 step 142 loss 1.528395414352417\n",
            "epoch 40 step 143 loss 1.4729782342910767\n",
            "epoch 40 step 144 loss 1.477902889251709\n",
            "epoch 40 step 145 loss 1.503447413444519\n",
            "epoch 40 step 146 loss 1.5102291107177734\n",
            "epoch 40 step 147 loss 1.511809229850769\n",
            "epoch 40 step 148 loss 1.4691689014434814\n",
            "epoch 40 step 149 loss 1.502659559249878\n",
            "epoch 40 step 150 loss 1.5041760206222534\n",
            "epoch 40 step 151 loss 1.5084774494171143\n",
            "epoch 40 step 152 loss 1.5159882307052612\n",
            "epoch 40 step 153 loss 1.4954502582550049\n",
            "epoch 40 step 154 loss 1.4993765354156494\n",
            "epoch 40 step 155 loss 1.5104286670684814\n",
            "epoch 40 step 156 loss 1.500705361366272\n",
            "epoch 40 step 157 loss 1.50222909450531\n",
            "epoch 40 step 158 loss 1.4789927005767822\n",
            "epoch 40 step 159 loss 1.5237183570861816\n",
            "epoch 40 step 160 loss 1.5104939937591553 test_accuracy 77.0 train_accuracy 93.75\n",
            "epoch 40 step 161 loss 1.5243102312088013\n",
            "epoch 40 step 162 loss 1.515516996383667\n",
            "epoch 40 step 163 loss 1.5015699863433838\n",
            "epoch 40 step 164 loss 1.5000897645950317\n",
            "epoch 40 step 165 loss 1.4785149097442627\n",
            "epoch 40 step 166 loss 1.5314160585403442\n",
            "epoch 40 step 167 loss 1.488412618637085\n",
            "epoch 40 step 168 loss 1.5273650884628296\n",
            "epoch 40 step 169 loss 1.5071910619735718\n",
            "epoch 40 step 170 loss 1.4977377653121948\n",
            "epoch 40 step 171 loss 1.4856692552566528\n",
            "epoch 40 step 172 loss 1.4939879179000854\n",
            "epoch 40 step 173 loss 1.5247167348861694\n",
            "epoch 40 step 174 loss 1.5032488107681274\n",
            "epoch 40 step 175 loss 1.4857052564620972\n",
            "epoch 40 step 176 loss 1.5140362977981567\n",
            "epoch 40 step 177 loss 1.4967584609985352\n",
            "epoch 40 step 178 loss 1.5148160457611084\n",
            "epoch 40 step 179 loss 1.5149277448654175\n",
            "epoch 40 step 180 loss 1.5351213216781616 test_accuracy 77.4000015258789 train_accuracy 98.4375\n",
            "epoch 40 step 181 loss 1.5297670364379883\n",
            "epoch 40 step 182 loss 1.4847056865692139\n",
            "epoch 40 step 183 loss 1.532394528388977\n",
            "epoch 40 step 184 loss 1.5152664184570312\n",
            "epoch 40 step 185 loss 1.4948697090148926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU1upXdZYmTz",
        "outputId": "aa06e7cb-f273-46b2-8652-051752d37361"
      },
      "source": [
        "print(maxacc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "77.4000015258789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfaeSkLZQ4Re",
        "outputId": "627bb7ac-369b-4512-eb2b-f97fc300c6a3"
      },
      "source": [
        "print(teste(souptest))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "62.525001525878906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mt9NC3yhp5l",
        "outputId": "4fefa7f3-c291-44ae-eb79-713b13ec9093"
      },
      "source": [
        "print(teste(souptest))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60.525001525878906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOQLMXUdM4zV",
        "outputId": "6bb8cdb6-4de9-4c9f-c0ac-d5a3ceb88b1e"
      },
      "source": [
        "threshold = 0.99\n",
        "l = []\n",
        "initial = 0\n",
        "final = 100000\n",
        "for i,(x,y) in enumerate(unsoup):\n",
        "  if (i<=initial):\n",
        "    continue\n",
        "  elif (i>=final):\n",
        "    break\n",
        "  xt = torch.unsqueeze(x,dim = 0)\n",
        "  xt = xt.to(device)\n",
        "  with torch.no_grad():\n",
        "    y_pred = model(xt)\n",
        "    y_pred = torch.squeeze(y_pred)\n",
        "    label = torch.argmax(y_pred)\n",
        "  if (y_pred[label]>threshold):\n",
        "    l.append((x,label))\n",
        "    print(i,y_pred[label])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 tensor(0.9988, device='cuda:0')\n",
            "5 tensor(0.9989, device='cuda:0')\n",
            "18 tensor(0.9935, device='cuda:0')\n",
            "22 tensor(0.9992, device='cuda:0')\n",
            "44 tensor(0.9947, device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "73419 tensor(0.9997, device='cuda:0')\n",
            "73423 tensor(0.9996, device='cuda:0')\n",
            "73425 tensor(0.9905, device='cuda:0')\n",
            "73426 tensor(0.9962, device='cuda:0')\n",
            "73427 tensor(0.9992, device='cuda:0')\n",
            "73430 tensor(0.9942, device='cuda:0')\n",
            "73443 tensor(0.9965, device='cuda:0')\n",
            "73456 tensor(0.9987, device='cuda:0')\n",
            "73458 tensor(0.9991, device='cuda:0')\n",
            "73471 tensor(0.9981, device='cuda:0')\n",
            "73472 tensor(0.9997, device='cuda:0')\n",
            "73483 tensor(0.9984, device='cuda:0')\n",
            "73488 tensor(0.9989, device='cuda:0')\n",
            "73491 tensor(0.9985, device='cuda:0')\n",
            "73492 tensor(0.9986, device='cuda:0')\n",
            "73512 tensor(0.9994, device='cuda:0')\n",
            "73519 tensor(0.9979, device='cuda:0')\n",
            "73526 tensor(0.9929, device='cuda:0')\n",
            "73531 tensor(0.9983, device='cuda:0')\n",
            "73533 tensor(0.9978, device='cuda:0')\n",
            "73535 tensor(0.9955, device='cuda:0')\n",
            "73540 tensor(0.9989, device='cuda:0')\n",
            "73545 tensor(0.9997, device='cuda:0')\n",
            "73551 tensor(0.9984, device='cuda:0')\n",
            "73553 tensor(0.9949, device='cuda:0')\n",
            "73557 tensor(0.9996, device='cuda:0')\n",
            "73564 tensor(0.9902, device='cuda:0')\n",
            "73566 tensor(0.9967, device='cuda:0')\n",
            "73568 tensor(0.9971, device='cuda:0')\n",
            "73573 tensor(0.9948, device='cuda:0')\n",
            "73586 tensor(0.9983, device='cuda:0')\n",
            "73587 tensor(0.9998, device='cuda:0')\n",
            "73591 tensor(0.9957, device='cuda:0')\n",
            "73592 tensor(0.9923, device='cuda:0')\n",
            "73595 tensor(0.9994, device='cuda:0')\n",
            "73601 tensor(0.9991, device='cuda:0')\n",
            "73607 tensor(0.9968, device='cuda:0')\n",
            "73618 tensor(0.9998, device='cuda:0')\n",
            "73628 tensor(0.9977, device='cuda:0')\n",
            "73632 tensor(0.9992, device='cuda:0')\n",
            "73645 tensor(0.9999, device='cuda:0')\n",
            "73648 tensor(0.9910, device='cuda:0')\n",
            "73661 tensor(0.9955, device='cuda:0')\n",
            "73663 tensor(0.9963, device='cuda:0')\n",
            "73664 tensor(0.9961, device='cuda:0')\n",
            "73667 tensor(0.9956, device='cuda:0')\n",
            "73672 tensor(0.9998, device='cuda:0')\n",
            "73681 tensor(0.9986, device='cuda:0')\n",
            "73683 tensor(0.9995, device='cuda:0')\n",
            "73688 tensor(0.9998, device='cuda:0')\n",
            "73689 tensor(0.9947, device='cuda:0')\n",
            "73698 tensor(0.9957, device='cuda:0')\n",
            "73705 tensor(0.9971, device='cuda:0')\n",
            "73708 tensor(0.9922, device='cuda:0')\n",
            "73723 tensor(0.9904, device='cuda:0')\n",
            "73724 tensor(0.9970, device='cuda:0')\n",
            "73742 tensor(0.9928, device='cuda:0')\n",
            "73772 tensor(0.9982, device='cuda:0')\n",
            "73784 tensor(0.9929, device='cuda:0')\n",
            "73793 tensor(0.9905, device='cuda:0')\n",
            "73802 tensor(0.9981, device='cuda:0')\n",
            "73803 tensor(0.9935, device='cuda:0')\n",
            "73805 tensor(0.9971, device='cuda:0')\n",
            "73810 tensor(0.9993, device='cuda:0')\n",
            "73813 tensor(0.9930, device='cuda:0')\n",
            "73814 tensor(0.9954, device='cuda:0')\n",
            "73815 tensor(0.9992, device='cuda:0')\n",
            "73816 tensor(0.9949, device='cuda:0')\n",
            "73817 tensor(0.9991, device='cuda:0')\n",
            "73821 tensor(0.9981, device='cuda:0')\n",
            "73823 tensor(0.9982, device='cuda:0')\n",
            "73825 tensor(0.9999, device='cuda:0')\n",
            "73829 tensor(0.9997, device='cuda:0')\n",
            "73831 tensor(0.9958, device='cuda:0')\n",
            "73838 tensor(0.9983, device='cuda:0')\n",
            "73842 tensor(0.9911, device='cuda:0')\n",
            "73844 tensor(0.9967, device='cuda:0')\n",
            "73852 tensor(0.9973, device='cuda:0')\n",
            "73857 tensor(0.9997, device='cuda:0')\n",
            "73861 tensor(0.9978, device='cuda:0')\n",
            "73864 tensor(0.9978, device='cuda:0')\n",
            "73879 tensor(0.9966, device='cuda:0')\n",
            "73883 tensor(0.9937, device='cuda:0')\n",
            "73892 tensor(0.9972, device='cuda:0')\n",
            "73894 tensor(0.9951, device='cuda:0')\n",
            "73895 tensor(0.9902, device='cuda:0')\n",
            "73901 tensor(0.9911, device='cuda:0')\n",
            "73907 tensor(0.9927, device='cuda:0')\n",
            "73910 tensor(0.9988, device='cuda:0')\n",
            "73912 tensor(0.9968, device='cuda:0')\n",
            "73921 tensor(0.9947, device='cuda:0')\n",
            "73922 tensor(0.9935, device='cuda:0')\n",
            "73924 tensor(0.9995, device='cuda:0')\n",
            "73925 tensor(0.9947, device='cuda:0')\n",
            "73927 tensor(0.9936, device='cuda:0')\n",
            "73937 tensor(0.9918, device='cuda:0')\n",
            "73945 tensor(0.9986, device='cuda:0')\n",
            "73947 tensor(0.9931, device='cuda:0')\n",
            "73950 tensor(0.9926, device='cuda:0')\n",
            "73951 tensor(0.9961, device='cuda:0')\n",
            "73952 tensor(0.9967, device='cuda:0')\n",
            "73969 tensor(0.9968, device='cuda:0')\n",
            "73973 tensor(0.9923, device='cuda:0')\n",
            "73976 tensor(0.9999, device='cuda:0')\n",
            "73977 tensor(0.9947, device='cuda:0')\n",
            "73982 tensor(0.9904, device='cuda:0')\n",
            "74000 tensor(0.9911, device='cuda:0')\n",
            "74004 tensor(0.9935, device='cuda:0')\n",
            "74011 tensor(0.9934, device='cuda:0')\n",
            "74018 tensor(0.9998, device='cuda:0')\n",
            "74019 tensor(0.9945, device='cuda:0')\n",
            "74020 tensor(0.9992, device='cuda:0')\n",
            "74026 tensor(0.9998, device='cuda:0')\n",
            "74030 tensor(0.9985, device='cuda:0')\n",
            "74034 tensor(0.9998, device='cuda:0')\n",
            "74037 tensor(0.9919, device='cuda:0')\n",
            "74038 tensor(0.9901, device='cuda:0')\n",
            "74042 tensor(0.9977, device='cuda:0')\n",
            "74045 tensor(0.9994, device='cuda:0')\n",
            "74050 tensor(0.9972, device='cuda:0')\n",
            "74054 tensor(0.9920, device='cuda:0')\n",
            "74059 tensor(0.9988, device='cuda:0')\n",
            "74067 tensor(0.9978, device='cuda:0')\n",
            "74068 tensor(0.9949, device='cuda:0')\n",
            "74069 tensor(0.9979, device='cuda:0')\n",
            "74074 tensor(0.9998, device='cuda:0')\n",
            "74100 tensor(0.9994, device='cuda:0')\n",
            "74105 tensor(0.9962, device='cuda:0')\n",
            "74108 tensor(0.9975, device='cuda:0')\n",
            "74118 tensor(0.9994, device='cuda:0')\n",
            "74119 tensor(0.9985, device='cuda:0')\n",
            "74127 tensor(0.9958, device='cuda:0')\n",
            "74138 tensor(0.9970, device='cuda:0')\n",
            "74140 tensor(0.9940, device='cuda:0')\n",
            "74146 tensor(0.9999, device='cuda:0')\n",
            "74165 tensor(0.9998, device='cuda:0')\n",
            "74166 tensor(0.9984, device='cuda:0')\n",
            "74168 tensor(0.9981, device='cuda:0')\n",
            "74174 tensor(0.9975, device='cuda:0')\n",
            "74186 tensor(0.9982, device='cuda:0')\n",
            "74190 tensor(0.9999, device='cuda:0')\n",
            "74192 tensor(0.9980, device='cuda:0')\n",
            "74194 tensor(0.9930, device='cuda:0')\n",
            "74196 tensor(0.9964, device='cuda:0')\n",
            "74199 tensor(0.9998, device='cuda:0')\n",
            "74202 tensor(0.9990, device='cuda:0')\n",
            "74203 tensor(0.9993, device='cuda:0')\n",
            "74204 tensor(0.9999, device='cuda:0')\n",
            "74224 tensor(0.9962, device='cuda:0')\n",
            "74227 tensor(0.9996, device='cuda:0')\n",
            "74239 tensor(0.9976, device='cuda:0')\n",
            "74251 tensor(0.9955, device='cuda:0')\n",
            "74253 tensor(0.9998, device='cuda:0')\n",
            "74258 tensor(0.9995, device='cuda:0')\n",
            "74260 tensor(0.9989, device='cuda:0')\n",
            "74261 tensor(0.9999, device='cuda:0')\n",
            "74264 tensor(0.9998, device='cuda:0')\n",
            "74267 tensor(0.9915, device='cuda:0')\n",
            "74271 tensor(0.9996, device='cuda:0')\n",
            "74273 tensor(0.9954, device='cuda:0')\n",
            "74277 tensor(0.9979, device='cuda:0')\n",
            "74285 tensor(0.9986, device='cuda:0')\n",
            "74286 tensor(0.9964, device='cuda:0')\n",
            "74287 tensor(0.9936, device='cuda:0')\n",
            "74291 tensor(0.9948, device='cuda:0')\n",
            "74300 tensor(0.9912, device='cuda:0')\n",
            "74315 tensor(0.9997, device='cuda:0')\n",
            "74323 tensor(0.9998, device='cuda:0')\n",
            "74325 tensor(0.9997, device='cuda:0')\n",
            "74331 tensor(0.9998, device='cuda:0')\n",
            "74337 tensor(0.9987, device='cuda:0')\n",
            "74357 tensor(0.9955, device='cuda:0')\n",
            "74361 tensor(0.9995, device='cuda:0')\n",
            "74374 tensor(0.9998, device='cuda:0')\n",
            "74379 tensor(0.9989, device='cuda:0')\n",
            "74381 tensor(0.9985, device='cuda:0')\n",
            "74382 tensor(0.9992, device='cuda:0')\n",
            "74385 tensor(0.9918, device='cuda:0')\n",
            "74408 tensor(0.9946, device='cuda:0')\n",
            "74409 tensor(0.9993, device='cuda:0')\n",
            "74411 tensor(0.9997, device='cuda:0')\n",
            "74414 tensor(0.9984, device='cuda:0')\n",
            "74424 tensor(0.9988, device='cuda:0')\n",
            "74425 tensor(0.9969, device='cuda:0')\n",
            "74428 tensor(0.9938, device='cuda:0')\n",
            "74437 tensor(0.9930, device='cuda:0')\n",
            "74443 tensor(0.9981, device='cuda:0')\n",
            "74445 tensor(0.9938, device='cuda:0')\n",
            "74448 tensor(0.9920, device='cuda:0')\n",
            "74452 tensor(0.9985, device='cuda:0')\n",
            "74459 tensor(0.9989, device='cuda:0')\n",
            "74472 tensor(0.9970, device='cuda:0')\n",
            "74479 tensor(0.9990, device='cuda:0')\n",
            "74480 tensor(0.9971, device='cuda:0')\n",
            "74481 tensor(0.9955, device='cuda:0')\n",
            "74482 tensor(0.9998, device='cuda:0')\n",
            "74488 tensor(0.9965, device='cuda:0')\n",
            "74490 tensor(0.9967, device='cuda:0')\n",
            "74501 tensor(0.9921, device='cuda:0')\n",
            "74512 tensor(0.9986, device='cuda:0')\n",
            "74517 tensor(0.9990, device='cuda:0')\n",
            "74523 tensor(0.9922, device='cuda:0')\n",
            "74526 tensor(0.9966, device='cuda:0')\n",
            "74530 tensor(0.9987, device='cuda:0')\n",
            "74531 tensor(0.9959, device='cuda:0')\n",
            "74545 tensor(0.9989, device='cuda:0')\n",
            "74546 tensor(0.9920, device='cuda:0')\n",
            "74550 tensor(0.9991, device='cuda:0')\n",
            "74562 tensor(0.9971, device='cuda:0')\n",
            "74592 tensor(0.9973, device='cuda:0')\n",
            "74597 tensor(0.9957, device='cuda:0')\n",
            "74603 tensor(0.9996, device='cuda:0')\n",
            "74605 tensor(0.9910, device='cuda:0')\n",
            "74611 tensor(0.9991, device='cuda:0')\n",
            "74614 tensor(0.9988, device='cuda:0')\n",
            "74622 tensor(0.9981, device='cuda:0')\n",
            "74629 tensor(0.9979, device='cuda:0')\n",
            "74636 tensor(0.9993, device='cuda:0')\n",
            "74641 tensor(0.9912, device='cuda:0')\n",
            "74645 tensor(0.9935, device='cuda:0')\n",
            "74646 tensor(0.9946, device='cuda:0')\n",
            "74656 tensor(0.9996, device='cuda:0')\n",
            "74658 tensor(0.9995, device='cuda:0')\n",
            "74660 tensor(0.9990, device='cuda:0')\n",
            "74661 tensor(0.9945, device='cuda:0')\n",
            "74668 tensor(0.9967, device='cuda:0')\n",
            "74670 tensor(0.9962, device='cuda:0')\n",
            "74673 tensor(0.9923, device='cuda:0')\n",
            "74684 tensor(0.9965, device='cuda:0')\n",
            "74691 tensor(0.9999, device='cuda:0')\n",
            "74695 tensor(0.9979, device='cuda:0')\n",
            "74724 tensor(0.9988, device='cuda:0')\n",
            "74726 tensor(0.9999, device='cuda:0')\n",
            "74731 tensor(0.9999, device='cuda:0')\n",
            "74736 tensor(0.9928, device='cuda:0')\n",
            "74740 tensor(0.9914, device='cuda:0')\n",
            "74746 tensor(0.9996, device='cuda:0')\n",
            "74750 tensor(0.9985, device='cuda:0')\n",
            "74760 tensor(0.9922, device='cuda:0')\n",
            "74776 tensor(0.9964, device='cuda:0')\n",
            "74777 tensor(0.9988, device='cuda:0')\n",
            "74778 tensor(0.9977, device='cuda:0')\n",
            "74782 tensor(0.9991, device='cuda:0')\n",
            "74789 tensor(0.9944, device='cuda:0')\n",
            "74791 tensor(0.9988, device='cuda:0')\n",
            "74796 tensor(0.9954, device='cuda:0')\n",
            "74798 tensor(0.9982, device='cuda:0')\n",
            "74801 tensor(0.9921, device='cuda:0')\n",
            "74811 tensor(0.9945, device='cuda:0')\n",
            "74820 tensor(0.9930, device='cuda:0')\n",
            "74825 tensor(0.9943, device='cuda:0')\n",
            "74829 tensor(0.9998, device='cuda:0')\n",
            "74830 tensor(0.9981, device='cuda:0')\n",
            "74831 tensor(0.9977, device='cuda:0')\n",
            "74832 tensor(0.9985, device='cuda:0')\n",
            "74844 tensor(0.9996, device='cuda:0')\n",
            "74847 tensor(0.9995, device='cuda:0')\n",
            "74859 tensor(0.9928, device='cuda:0')\n",
            "74860 tensor(0.9919, device='cuda:0')\n",
            "74863 tensor(0.9991, device='cuda:0')\n",
            "74864 tensor(0.9996, device='cuda:0')\n",
            "74867 tensor(0.9996, device='cuda:0')\n",
            "74877 tensor(0.9957, device='cuda:0')\n",
            "74879 tensor(0.9987, device='cuda:0')\n",
            "74883 tensor(0.9956, device='cuda:0')\n",
            "74887 tensor(0.9931, device='cuda:0')\n",
            "74895 tensor(0.9991, device='cuda:0')\n",
            "74901 tensor(0.9992, device='cuda:0')\n",
            "74904 tensor(0.9958, device='cuda:0')\n",
            "74908 tensor(0.9998, device='cuda:0')\n",
            "74909 tensor(0.9950, device='cuda:0')\n",
            "74920 tensor(0.9998, device='cuda:0')\n",
            "74931 tensor(0.9917, device='cuda:0')\n",
            "74959 tensor(0.9965, device='cuda:0')\n",
            "74969 tensor(0.9936, device='cuda:0')\n",
            "74970 tensor(1.0000, device='cuda:0')\n",
            "74987 tensor(0.9977, device='cuda:0')\n",
            "74996 tensor(0.9925, device='cuda:0')\n",
            "75002 tensor(0.9927, device='cuda:0')\n",
            "75004 tensor(0.9984, device='cuda:0')\n",
            "75037 tensor(0.9909, device='cuda:0')\n",
            "75038 tensor(0.9923, device='cuda:0')\n",
            "75040 tensor(0.9993, device='cuda:0')\n",
            "75048 tensor(0.9987, device='cuda:0')\n",
            "75055 tensor(0.9999, device='cuda:0')\n",
            "75075 tensor(0.9978, device='cuda:0')\n",
            "75085 tensor(0.9928, device='cuda:0')\n",
            "75086 tensor(0.9923, device='cuda:0')\n",
            "75091 tensor(0.9976, device='cuda:0')\n",
            "75098 tensor(0.9996, device='cuda:0')\n",
            "75104 tensor(0.9993, device='cuda:0')\n",
            "75105 tensor(0.9992, device='cuda:0')\n",
            "75111 tensor(0.9978, device='cuda:0')\n",
            "75113 tensor(0.9984, device='cuda:0')\n",
            "75114 tensor(0.9997, device='cuda:0')\n",
            "75116 tensor(0.9997, device='cuda:0')\n",
            "75125 tensor(0.9982, device='cuda:0')\n",
            "75128 tensor(0.9923, device='cuda:0')\n",
            "75133 tensor(0.9962, device='cuda:0')\n",
            "75135 tensor(0.9998, device='cuda:0')\n",
            "75137 tensor(0.9982, device='cuda:0')\n",
            "75139 tensor(0.9944, device='cuda:0')\n",
            "75140 tensor(0.9955, device='cuda:0')\n",
            "75151 tensor(0.9986, device='cuda:0')\n",
            "75152 tensor(0.9999, device='cuda:0')\n",
            "75153 tensor(0.9994, device='cuda:0')\n",
            "75160 tensor(0.9988, device='cuda:0')\n",
            "75161 tensor(0.9989, device='cuda:0')\n",
            "75168 tensor(0.9904, device='cuda:0')\n",
            "75173 tensor(0.9990, device='cuda:0')\n",
            "75176 tensor(0.9931, device='cuda:0')\n",
            "75188 tensor(0.9997, device='cuda:0')\n",
            "75189 tensor(0.9954, device='cuda:0')\n",
            "75203 tensor(0.9961, device='cuda:0')\n",
            "75204 tensor(0.9946, device='cuda:0')\n",
            "75210 tensor(0.9994, device='cuda:0')\n",
            "75220 tensor(0.9966, device='cuda:0')\n",
            "75222 tensor(1.0000, device='cuda:0')\n",
            "75224 tensor(0.9965, device='cuda:0')\n",
            "75237 tensor(0.9987, device='cuda:0')\n",
            "75239 tensor(0.9979, device='cuda:0')\n",
            "75240 tensor(0.9984, device='cuda:0')\n",
            "75243 tensor(0.9984, device='cuda:0')\n",
            "75245 tensor(0.9988, device='cuda:0')\n",
            "75249 tensor(0.9967, device='cuda:0')\n",
            "75260 tensor(0.9971, device='cuda:0')\n",
            "75262 tensor(0.9977, device='cuda:0')\n",
            "75263 tensor(0.9951, device='cuda:0')\n",
            "75310 tensor(0.9994, device='cuda:0')\n",
            "75313 tensor(0.9938, device='cuda:0')\n",
            "75314 tensor(0.9995, device='cuda:0')\n",
            "75319 tensor(0.9978, device='cuda:0')\n",
            "75332 tensor(0.9950, device='cuda:0')\n",
            "75334 tensor(0.9972, device='cuda:0')\n",
            "75348 tensor(0.9964, device='cuda:0')\n",
            "75365 tensor(0.9994, device='cuda:0')\n",
            "75368 tensor(0.9950, device='cuda:0')\n",
            "75369 tensor(0.9947, device='cuda:0')\n",
            "75383 tensor(0.9909, device='cuda:0')\n",
            "75398 tensor(0.9968, device='cuda:0')\n",
            "75399 tensor(0.9997, device='cuda:0')\n",
            "75406 tensor(0.9987, device='cuda:0')\n",
            "75407 tensor(0.9990, device='cuda:0')\n",
            "75411 tensor(0.9930, device='cuda:0')\n",
            "75412 tensor(0.9966, device='cuda:0')\n",
            "75414 tensor(0.9993, device='cuda:0')\n",
            "75419 tensor(0.9931, device='cuda:0')\n",
            "75421 tensor(0.9974, device='cuda:0')\n",
            "75425 tensor(0.9990, device='cuda:0')\n",
            "75427 tensor(0.9961, device='cuda:0')\n",
            "75428 tensor(0.9998, device='cuda:0')\n",
            "75432 tensor(0.9971, device='cuda:0')\n",
            "75434 tensor(0.9959, device='cuda:0')\n",
            "75454 tensor(0.9995, device='cuda:0')\n",
            "75456 tensor(0.9956, device='cuda:0')\n",
            "75465 tensor(0.9995, device='cuda:0')\n",
            "75470 tensor(0.9980, device='cuda:0')\n",
            "75475 tensor(0.9987, device='cuda:0')\n",
            "75481 tensor(0.9952, device='cuda:0')\n",
            "75485 tensor(0.9941, device='cuda:0')\n",
            "75490 tensor(0.9934, device='cuda:0')\n",
            "75496 tensor(0.9997, device='cuda:0')\n",
            "75505 tensor(0.9980, device='cuda:0')\n",
            "75509 tensor(0.9952, device='cuda:0')\n",
            "75510 tensor(0.9958, device='cuda:0')\n",
            "75521 tensor(0.9962, device='cuda:0')\n",
            "75538 tensor(0.9977, device='cuda:0')\n",
            "75544 tensor(0.9986, device='cuda:0')\n",
            "75545 tensor(0.9997, device='cuda:0')\n",
            "75549 tensor(0.9917, device='cuda:0')\n",
            "75559 tensor(0.9903, device='cuda:0')\n",
            "75566 tensor(0.9936, device='cuda:0')\n",
            "75570 tensor(0.9939, device='cuda:0')\n",
            "75588 tensor(0.9997, device='cuda:0')\n",
            "75589 tensor(0.9928, device='cuda:0')\n",
            "75591 tensor(0.9911, device='cuda:0')\n",
            "75597 tensor(0.9949, device='cuda:0')\n",
            "75598 tensor(1.0000, device='cuda:0')\n",
            "75599 tensor(0.9908, device='cuda:0')\n",
            "75605 tensor(0.9984, device='cuda:0')\n",
            "75612 tensor(0.9948, device='cuda:0')\n",
            "75621 tensor(0.9964, device='cuda:0')\n",
            "75629 tensor(0.9998, device='cuda:0')\n",
            "75632 tensor(0.9997, device='cuda:0')\n",
            "75635 tensor(0.9997, device='cuda:0')\n",
            "75645 tensor(0.9926, device='cuda:0')\n",
            "75652 tensor(0.9958, device='cuda:0')\n",
            "75696 tensor(0.9952, device='cuda:0')\n",
            "75701 tensor(0.9996, device='cuda:0')\n",
            "75706 tensor(0.9997, device='cuda:0')\n",
            "75707 tensor(0.9990, device='cuda:0')\n",
            "75714 tensor(0.9991, device='cuda:0')\n",
            "75715 tensor(0.9964, device='cuda:0')\n",
            "75721 tensor(0.9952, device='cuda:0')\n",
            "75728 tensor(0.9991, device='cuda:0')\n",
            "75733 tensor(0.9910, device='cuda:0')\n",
            "75743 tensor(0.9952, device='cuda:0')\n",
            "75751 tensor(0.9982, device='cuda:0')\n",
            "75753 tensor(0.9995, device='cuda:0')\n",
            "75754 tensor(0.9976, device='cuda:0')\n",
            "75762 tensor(0.9921, device='cuda:0')\n",
            "75764 tensor(0.9961, device='cuda:0')\n",
            "75765 tensor(0.9997, device='cuda:0')\n",
            "75773 tensor(0.9964, device='cuda:0')\n",
            "75775 tensor(0.9990, device='cuda:0')\n",
            "75776 tensor(0.9995, device='cuda:0')\n",
            "75787 tensor(0.9992, device='cuda:0')\n",
            "75790 tensor(0.9939, device='cuda:0')\n",
            "75791 tensor(0.9998, device='cuda:0')\n",
            "75797 tensor(0.9934, device='cuda:0')\n",
            "75803 tensor(0.9998, device='cuda:0')\n",
            "75804 tensor(0.9947, device='cuda:0')\n",
            "75811 tensor(0.9995, device='cuda:0')\n",
            "75813 tensor(0.9997, device='cuda:0')\n",
            "75815 tensor(0.9959, device='cuda:0')\n",
            "75816 tensor(0.9980, device='cuda:0')\n",
            "75819 tensor(0.9973, device='cuda:0')\n",
            "75820 tensor(0.9994, device='cuda:0')\n",
            "75824 tensor(0.9980, device='cuda:0')\n",
            "75825 tensor(0.9972, device='cuda:0')\n",
            "75827 tensor(0.9998, device='cuda:0')\n",
            "75842 tensor(0.9983, device='cuda:0')\n",
            "75844 tensor(0.9988, device='cuda:0')\n",
            "75849 tensor(0.9974, device='cuda:0')\n",
            "75850 tensor(0.9999, device='cuda:0')\n",
            "75851 tensor(0.9933, device='cuda:0')\n",
            "75852 tensor(0.9961, device='cuda:0')\n",
            "75854 tensor(0.9933, device='cuda:0')\n",
            "75855 tensor(0.9974, device='cuda:0')\n",
            "75862 tensor(0.9974, device='cuda:0')\n",
            "75874 tensor(0.9968, device='cuda:0')\n",
            "75878 tensor(0.9922, device='cuda:0')\n",
            "75890 tensor(0.9942, device='cuda:0')\n",
            "75894 tensor(0.9963, device='cuda:0')\n",
            "75918 tensor(0.9992, device='cuda:0')\n",
            "75923 tensor(0.9994, device='cuda:0')\n",
            "75939 tensor(0.9983, device='cuda:0')\n",
            "75941 tensor(0.9950, device='cuda:0')\n",
            "75942 tensor(0.9995, device='cuda:0')\n",
            "75947 tensor(0.9990, device='cuda:0')\n",
            "75952 tensor(0.9917, device='cuda:0')\n",
            "75955 tensor(0.9940, device='cuda:0')\n",
            "75986 tensor(0.9948, device='cuda:0')\n",
            "75988 tensor(0.9985, device='cuda:0')\n",
            "76004 tensor(0.9987, device='cuda:0')\n",
            "76008 tensor(0.9976, device='cuda:0')\n",
            "76009 tensor(0.9968, device='cuda:0')\n",
            "76015 tensor(0.9949, device='cuda:0')\n",
            "76028 tensor(0.9918, device='cuda:0')\n",
            "76030 tensor(0.9986, device='cuda:0')\n",
            "76032 tensor(0.9936, device='cuda:0')\n",
            "76047 tensor(0.9964, device='cuda:0')\n",
            "76049 tensor(0.9907, device='cuda:0')\n",
            "76053 tensor(0.9967, device='cuda:0')\n",
            "76060 tensor(0.9998, device='cuda:0')\n",
            "76062 tensor(0.9980, device='cuda:0')\n",
            "76064 tensor(0.9997, device='cuda:0')\n",
            "76067 tensor(0.9969, device='cuda:0')\n",
            "76070 tensor(0.9979, device='cuda:0')\n",
            "76081 tensor(0.9938, device='cuda:0')\n",
            "76082 tensor(0.9933, device='cuda:0')\n",
            "76087 tensor(0.9998, device='cuda:0')\n",
            "76090 tensor(0.9962, device='cuda:0')\n",
            "76097 tensor(0.9996, device='cuda:0')\n",
            "76120 tensor(0.9919, device='cuda:0')\n",
            "76122 tensor(0.9963, device='cuda:0')\n",
            "76126 tensor(0.9994, device='cuda:0')\n",
            "76132 tensor(0.9954, device='cuda:0')\n",
            "76137 tensor(0.9924, device='cuda:0')\n",
            "76138 tensor(0.9994, device='cuda:0')\n",
            "76143 tensor(0.9978, device='cuda:0')\n",
            "76147 tensor(0.9989, device='cuda:0')\n",
            "76152 tensor(0.9951, device='cuda:0')\n",
            "76153 tensor(0.9993, device='cuda:0')\n",
            "76162 tensor(0.9952, device='cuda:0')\n",
            "76169 tensor(0.9925, device='cuda:0')\n",
            "76181 tensor(0.9950, device='cuda:0')\n",
            "76183 tensor(0.9980, device='cuda:0')\n",
            "76185 tensor(0.9970, device='cuda:0')\n",
            "76186 tensor(0.9987, device='cuda:0')\n",
            "76196 tensor(0.9917, device='cuda:0')\n",
            "76198 tensor(0.9999, device='cuda:0')\n",
            "76201 tensor(0.9914, device='cuda:0')\n",
            "76203 tensor(0.9992, device='cuda:0')\n",
            "76204 tensor(0.9939, device='cuda:0')\n",
            "76207 tensor(0.9993, device='cuda:0')\n",
            "76208 tensor(0.9906, device='cuda:0')\n",
            "76216 tensor(0.9975, device='cuda:0')\n",
            "76219 tensor(0.9962, device='cuda:0')\n",
            "76243 tensor(0.9979, device='cuda:0')\n",
            "76246 tensor(0.9965, device='cuda:0')\n",
            "76251 tensor(0.9946, device='cuda:0')\n",
            "76269 tensor(0.9992, device='cuda:0')\n",
            "76274 tensor(0.9966, device='cuda:0')\n",
            "76276 tensor(0.9947, device='cuda:0')\n",
            "76290 tensor(0.9930, device='cuda:0')\n",
            "76292 tensor(0.9951, device='cuda:0')\n",
            "76294 tensor(0.9967, device='cuda:0')\n",
            "76297 tensor(0.9996, device='cuda:0')\n",
            "76300 tensor(0.9945, device='cuda:0')\n",
            "76302 tensor(0.9977, device='cuda:0')\n",
            "76308 tensor(0.9995, device='cuda:0')\n",
            "76322 tensor(0.9921, device='cuda:0')\n",
            "76357 tensor(0.9991, device='cuda:0')\n",
            "76358 tensor(0.9939, device='cuda:0')\n",
            "76376 tensor(0.9986, device='cuda:0')\n",
            "76378 tensor(0.9997, device='cuda:0')\n",
            "76379 tensor(0.9999, device='cuda:0')\n",
            "76383 tensor(0.9939, device='cuda:0')\n",
            "76392 tensor(0.9960, device='cuda:0')\n",
            "76393 tensor(0.9999, device='cuda:0')\n",
            "76404 tensor(0.9961, device='cuda:0')\n",
            "76407 tensor(0.9995, device='cuda:0')\n",
            "76411 tensor(0.9946, device='cuda:0')\n",
            "76414 tensor(0.9996, device='cuda:0')\n",
            "76415 tensor(0.9955, device='cuda:0')\n",
            "76420 tensor(0.9947, device='cuda:0')\n",
            "76430 tensor(0.9980, device='cuda:0')\n",
            "76432 tensor(0.9991, device='cuda:0')\n",
            "76433 tensor(0.9971, device='cuda:0')\n",
            "76441 tensor(0.9995, device='cuda:0')\n",
            "76442 tensor(0.9994, device='cuda:0')\n",
            "76443 tensor(0.9997, device='cuda:0')\n",
            "76447 tensor(0.9997, device='cuda:0')\n",
            "76448 tensor(0.9977, device='cuda:0')\n",
            "76456 tensor(0.9991, device='cuda:0')\n",
            "76457 tensor(0.9995, device='cuda:0')\n",
            "76479 tensor(0.9949, device='cuda:0')\n",
            "76482 tensor(0.9994, device='cuda:0')\n",
            "76484 tensor(0.9939, device='cuda:0')\n",
            "76491 tensor(0.9979, device='cuda:0')\n",
            "76500 tensor(0.9992, device='cuda:0')\n",
            "76507 tensor(0.9917, device='cuda:0')\n",
            "76509 tensor(0.9951, device='cuda:0')\n",
            "76513 tensor(0.9994, device='cuda:0')\n",
            "76514 tensor(0.9998, device='cuda:0')\n",
            "76523 tensor(0.9995, device='cuda:0')\n",
            "76526 tensor(0.9981, device='cuda:0')\n",
            "76527 tensor(0.9998, device='cuda:0')\n",
            "76530 tensor(0.9989, device='cuda:0')\n",
            "76539 tensor(0.9999, device='cuda:0')\n",
            "76545 tensor(0.9995, device='cuda:0')\n",
            "76547 tensor(0.9957, device='cuda:0')\n",
            "76552 tensor(0.9924, device='cuda:0')\n",
            "76561 tensor(0.9928, device='cuda:0')\n",
            "76563 tensor(0.9907, device='cuda:0')\n",
            "76565 tensor(0.9983, device='cuda:0')\n",
            "76570 tensor(0.9936, device='cuda:0')\n",
            "76576 tensor(0.9978, device='cuda:0')\n",
            "76577 tensor(0.9986, device='cuda:0')\n",
            "76593 tensor(0.9980, device='cuda:0')\n",
            "76597 tensor(0.9993, device='cuda:0')\n",
            "76617 tensor(0.9998, device='cuda:0')\n",
            "76622 tensor(0.9990, device='cuda:0')\n",
            "76641 tensor(0.9973, device='cuda:0')\n",
            "76644 tensor(0.9946, device='cuda:0')\n",
            "76646 tensor(0.9992, device='cuda:0')\n",
            "76647 tensor(0.9964, device='cuda:0')\n",
            "76649 tensor(0.9908, device='cuda:0')\n",
            "76654 tensor(0.9986, device='cuda:0')\n",
            "76663 tensor(0.9927, device='cuda:0')\n",
            "76672 tensor(0.9979, device='cuda:0')\n",
            "76679 tensor(0.9931, device='cuda:0')\n",
            "76681 tensor(0.9908, device='cuda:0')\n",
            "76693 tensor(0.9977, device='cuda:0')\n",
            "76705 tensor(0.9975, device='cuda:0')\n",
            "76708 tensor(0.9969, device='cuda:0')\n",
            "76710 tensor(0.9928, device='cuda:0')\n",
            "76711 tensor(0.9985, device='cuda:0')\n",
            "76716 tensor(0.9919, device='cuda:0')\n",
            "76721 tensor(0.9988, device='cuda:0')\n",
            "76725 tensor(0.9989, device='cuda:0')\n",
            "76729 tensor(0.9921, device='cuda:0')\n",
            "76746 tensor(0.9950, device='cuda:0')\n",
            "76748 tensor(0.9997, device='cuda:0')\n",
            "76752 tensor(0.9977, device='cuda:0')\n",
            "76758 tensor(0.9982, device='cuda:0')\n",
            "76775 tensor(0.9998, device='cuda:0')\n",
            "76781 tensor(0.9959, device='cuda:0')\n",
            "76782 tensor(0.9941, device='cuda:0')\n",
            "76783 tensor(0.9988, device='cuda:0')\n",
            "76784 tensor(0.9925, device='cuda:0')\n",
            "76785 tensor(0.9997, device='cuda:0')\n",
            "76788 tensor(0.9905, device='cuda:0')\n",
            "76789 tensor(0.9976, device='cuda:0')\n",
            "76835 tensor(0.9991, device='cuda:0')\n",
            "76838 tensor(0.9965, device='cuda:0')\n",
            "76845 tensor(0.9995, device='cuda:0')\n",
            "76848 tensor(0.9999, device='cuda:0')\n",
            "76849 tensor(0.9997, device='cuda:0')\n",
            "76850 tensor(0.9929, device='cuda:0')\n",
            "76857 tensor(0.9940, device='cuda:0')\n",
            "76865 tensor(0.9924, device='cuda:0')\n",
            "76878 tensor(0.9996, device='cuda:0')\n",
            "76880 tensor(0.9983, device='cuda:0')\n",
            "76881 tensor(0.9997, device='cuda:0')\n",
            "76882 tensor(0.9991, device='cuda:0')\n",
            "76886 tensor(0.9921, device='cuda:0')\n",
            "76887 tensor(0.9948, device='cuda:0')\n",
            "76890 tensor(0.9996, device='cuda:0')\n",
            "76893 tensor(0.9939, device='cuda:0')\n",
            "76898 tensor(0.9969, device='cuda:0')\n",
            "76904 tensor(0.9989, device='cuda:0')\n",
            "76919 tensor(0.9991, device='cuda:0')\n",
            "76920 tensor(0.9967, device='cuda:0')\n",
            "76921 tensor(0.9998, device='cuda:0')\n",
            "76931 tensor(0.9972, device='cuda:0')\n",
            "76937 tensor(0.9920, device='cuda:0')\n",
            "76947 tensor(0.9931, device='cuda:0')\n",
            "76954 tensor(0.9981, device='cuda:0')\n",
            "76955 tensor(0.9968, device='cuda:0')\n",
            "76963 tensor(0.9944, device='cuda:0')\n",
            "76973 tensor(0.9937, device='cuda:0')\n",
            "76976 tensor(0.9925, device='cuda:0')\n",
            "76980 tensor(0.9978, device='cuda:0')\n",
            "76986 tensor(0.9908, device='cuda:0')\n",
            "76987 tensor(0.9925, device='cuda:0')\n",
            "76989 tensor(0.9963, device='cuda:0')\n",
            "76991 tensor(0.9983, device='cuda:0')\n",
            "77004 tensor(0.9972, device='cuda:0')\n",
            "77007 tensor(0.9963, device='cuda:0')\n",
            "77022 tensor(0.9984, device='cuda:0')\n",
            "77033 tensor(0.9938, device='cuda:0')\n",
            "77042 tensor(0.9965, device='cuda:0')\n",
            "77063 tensor(0.9990, device='cuda:0')\n",
            "77066 tensor(0.9994, device='cuda:0')\n",
            "77067 tensor(0.9976, device='cuda:0')\n",
            "77068 tensor(0.9995, device='cuda:0')\n",
            "77074 tensor(0.9918, device='cuda:0')\n",
            "77075 tensor(0.9989, device='cuda:0')\n",
            "77082 tensor(0.9985, device='cuda:0')\n",
            "77101 tensor(0.9992, device='cuda:0')\n",
            "77104 tensor(0.9907, device='cuda:0')\n",
            "77108 tensor(0.9913, device='cuda:0')\n",
            "77111 tensor(0.9998, device='cuda:0')\n",
            "77116 tensor(0.9916, device='cuda:0')\n",
            "77119 tensor(0.9985, device='cuda:0')\n",
            "77131 tensor(0.9962, device='cuda:0')\n",
            "77134 tensor(0.9980, device='cuda:0')\n",
            "77140 tensor(0.9974, device='cuda:0')\n",
            "77141 tensor(0.9953, device='cuda:0')\n",
            "77142 tensor(0.9991, device='cuda:0')\n",
            "77147 tensor(0.9985, device='cuda:0')\n",
            "77161 tensor(0.9996, device='cuda:0')\n",
            "77168 tensor(0.9977, device='cuda:0')\n",
            "77172 tensor(0.9969, device='cuda:0')\n",
            "77173 tensor(0.9908, device='cuda:0')\n",
            "77174 tensor(0.9937, device='cuda:0')\n",
            "77178 tensor(0.9946, device='cuda:0')\n",
            "77180 tensor(0.9967, device='cuda:0')\n",
            "77181 tensor(0.9992, device='cuda:0')\n",
            "77184 tensor(0.9901, device='cuda:0')\n",
            "77188 tensor(0.9994, device='cuda:0')\n",
            "77193 tensor(0.9989, device='cuda:0')\n",
            "77197 tensor(0.9972, device='cuda:0')\n",
            "77202 tensor(0.9970, device='cuda:0')\n",
            "77206 tensor(0.9916, device='cuda:0')\n",
            "77211 tensor(0.9955, device='cuda:0')\n",
            "77212 tensor(0.9944, device='cuda:0')\n",
            "77219 tensor(0.9979, device='cuda:0')\n",
            "77229 tensor(0.9936, device='cuda:0')\n",
            "77243 tensor(0.9991, device='cuda:0')\n",
            "77244 tensor(0.9992, device='cuda:0')\n",
            "77248 tensor(0.9945, device='cuda:0')\n",
            "77256 tensor(0.9926, device='cuda:0')\n",
            "77258 tensor(0.9926, device='cuda:0')\n",
            "77259 tensor(0.9997, device='cuda:0')\n",
            "77270 tensor(0.9966, device='cuda:0')\n",
            "77277 tensor(0.9907, device='cuda:0')\n",
            "77279 tensor(0.9987, device='cuda:0')\n",
            "77281 tensor(0.9946, device='cuda:0')\n",
            "77282 tensor(0.9994, device='cuda:0')\n",
            "77287 tensor(0.9978, device='cuda:0')\n",
            "77292 tensor(0.9997, device='cuda:0')\n",
            "77293 tensor(0.9927, device='cuda:0')\n",
            "77302 tensor(0.9948, device='cuda:0')\n",
            "77314 tensor(0.9990, device='cuda:0')\n",
            "77320 tensor(1.0000, device='cuda:0')\n",
            "77322 tensor(0.9982, device='cuda:0')\n",
            "77327 tensor(0.9998, device='cuda:0')\n",
            "77331 tensor(0.9974, device='cuda:0')\n",
            "77333 tensor(0.9936, device='cuda:0')\n",
            "77334 tensor(0.9995, device='cuda:0')\n",
            "77337 tensor(0.9920, device='cuda:0')\n",
            "77343 tensor(0.9988, device='cuda:0')\n",
            "77346 tensor(0.9986, device='cuda:0')\n",
            "77354 tensor(0.9970, device='cuda:0')\n",
            "77355 tensor(0.9910, device='cuda:0')\n",
            "77357 tensor(0.9997, device='cuda:0')\n",
            "77358 tensor(0.9981, device='cuda:0')\n",
            "77365 tensor(0.9981, device='cuda:0')\n",
            "77366 tensor(0.9993, device='cuda:0')\n",
            "77370 tensor(0.9974, device='cuda:0')\n",
            "77375 tensor(0.9931, device='cuda:0')\n",
            "77383 tensor(0.9970, device='cuda:0')\n",
            "77385 tensor(0.9972, device='cuda:0')\n",
            "77387 tensor(0.9915, device='cuda:0')\n",
            "77397 tensor(0.9978, device='cuda:0')\n",
            "77399 tensor(0.9946, device='cuda:0')\n",
            "77403 tensor(0.9913, device='cuda:0')\n",
            "77409 tensor(0.9952, device='cuda:0')\n",
            "77415 tensor(0.9959, device='cuda:0')\n",
            "77423 tensor(0.9985, device='cuda:0')\n",
            "77424 tensor(0.9935, device='cuda:0')\n",
            "77450 tensor(0.9905, device='cuda:0')\n",
            "77461 tensor(0.9904, device='cuda:0')\n",
            "77472 tensor(0.9944, device='cuda:0')\n",
            "77476 tensor(0.9996, device='cuda:0')\n",
            "77488 tensor(0.9958, device='cuda:0')\n",
            "77492 tensor(0.9987, device='cuda:0')\n",
            "77497 tensor(0.9979, device='cuda:0')\n",
            "77504 tensor(0.9992, device='cuda:0')\n",
            "77518 tensor(0.9994, device='cuda:0')\n",
            "77520 tensor(0.9991, device='cuda:0')\n",
            "77527 tensor(0.9985, device='cuda:0')\n",
            "77528 tensor(0.9995, device='cuda:0')\n",
            "77536 tensor(0.9949, device='cuda:0')\n",
            "77558 tensor(0.9998, device='cuda:0')\n",
            "77561 tensor(0.9955, device='cuda:0')\n",
            "77566 tensor(0.9992, device='cuda:0')\n",
            "77573 tensor(0.9953, device='cuda:0')\n",
            "77577 tensor(0.9967, device='cuda:0')\n",
            "77582 tensor(0.9959, device='cuda:0')\n",
            "77590 tensor(0.9984, device='cuda:0')\n",
            "77592 tensor(0.9984, device='cuda:0')\n",
            "77597 tensor(0.9923, device='cuda:0')\n",
            "77598 tensor(0.9932, device='cuda:0')\n",
            "77602 tensor(0.9978, device='cuda:0')\n",
            "77620 tensor(0.9993, device='cuda:0')\n",
            "77621 tensor(0.9931, device='cuda:0')\n",
            "77626 tensor(0.9980, device='cuda:0')\n",
            "77627 tensor(0.9939, device='cuda:0')\n",
            "77628 tensor(0.9970, device='cuda:0')\n",
            "77630 tensor(0.9967, device='cuda:0')\n",
            "77632 tensor(0.9993, device='cuda:0')\n",
            "77638 tensor(0.9996, device='cuda:0')\n",
            "77657 tensor(0.9963, device='cuda:0')\n",
            "77658 tensor(1.0000, device='cuda:0')\n",
            "77668 tensor(0.9999, device='cuda:0')\n",
            "77669 tensor(0.9969, device='cuda:0')\n",
            "77672 tensor(0.9984, device='cuda:0')\n",
            "77676 tensor(0.9918, device='cuda:0')\n",
            "77677 tensor(0.9988, device='cuda:0')\n",
            "77681 tensor(0.9979, device='cuda:0')\n",
            "77682 tensor(0.9976, device='cuda:0')\n",
            "77686 tensor(0.9979, device='cuda:0')\n",
            "77690 tensor(0.9980, device='cuda:0')\n",
            "77694 tensor(0.9999, device='cuda:0')\n",
            "77704 tensor(0.9977, device='cuda:0')\n",
            "77705 tensor(0.9996, device='cuda:0')\n",
            "77707 tensor(0.9915, device='cuda:0')\n",
            "77713 tensor(0.9997, device='cuda:0')\n",
            "77727 tensor(0.9952, device='cuda:0')\n",
            "77737 tensor(0.9976, device='cuda:0')\n",
            "77738 tensor(0.9947, device='cuda:0')\n",
            "77740 tensor(0.9997, device='cuda:0')\n",
            "77746 tensor(0.9993, device='cuda:0')\n",
            "77750 tensor(0.9995, device='cuda:0')\n",
            "77752 tensor(0.9963, device='cuda:0')\n",
            "77755 tensor(0.9913, device='cuda:0')\n",
            "77763 tensor(0.9987, device='cuda:0')\n",
            "77765 tensor(0.9906, device='cuda:0')\n",
            "77771 tensor(0.9907, device='cuda:0')\n",
            "77797 tensor(0.9998, device='cuda:0')\n",
            "77798 tensor(0.9923, device='cuda:0')\n",
            "77802 tensor(0.9999, device='cuda:0')\n",
            "77803 tensor(0.9999, device='cuda:0')\n",
            "77809 tensor(0.9996, device='cuda:0')\n",
            "77816 tensor(0.9996, device='cuda:0')\n",
            "77818 tensor(0.9997, device='cuda:0')\n",
            "77821 tensor(0.9941, device='cuda:0')\n",
            "77826 tensor(0.9917, device='cuda:0')\n",
            "77829 tensor(0.9985, device='cuda:0')\n",
            "77830 tensor(0.9992, device='cuda:0')\n",
            "77831 tensor(0.9942, device='cuda:0')\n",
            "77833 tensor(0.9951, device='cuda:0')\n",
            "77845 tensor(0.9936, device='cuda:0')\n",
            "77861 tensor(0.9948, device='cuda:0')\n",
            "77867 tensor(0.9995, device='cuda:0')\n",
            "77871 tensor(0.9931, device='cuda:0')\n",
            "77872 tensor(0.9912, device='cuda:0')\n",
            "77879 tensor(0.9998, device='cuda:0')\n",
            "77881 tensor(0.9987, device='cuda:0')\n",
            "77884 tensor(0.9972, device='cuda:0')\n",
            "77885 tensor(0.9985, device='cuda:0')\n",
            "77887 tensor(0.9999, device='cuda:0')\n",
            "77892 tensor(0.9995, device='cuda:0')\n",
            "77895 tensor(0.9969, device='cuda:0')\n",
            "77901 tensor(0.9994, device='cuda:0')\n",
            "77903 tensor(0.9996, device='cuda:0')\n",
            "77911 tensor(0.9989, device='cuda:0')\n",
            "77912 tensor(0.9987, device='cuda:0')\n",
            "77915 tensor(0.9993, device='cuda:0')\n",
            "77924 tensor(0.9984, device='cuda:0')\n",
            "77929 tensor(0.9995, device='cuda:0')\n",
            "77934 tensor(0.9996, device='cuda:0')\n",
            "77949 tensor(0.9991, device='cuda:0')\n",
            "77951 tensor(0.9998, device='cuda:0')\n",
            "77952 tensor(0.9984, device='cuda:0')\n",
            "77959 tensor(0.9984, device='cuda:0')\n",
            "77964 tensor(0.9995, device='cuda:0')\n",
            "77973 tensor(0.9990, device='cuda:0')\n",
            "77981 tensor(0.9999, device='cuda:0')\n",
            "77983 tensor(0.9917, device='cuda:0')\n",
            "77986 tensor(0.9986, device='cuda:0')\n",
            "77987 tensor(0.9979, device='cuda:0')\n",
            "77998 tensor(0.9953, device='cuda:0')\n",
            "78008 tensor(0.9992, device='cuda:0')\n",
            "78021 tensor(0.9983, device='cuda:0')\n",
            "78026 tensor(0.9928, device='cuda:0')\n",
            "78032 tensor(0.9998, device='cuda:0')\n",
            "78038 tensor(0.9998, device='cuda:0')\n",
            "78046 tensor(0.9963, device='cuda:0')\n",
            "78048 tensor(0.9984, device='cuda:0')\n",
            "78061 tensor(0.9989, device='cuda:0')\n",
            "78070 tensor(0.9973, device='cuda:0')\n",
            "78071 tensor(0.9937, device='cuda:0')\n",
            "78076 tensor(0.9985, device='cuda:0')\n",
            "78097 tensor(0.9998, device='cuda:0')\n",
            "78099 tensor(0.9976, device='cuda:0')\n",
            "78101 tensor(0.9939, device='cuda:0')\n",
            "78103 tensor(1.0000, device='cuda:0')\n",
            "78112 tensor(0.9992, device='cuda:0')\n",
            "78113 tensor(0.9997, device='cuda:0')\n",
            "78114 tensor(0.9939, device='cuda:0')\n",
            "78115 tensor(0.9967, device='cuda:0')\n",
            "78118 tensor(0.9954, device='cuda:0')\n",
            "78122 tensor(0.9989, device='cuda:0')\n",
            "78125 tensor(0.9999, device='cuda:0')\n",
            "78126 tensor(0.9995, device='cuda:0')\n",
            "78128 tensor(0.9937, device='cuda:0')\n",
            "78144 tensor(0.9985, device='cuda:0')\n",
            "78155 tensor(0.9997, device='cuda:0')\n",
            "78165 tensor(0.9987, device='cuda:0')\n",
            "78167 tensor(0.9939, device='cuda:0')\n",
            "78171 tensor(0.9983, device='cuda:0')\n",
            "78173 tensor(0.9919, device='cuda:0')\n",
            "78175 tensor(0.9968, device='cuda:0')\n",
            "78183 tensor(0.9914, device='cuda:0')\n",
            "78185 tensor(0.9901, device='cuda:0')\n",
            "78189 tensor(0.9980, device='cuda:0')\n",
            "78192 tensor(0.9994, device='cuda:0')\n",
            "78196 tensor(0.9957, device='cuda:0')\n",
            "78197 tensor(0.9961, device='cuda:0')\n",
            "78200 tensor(0.9958, device='cuda:0')\n",
            "78202 tensor(0.9969, device='cuda:0')\n",
            "78204 tensor(0.9988, device='cuda:0')\n",
            "78218 tensor(0.9996, device='cuda:0')\n",
            "78227 tensor(0.9993, device='cuda:0')\n",
            "78231 tensor(0.9989, device='cuda:0')\n",
            "78236 tensor(0.9962, device='cuda:0')\n",
            "78240 tensor(0.9984, device='cuda:0')\n",
            "78243 tensor(0.9995, device='cuda:0')\n",
            "78245 tensor(0.9975, device='cuda:0')\n",
            "78246 tensor(0.9997, device='cuda:0')\n",
            "78255 tensor(0.9958, device='cuda:0')\n",
            "78260 tensor(0.9965, device='cuda:0')\n",
            "78266 tensor(0.9967, device='cuda:0')\n",
            "78272 tensor(0.9992, device='cuda:0')\n",
            "78273 tensor(0.9963, device='cuda:0')\n",
            "78282 tensor(0.9984, device='cuda:0')\n",
            "78283 tensor(0.9979, device='cuda:0')\n",
            "78288 tensor(0.9908, device='cuda:0')\n",
            "78297 tensor(0.9919, device='cuda:0')\n",
            "78320 tensor(0.9947, device='cuda:0')\n",
            "78321 tensor(0.9913, device='cuda:0')\n",
            "78323 tensor(0.9988, device='cuda:0')\n",
            "78329 tensor(0.9947, device='cuda:0')\n",
            "78335 tensor(0.9995, device='cuda:0')\n",
            "78337 tensor(0.9952, device='cuda:0')\n",
            "78346 tensor(0.9945, device='cuda:0')\n",
            "78357 tensor(0.9977, device='cuda:0')\n",
            "78366 tensor(0.9911, device='cuda:0')\n",
            "78370 tensor(0.9978, device='cuda:0')\n",
            "78375 tensor(0.9989, device='cuda:0')\n",
            "78376 tensor(0.9948, device='cuda:0')\n",
            "78380 tensor(0.9922, device='cuda:0')\n",
            "78385 tensor(0.9970, device='cuda:0')\n",
            "78395 tensor(0.9915, device='cuda:0')\n",
            "78401 tensor(0.9993, device='cuda:0')\n",
            "78404 tensor(0.9949, device='cuda:0')\n",
            "78406 tensor(0.9993, device='cuda:0')\n",
            "78420 tensor(0.9930, device='cuda:0')\n",
            "78428 tensor(0.9980, device='cuda:0')\n",
            "78429 tensor(0.9998, device='cuda:0')\n",
            "78434 tensor(0.9997, device='cuda:0')\n",
            "78441 tensor(0.9988, device='cuda:0')\n",
            "78448 tensor(0.9906, device='cuda:0')\n",
            "78452 tensor(0.9968, device='cuda:0')\n",
            "78472 tensor(0.9965, device='cuda:0')\n",
            "78475 tensor(0.9976, device='cuda:0')\n",
            "78480 tensor(0.9920, device='cuda:0')\n",
            "78481 tensor(0.9978, device='cuda:0')\n",
            "78482 tensor(0.9980, device='cuda:0')\n",
            "78486 tensor(0.9963, device='cuda:0')\n",
            "78494 tensor(0.9928, device='cuda:0')\n",
            "78497 tensor(0.9964, device='cuda:0')\n",
            "78498 tensor(0.9986, device='cuda:0')\n",
            "78500 tensor(0.9908, device='cuda:0')\n",
            "78533 tensor(0.9988, device='cuda:0')\n",
            "78536 tensor(0.9993, device='cuda:0')\n",
            "78537 tensor(0.9932, device='cuda:0')\n",
            "78551 tensor(0.9920, device='cuda:0')\n",
            "78552 tensor(0.9997, device='cuda:0')\n",
            "78560 tensor(0.9901, device='cuda:0')\n",
            "78565 tensor(0.9942, device='cuda:0')\n",
            "78570 tensor(0.9905, device='cuda:0')\n",
            "78575 tensor(0.9912, device='cuda:0')\n",
            "78580 tensor(0.9940, device='cuda:0')\n",
            "78583 tensor(0.9956, device='cuda:0')\n",
            "78587 tensor(0.9926, device='cuda:0')\n",
            "78595 tensor(0.9963, device='cuda:0')\n",
            "78596 tensor(0.9982, device='cuda:0')\n",
            "78597 tensor(0.9912, device='cuda:0')\n",
            "78606 tensor(0.9998, device='cuda:0')\n",
            "78616 tensor(0.9978, device='cuda:0')\n",
            "78622 tensor(0.9946, device='cuda:0')\n",
            "78626 tensor(0.9904, device='cuda:0')\n",
            "78630 tensor(0.9983, device='cuda:0')\n",
            "78631 tensor(0.9998, device='cuda:0')\n",
            "78632 tensor(0.9948, device='cuda:0')\n",
            "78641 tensor(0.9963, device='cuda:0')\n",
            "78649 tensor(0.9972, device='cuda:0')\n",
            "78650 tensor(0.9967, device='cuda:0')\n",
            "78654 tensor(0.9967, device='cuda:0')\n",
            "78663 tensor(0.9970, device='cuda:0')\n",
            "78666 tensor(0.9999, device='cuda:0')\n",
            "78671 tensor(0.9965, device='cuda:0')\n",
            "78672 tensor(0.9972, device='cuda:0')\n",
            "78674 tensor(0.9928, device='cuda:0')\n",
            "78677 tensor(0.9921, device='cuda:0')\n",
            "78678 tensor(0.9986, device='cuda:0')\n",
            "78683 tensor(0.9991, device='cuda:0')\n",
            "78694 tensor(0.9927, device='cuda:0')\n",
            "78699 tensor(0.9955, device='cuda:0')\n",
            "78705 tensor(0.9914, device='cuda:0')\n",
            "78708 tensor(0.9996, device='cuda:0')\n",
            "78716 tensor(0.9985, device='cuda:0')\n",
            "78720 tensor(0.9924, device='cuda:0')\n",
            "78724 tensor(0.9986, device='cuda:0')\n",
            "78731 tensor(0.9994, device='cuda:0')\n",
            "78734 tensor(0.9986, device='cuda:0')\n",
            "78738 tensor(0.9999, device='cuda:0')\n",
            "78742 tensor(0.9997, device='cuda:0')\n",
            "78743 tensor(0.9969, device='cuda:0')\n",
            "78748 tensor(0.9997, device='cuda:0')\n",
            "78750 tensor(0.9919, device='cuda:0')\n",
            "78754 tensor(0.9901, device='cuda:0')\n",
            "78767 tensor(0.9940, device='cuda:0')\n",
            "78772 tensor(0.9991, device='cuda:0')\n",
            "78777 tensor(0.9997, device='cuda:0')\n",
            "78785 tensor(0.9993, device='cuda:0')\n",
            "78796 tensor(0.9990, device='cuda:0')\n",
            "78806 tensor(0.9915, device='cuda:0')\n",
            "78811 tensor(0.9946, device='cuda:0')\n",
            "78830 tensor(0.9940, device='cuda:0')\n",
            "78834 tensor(0.9973, device='cuda:0')\n",
            "78840 tensor(0.9917, device='cuda:0')\n",
            "78850 tensor(0.9979, device='cuda:0')\n",
            "78861 tensor(0.9984, device='cuda:0')\n",
            "78867 tensor(0.9984, device='cuda:0')\n",
            "78872 tensor(0.9920, device='cuda:0')\n",
            "78874 tensor(0.9922, device='cuda:0')\n",
            "78878 tensor(0.9946, device='cuda:0')\n",
            "78881 tensor(0.9979, device='cuda:0')\n",
            "78886 tensor(0.9938, device='cuda:0')\n",
            "78892 tensor(0.9922, device='cuda:0')\n",
            "78893 tensor(0.9979, device='cuda:0')\n",
            "78896 tensor(0.9966, device='cuda:0')\n",
            "78906 tensor(0.9949, device='cuda:0')\n",
            "78909 tensor(0.9981, device='cuda:0')\n",
            "78916 tensor(0.9999, device='cuda:0')\n",
            "78920 tensor(0.9996, device='cuda:0')\n",
            "78922 tensor(0.9951, device='cuda:0')\n",
            "78927 tensor(0.9998, device='cuda:0')\n",
            "78928 tensor(0.9975, device='cuda:0')\n",
            "78931 tensor(0.9921, device='cuda:0')\n",
            "78954 tensor(0.9962, device='cuda:0')\n",
            "78960 tensor(0.9983, device='cuda:0')\n",
            "78961 tensor(0.9942, device='cuda:0')\n",
            "78974 tensor(0.9932, device='cuda:0')\n",
            "78980 tensor(0.9988, device='cuda:0')\n",
            "78982 tensor(0.9999, device='cuda:0')\n",
            "78987 tensor(0.9904, device='cuda:0')\n",
            "78993 tensor(0.9945, device='cuda:0')\n",
            "78994 tensor(0.9986, device='cuda:0')\n",
            "78996 tensor(0.9977, device='cuda:0')\n",
            "78997 tensor(0.9909, device='cuda:0')\n",
            "79001 tensor(0.9906, device='cuda:0')\n",
            "79003 tensor(0.9969, device='cuda:0')\n",
            "79006 tensor(0.9980, device='cuda:0')\n",
            "79010 tensor(0.9914, device='cuda:0')\n",
            "79012 tensor(0.9953, device='cuda:0')\n",
            "79013 tensor(0.9983, device='cuda:0')\n",
            "79016 tensor(0.9978, device='cuda:0')\n",
            "79022 tensor(0.9902, device='cuda:0')\n",
            "79028 tensor(0.9916, device='cuda:0')\n",
            "79039 tensor(0.9936, device='cuda:0')\n",
            "79043 tensor(0.9919, device='cuda:0')\n",
            "79047 tensor(0.9980, device='cuda:0')\n",
            "79050 tensor(0.9998, device='cuda:0')\n",
            "79052 tensor(0.9919, device='cuda:0')\n",
            "79054 tensor(0.9983, device='cuda:0')\n",
            "79061 tensor(0.9926, device='cuda:0')\n",
            "79065 tensor(0.9940, device='cuda:0')\n",
            "79068 tensor(0.9994, device='cuda:0')\n",
            "79072 tensor(0.9933, device='cuda:0')\n",
            "79081 tensor(0.9962, device='cuda:0')\n",
            "79086 tensor(0.9997, device='cuda:0')\n",
            "79087 tensor(0.9998, device='cuda:0')\n",
            "79096 tensor(0.9953, device='cuda:0')\n",
            "79097 tensor(0.9994, device='cuda:0')\n",
            "79102 tensor(0.9966, device='cuda:0')\n",
            "79103 tensor(0.9993, device='cuda:0')\n",
            "79108 tensor(0.9970, device='cuda:0')\n",
            "79110 tensor(0.9993, device='cuda:0')\n",
            "79119 tensor(0.9919, device='cuda:0')\n",
            "79126 tensor(0.9930, device='cuda:0')\n",
            "79127 tensor(0.9984, device='cuda:0')\n",
            "79129 tensor(0.9965, device='cuda:0')\n",
            "79133 tensor(0.9962, device='cuda:0')\n",
            "79141 tensor(0.9964, device='cuda:0')\n",
            "79144 tensor(0.9962, device='cuda:0')\n",
            "79146 tensor(0.9998, device='cuda:0')\n",
            "79150 tensor(0.9991, device='cuda:0')\n",
            "79151 tensor(0.9949, device='cuda:0')\n",
            "79160 tensor(0.9980, device='cuda:0')\n",
            "79165 tensor(0.9995, device='cuda:0')\n",
            "79175 tensor(0.9990, device='cuda:0')\n",
            "79177 tensor(0.9977, device='cuda:0')\n",
            "79178 tensor(0.9989, device='cuda:0')\n",
            "79182 tensor(0.9941, device='cuda:0')\n",
            "79184 tensor(0.9948, device='cuda:0')\n",
            "79188 tensor(0.9994, device='cuda:0')\n",
            "79194 tensor(0.9988, device='cuda:0')\n",
            "79198 tensor(0.9981, device='cuda:0')\n",
            "79200 tensor(0.9981, device='cuda:0')\n",
            "79203 tensor(0.9914, device='cuda:0')\n",
            "79204 tensor(0.9988, device='cuda:0')\n",
            "79206 tensor(0.9999, device='cuda:0')\n",
            "79210 tensor(0.9996, device='cuda:0')\n",
            "79211 tensor(0.9973, device='cuda:0')\n",
            "79215 tensor(0.9975, device='cuda:0')\n",
            "79230 tensor(0.9961, device='cuda:0')\n",
            "79238 tensor(0.9980, device='cuda:0')\n",
            "79242 tensor(0.9916, device='cuda:0')\n",
            "79247 tensor(0.9963, device='cuda:0')\n",
            "79250 tensor(0.9925, device='cuda:0')\n",
            "79253 tensor(0.9998, device='cuda:0')\n",
            "79256 tensor(0.9985, device='cuda:0')\n",
            "79265 tensor(0.9956, device='cuda:0')\n",
            "79267 tensor(0.9911, device='cuda:0')\n",
            "79268 tensor(0.9994, device='cuda:0')\n",
            "79272 tensor(0.9904, device='cuda:0')\n",
            "79279 tensor(0.9999, device='cuda:0')\n",
            "79288 tensor(0.9968, device='cuda:0')\n",
            "79294 tensor(0.9957, device='cuda:0')\n",
            "79295 tensor(0.9990, device='cuda:0')\n",
            "79296 tensor(0.9957, device='cuda:0')\n",
            "79297 tensor(0.9941, device='cuda:0')\n",
            "79309 tensor(0.9998, device='cuda:0')\n",
            "79310 tensor(0.9981, device='cuda:0')\n",
            "79311 tensor(0.9910, device='cuda:0')\n",
            "79324 tensor(0.9905, device='cuda:0')\n",
            "79325 tensor(0.9963, device='cuda:0')\n",
            "79326 tensor(0.9942, device='cuda:0')\n",
            "79365 tensor(0.9966, device='cuda:0')\n",
            "79370 tensor(0.9904, device='cuda:0')\n",
            "79375 tensor(0.9990, device='cuda:0')\n",
            "79377 tensor(0.9932, device='cuda:0')\n",
            "79379 tensor(0.9949, device='cuda:0')\n",
            "79386 tensor(0.9977, device='cuda:0')\n",
            "79391 tensor(0.9999, device='cuda:0')\n",
            "79399 tensor(0.9994, device='cuda:0')\n",
            "79405 tensor(0.9947, device='cuda:0')\n",
            "79418 tensor(0.9957, device='cuda:0')\n",
            "79421 tensor(0.9988, device='cuda:0')\n",
            "79422 tensor(0.9977, device='cuda:0')\n",
            "79427 tensor(0.9951, device='cuda:0')\n",
            "79433 tensor(0.9982, device='cuda:0')\n",
            "79438 tensor(0.9991, device='cuda:0')\n",
            "79439 tensor(0.9963, device='cuda:0')\n",
            "79442 tensor(0.9942, device='cuda:0')\n",
            "79447 tensor(0.9975, device='cuda:0')\n",
            "79450 tensor(0.9992, device='cuda:0')\n",
            "79456 tensor(0.9971, device='cuda:0')\n",
            "79458 tensor(0.9985, device='cuda:0')\n",
            "79466 tensor(0.9925, device='cuda:0')\n",
            "79467 tensor(0.9912, device='cuda:0')\n",
            "79472 tensor(0.9995, device='cuda:0')\n",
            "79479 tensor(0.9980, device='cuda:0')\n",
            "79481 tensor(0.9959, device='cuda:0')\n",
            "79484 tensor(0.9918, device='cuda:0')\n",
            "79487 tensor(0.9979, device='cuda:0')\n",
            "79493 tensor(0.9964, device='cuda:0')\n",
            "79494 tensor(0.9982, device='cuda:0')\n",
            "79503 tensor(0.9998, device='cuda:0')\n",
            "79508 tensor(0.9958, device='cuda:0')\n",
            "79516 tensor(0.9995, device='cuda:0')\n",
            "79523 tensor(0.9934, device='cuda:0')\n",
            "79531 tensor(0.9943, device='cuda:0')\n",
            "79534 tensor(0.9972, device='cuda:0')\n",
            "79535 tensor(0.9961, device='cuda:0')\n",
            "79538 tensor(0.9970, device='cuda:0')\n",
            "79548 tensor(0.9993, device='cuda:0')\n",
            "79554 tensor(0.9931, device='cuda:0')\n",
            "79557 tensor(0.9941, device='cuda:0')\n",
            "79558 tensor(0.9987, device='cuda:0')\n",
            "79562 tensor(0.9954, device='cuda:0')\n",
            "79570 tensor(0.9995, device='cuda:0')\n",
            "79574 tensor(0.9999, device='cuda:0')\n",
            "79580 tensor(0.9997, device='cuda:0')\n",
            "79589 tensor(0.9938, device='cuda:0')\n",
            "79597 tensor(0.9930, device='cuda:0')\n",
            "79599 tensor(0.9997, device='cuda:0')\n",
            "79606 tensor(0.9985, device='cuda:0')\n",
            "79613 tensor(0.9991, device='cuda:0')\n",
            "79620 tensor(0.9989, device='cuda:0')\n",
            "79622 tensor(0.9974, device='cuda:0')\n",
            "79624 tensor(0.9999, device='cuda:0')\n",
            "79633 tensor(0.9956, device='cuda:0')\n",
            "79636 tensor(0.9968, device='cuda:0')\n",
            "79638 tensor(0.9925, device='cuda:0')\n",
            "79661 tensor(0.9923, device='cuda:0')\n",
            "79664 tensor(0.9986, device='cuda:0')\n",
            "79666 tensor(0.9998, device='cuda:0')\n",
            "79670 tensor(0.9973, device='cuda:0')\n",
            "79672 tensor(0.9932, device='cuda:0')\n",
            "79678 tensor(0.9952, device='cuda:0')\n",
            "79681 tensor(0.9995, device='cuda:0')\n",
            "79684 tensor(0.9983, device='cuda:0')\n",
            "79685 tensor(0.9933, device='cuda:0')\n",
            "79686 tensor(0.9994, device='cuda:0')\n",
            "79692 tensor(0.9916, device='cuda:0')\n",
            "79693 tensor(0.9934, device='cuda:0')\n",
            "79695 tensor(0.9933, device='cuda:0')\n",
            "79696 tensor(0.9998, device='cuda:0')\n",
            "79705 tensor(0.9990, device='cuda:0')\n",
            "79710 tensor(0.9984, device='cuda:0')\n",
            "79718 tensor(0.9994, device='cuda:0')\n",
            "79737 tensor(0.9905, device='cuda:0')\n",
            "79748 tensor(0.9990, device='cuda:0')\n",
            "79749 tensor(1.0000, device='cuda:0')\n",
            "79758 tensor(0.9948, device='cuda:0')\n",
            "79759 tensor(0.9910, device='cuda:0')\n",
            "79764 tensor(1.0000, device='cuda:0')\n",
            "79769 tensor(0.9942, device='cuda:0')\n",
            "79780 tensor(0.9975, device='cuda:0')\n",
            "79788 tensor(0.9928, device='cuda:0')\n",
            "79793 tensor(0.9939, device='cuda:0')\n",
            "79794 tensor(0.9971, device='cuda:0')\n",
            "79804 tensor(0.9995, device='cuda:0')\n",
            "79807 tensor(0.9921, device='cuda:0')\n",
            "79809 tensor(0.9993, device='cuda:0')\n",
            "79811 tensor(0.9985, device='cuda:0')\n",
            "79828 tensor(0.9977, device='cuda:0')\n",
            "79831 tensor(0.9994, device='cuda:0')\n",
            "79834 tensor(0.9998, device='cuda:0')\n",
            "79835 tensor(0.9939, device='cuda:0')\n",
            "79840 tensor(0.9978, device='cuda:0')\n",
            "79845 tensor(0.9931, device='cuda:0')\n",
            "79846 tensor(0.9997, device='cuda:0')\n",
            "79851 tensor(0.9975, device='cuda:0')\n",
            "79852 tensor(0.9999, device='cuda:0')\n",
            "79853 tensor(0.9950, device='cuda:0')\n",
            "79857 tensor(0.9917, device='cuda:0')\n",
            "79858 tensor(0.9963, device='cuda:0')\n",
            "79864 tensor(0.9990, device='cuda:0')\n",
            "79865 tensor(0.9967, device='cuda:0')\n",
            "79877 tensor(0.9976, device='cuda:0')\n",
            "79879 tensor(0.9998, device='cuda:0')\n",
            "79883 tensor(0.9989, device='cuda:0')\n",
            "79897 tensor(0.9991, device='cuda:0')\n",
            "79912 tensor(0.9985, device='cuda:0')\n",
            "79913 tensor(0.9964, device='cuda:0')\n",
            "79919 tensor(0.9992, device='cuda:0')\n",
            "79925 tensor(0.9996, device='cuda:0')\n",
            "79928 tensor(0.9983, device='cuda:0')\n",
            "79932 tensor(0.9931, device='cuda:0')\n",
            "79937 tensor(0.9952, device='cuda:0')\n",
            "79939 tensor(0.9950, device='cuda:0')\n",
            "79945 tensor(0.9918, device='cuda:0')\n",
            "79947 tensor(0.9996, device='cuda:0')\n",
            "79948 tensor(0.9986, device='cuda:0')\n",
            "79954 tensor(0.9972, device='cuda:0')\n",
            "79971 tensor(0.9954, device='cuda:0')\n",
            "79974 tensor(0.9974, device='cuda:0')\n",
            "79975 tensor(0.9976, device='cuda:0')\n",
            "79977 tensor(0.9917, device='cuda:0')\n",
            "79983 tensor(0.9977, device='cuda:0')\n",
            "79984 tensor(0.9936, device='cuda:0')\n",
            "79985 tensor(0.9972, device='cuda:0')\n",
            "79987 tensor(0.9910, device='cuda:0')\n",
            "79993 tensor(0.9986, device='cuda:0')\n",
            "79997 tensor(0.9995, device='cuda:0')\n",
            "80001 tensor(0.9943, device='cuda:0')\n",
            "80002 tensor(0.9937, device='cuda:0')\n",
            "80003 tensor(0.9999, device='cuda:0')\n",
            "80007 tensor(0.9982, device='cuda:0')\n",
            "80014 tensor(0.9977, device='cuda:0')\n",
            "80023 tensor(0.9970, device='cuda:0')\n",
            "80027 tensor(0.9986, device='cuda:0')\n",
            "80040 tensor(0.9941, device='cuda:0')\n",
            "80046 tensor(0.9933, device='cuda:0')\n",
            "80047 tensor(0.9928, device='cuda:0')\n",
            "80048 tensor(0.9936, device='cuda:0')\n",
            "80060 tensor(0.9968, device='cuda:0')\n",
            "80068 tensor(0.9941, device='cuda:0')\n",
            "80070 tensor(0.9973, device='cuda:0')\n",
            "80072 tensor(0.9946, device='cuda:0')\n",
            "80092 tensor(0.9943, device='cuda:0')\n",
            "80093 tensor(0.9916, device='cuda:0')\n",
            "80095 tensor(0.9996, device='cuda:0')\n",
            "80096 tensor(0.9947, device='cuda:0')\n",
            "80107 tensor(0.9916, device='cuda:0')\n",
            "80109 tensor(0.9947, device='cuda:0')\n",
            "80111 tensor(0.9934, device='cuda:0')\n",
            "80113 tensor(0.9986, device='cuda:0')\n",
            "80117 tensor(0.9976, device='cuda:0')\n",
            "80121 tensor(0.9999, device='cuda:0')\n",
            "80139 tensor(0.9910, device='cuda:0')\n",
            "80141 tensor(0.9980, device='cuda:0')\n",
            "80143 tensor(0.9967, device='cuda:0')\n",
            "80144 tensor(0.9961, device='cuda:0')\n",
            "80146 tensor(0.9995, device='cuda:0')\n",
            "80148 tensor(0.9963, device='cuda:0')\n",
            "80158 tensor(0.9906, device='cuda:0')\n",
            "80162 tensor(0.9946, device='cuda:0')\n",
            "80165 tensor(0.9982, device='cuda:0')\n",
            "80174 tensor(0.9917, device='cuda:0')\n",
            "80175 tensor(0.9995, device='cuda:0')\n",
            "80177 tensor(0.9980, device='cuda:0')\n",
            "80188 tensor(0.9929, device='cuda:0')\n",
            "80190 tensor(0.9984, device='cuda:0')\n",
            "80199 tensor(0.9978, device='cuda:0')\n",
            "80203 tensor(0.9998, device='cuda:0')\n",
            "80204 tensor(0.9903, device='cuda:0')\n",
            "80205 tensor(0.9987, device='cuda:0')\n",
            "80217 tensor(0.9983, device='cuda:0')\n",
            "80219 tensor(0.9949, device='cuda:0')\n",
            "80220 tensor(0.9993, device='cuda:0')\n",
            "80221 tensor(0.9911, device='cuda:0')\n",
            "80222 tensor(0.9933, device='cuda:0')\n",
            "80223 tensor(0.9989, device='cuda:0')\n",
            "80245 tensor(0.9972, device='cuda:0')\n",
            "80253 tensor(0.9991, device='cuda:0')\n",
            "80257 tensor(0.9905, device='cuda:0')\n",
            "80263 tensor(0.9943, device='cuda:0')\n",
            "80271 tensor(0.9922, device='cuda:0')\n",
            "80282 tensor(0.9939, device='cuda:0')\n",
            "80283 tensor(0.9999, device='cuda:0')\n",
            "80287 tensor(0.9946, device='cuda:0')\n",
            "80288 tensor(0.9971, device='cuda:0')\n",
            "80302 tensor(0.9995, device='cuda:0')\n",
            "80304 tensor(0.9971, device='cuda:0')\n",
            "80306 tensor(0.9999, device='cuda:0')\n",
            "80307 tensor(0.9946, device='cuda:0')\n",
            "80308 tensor(0.9946, device='cuda:0')\n",
            "80319 tensor(0.9904, device='cuda:0')\n",
            "80321 tensor(1.0000, device='cuda:0')\n",
            "80334 tensor(0.9992, device='cuda:0')\n",
            "80345 tensor(0.9932, device='cuda:0')\n",
            "80349 tensor(0.9923, device='cuda:0')\n",
            "80354 tensor(0.9992, device='cuda:0')\n",
            "80355 tensor(0.9992, device='cuda:0')\n",
            "80361 tensor(0.9935, device='cuda:0')\n",
            "80364 tensor(0.9977, device='cuda:0')\n",
            "80365 tensor(0.9979, device='cuda:0')\n",
            "80370 tensor(0.9972, device='cuda:0')\n",
            "80372 tensor(0.9949, device='cuda:0')\n",
            "80373 tensor(0.9987, device='cuda:0')\n",
            "80375 tensor(0.9952, device='cuda:0')\n",
            "80381 tensor(0.9989, device='cuda:0')\n",
            "80383 tensor(0.9989, device='cuda:0')\n",
            "80388 tensor(0.9977, device='cuda:0')\n",
            "80391 tensor(0.9914, device='cuda:0')\n",
            "80407 tensor(0.9957, device='cuda:0')\n",
            "80409 tensor(0.9963, device='cuda:0')\n",
            "80426 tensor(0.9998, device='cuda:0')\n",
            "80428 tensor(0.9971, device='cuda:0')\n",
            "80438 tensor(0.9991, device='cuda:0')\n",
            "80439 tensor(0.9932, device='cuda:0')\n",
            "80443 tensor(0.9913, device='cuda:0')\n",
            "80448 tensor(0.9931, device='cuda:0')\n",
            "80449 tensor(0.9984, device='cuda:0')\n",
            "80453 tensor(0.9964, device='cuda:0')\n",
            "80464 tensor(0.9974, device='cuda:0')\n",
            "80465 tensor(0.9999, device='cuda:0')\n",
            "80468 tensor(0.9996, device='cuda:0')\n",
            "80472 tensor(0.9976, device='cuda:0')\n",
            "80473 tensor(0.9996, device='cuda:0')\n",
            "80485 tensor(0.9993, device='cuda:0')\n",
            "80488 tensor(0.9939, device='cuda:0')\n",
            "80497 tensor(0.9970, device='cuda:0')\n",
            "80498 tensor(0.9946, device='cuda:0')\n",
            "80499 tensor(0.9995, device='cuda:0')\n",
            "80511 tensor(0.9923, device='cuda:0')\n",
            "80514 tensor(0.9992, device='cuda:0')\n",
            "80517 tensor(0.9996, device='cuda:0')\n",
            "80523 tensor(0.9999, device='cuda:0')\n",
            "80545 tensor(0.9981, device='cuda:0')\n",
            "80547 tensor(0.9985, device='cuda:0')\n",
            "80551 tensor(0.9964, device='cuda:0')\n",
            "80555 tensor(0.9986, device='cuda:0')\n",
            "80559 tensor(0.9969, device='cuda:0')\n",
            "80560 tensor(0.9995, device='cuda:0')\n",
            "80562 tensor(0.9945, device='cuda:0')\n",
            "80567 tensor(0.9990, device='cuda:0')\n",
            "80571 tensor(0.9987, device='cuda:0')\n",
            "80572 tensor(0.9925, device='cuda:0')\n",
            "80577 tensor(0.9914, device='cuda:0')\n",
            "80588 tensor(0.9993, device='cuda:0')\n",
            "80592 tensor(0.9990, device='cuda:0')\n",
            "80593 tensor(0.9991, device='cuda:0')\n",
            "80606 tensor(0.9925, device='cuda:0')\n",
            "80609 tensor(0.9979, device='cuda:0')\n",
            "80615 tensor(0.9938, device='cuda:0')\n",
            "80616 tensor(0.9991, device='cuda:0')\n",
            "80624 tensor(0.9981, device='cuda:0')\n",
            "80629 tensor(0.9949, device='cuda:0')\n",
            "80639 tensor(0.9934, device='cuda:0')\n",
            "80647 tensor(0.9979, device='cuda:0')\n",
            "80650 tensor(0.9967, device='cuda:0')\n",
            "80653 tensor(0.9928, device='cuda:0')\n",
            "80656 tensor(0.9995, device='cuda:0')\n",
            "80660 tensor(0.9993, device='cuda:0')\n",
            "80666 tensor(0.9997, device='cuda:0')\n",
            "80668 tensor(0.9999, device='cuda:0')\n",
            "80673 tensor(0.9925, device='cuda:0')\n",
            "80686 tensor(0.9996, device='cuda:0')\n",
            "80688 tensor(0.9977, device='cuda:0')\n",
            "80692 tensor(0.9985, device='cuda:0')\n",
            "80693 tensor(0.9909, device='cuda:0')\n",
            "80702 tensor(0.9987, device='cuda:0')\n",
            "80713 tensor(0.9941, device='cuda:0')\n",
            "80720 tensor(0.9984, device='cuda:0')\n",
            "80723 tensor(0.9972, device='cuda:0')\n",
            "80724 tensor(0.9985, device='cuda:0')\n",
            "80727 tensor(0.9929, device='cuda:0')\n",
            "80735 tensor(0.9994, device='cuda:0')\n",
            "80737 tensor(0.9971, device='cuda:0')\n",
            "80739 tensor(0.9990, device='cuda:0')\n",
            "80756 tensor(0.9927, device='cuda:0')\n",
            "80758 tensor(0.9935, device='cuda:0')\n",
            "80765 tensor(0.9953, device='cuda:0')\n",
            "80769 tensor(0.9998, device='cuda:0')\n",
            "80779 tensor(0.9928, device='cuda:0')\n",
            "80780 tensor(0.9977, device='cuda:0')\n",
            "80787 tensor(0.9916, device='cuda:0')\n",
            "80789 tensor(0.9954, device='cuda:0')\n",
            "80790 tensor(0.9959, device='cuda:0')\n",
            "80807 tensor(0.9964, device='cuda:0')\n",
            "80808 tensor(0.9925, device='cuda:0')\n",
            "80815 tensor(0.9981, device='cuda:0')\n",
            "80816 tensor(0.9993, device='cuda:0')\n",
            "80819 tensor(0.9975, device='cuda:0')\n",
            "80826 tensor(0.9992, device='cuda:0')\n",
            "80828 tensor(0.9925, device='cuda:0')\n",
            "80834 tensor(0.9979, device='cuda:0')\n",
            "80836 tensor(0.9919, device='cuda:0')\n",
            "80837 tensor(0.9963, device='cuda:0')\n",
            "80839 tensor(0.9991, device='cuda:0')\n",
            "80844 tensor(0.9923, device='cuda:0')\n",
            "80848 tensor(0.9953, device='cuda:0')\n",
            "80849 tensor(0.9961, device='cuda:0')\n",
            "80853 tensor(0.9994, device='cuda:0')\n",
            "80856 tensor(0.9988, device='cuda:0')\n",
            "80867 tensor(0.9907, device='cuda:0')\n",
            "80874 tensor(0.9930, device='cuda:0')\n",
            "80884 tensor(0.9976, device='cuda:0')\n",
            "80885 tensor(0.9992, device='cuda:0')\n",
            "80886 tensor(0.9967, device='cuda:0')\n",
            "80890 tensor(0.9944, device='cuda:0')\n",
            "80894 tensor(0.9913, device='cuda:0')\n",
            "80901 tensor(0.9930, device='cuda:0')\n",
            "80913 tensor(0.9906, device='cuda:0')\n",
            "80915 tensor(0.9931, device='cuda:0')\n",
            "80917 tensor(0.9970, device='cuda:0')\n",
            "80931 tensor(0.9996, device='cuda:0')\n",
            "80939 tensor(0.9993, device='cuda:0')\n",
            "80942 tensor(0.9995, device='cuda:0')\n",
            "80945 tensor(0.9992, device='cuda:0')\n",
            "80946 tensor(0.9945, device='cuda:0')\n",
            "80975 tensor(0.9999, device='cuda:0')\n",
            "80978 tensor(0.9934, device='cuda:0')\n",
            "80986 tensor(0.9995, device='cuda:0')\n",
            "80992 tensor(0.9955, device='cuda:0')\n",
            "80995 tensor(0.9949, device='cuda:0')\n",
            "80996 tensor(0.9919, device='cuda:0')\n",
            "81000 tensor(0.9917, device='cuda:0')\n",
            "81012 tensor(0.9958, device='cuda:0')\n",
            "81016 tensor(0.9962, device='cuda:0')\n",
            "81017 tensor(0.9964, device='cuda:0')\n",
            "81031 tensor(0.9992, device='cuda:0')\n",
            "81037 tensor(0.9987, device='cuda:0')\n",
            "81041 tensor(0.9997, device='cuda:0')\n",
            "81056 tensor(0.9973, device='cuda:0')\n",
            "81059 tensor(0.9944, device='cuda:0')\n",
            "81062 tensor(0.9907, device='cuda:0')\n",
            "81065 tensor(0.9996, device='cuda:0')\n",
            "81066 tensor(0.9967, device='cuda:0')\n",
            "81067 tensor(0.9993, device='cuda:0')\n",
            "81071 tensor(0.9998, device='cuda:0')\n",
            "81076 tensor(0.9963, device='cuda:0')\n",
            "81081 tensor(0.9989, device='cuda:0')\n",
            "81095 tensor(0.9911, device='cuda:0')\n",
            "81096 tensor(0.9969, device='cuda:0')\n",
            "81100 tensor(0.9940, device='cuda:0')\n",
            "81105 tensor(0.9997, device='cuda:0')\n",
            "81114 tensor(0.9998, device='cuda:0')\n",
            "81121 tensor(0.9995, device='cuda:0')\n",
            "81123 tensor(0.9930, device='cuda:0')\n",
            "81127 tensor(0.9973, device='cuda:0')\n",
            "81131 tensor(0.9952, device='cuda:0')\n",
            "81137 tensor(0.9950, device='cuda:0')\n",
            "81139 tensor(0.9989, device='cuda:0')\n",
            "81140 tensor(0.9959, device='cuda:0')\n",
            "81152 tensor(0.9981, device='cuda:0')\n",
            "81155 tensor(0.9998, device='cuda:0')\n",
            "81161 tensor(0.9998, device='cuda:0')\n",
            "81164 tensor(0.9991, device='cuda:0')\n",
            "81171 tensor(0.9955, device='cuda:0')\n",
            "81179 tensor(0.9949, device='cuda:0')\n",
            "81181 tensor(0.9945, device='cuda:0')\n",
            "81191 tensor(0.9974, device='cuda:0')\n",
            "81193 tensor(0.9993, device='cuda:0')\n",
            "81196 tensor(0.9956, device='cuda:0')\n",
            "81201 tensor(0.9933, device='cuda:0')\n",
            "81210 tensor(0.9991, device='cuda:0')\n",
            "81215 tensor(0.9931, device='cuda:0')\n",
            "81228 tensor(0.9996, device='cuda:0')\n",
            "81247 tensor(0.9949, device='cuda:0')\n",
            "81250 tensor(0.9990, device='cuda:0')\n",
            "81267 tensor(0.9960, device='cuda:0')\n",
            "81273 tensor(0.9982, device='cuda:0')\n",
            "81281 tensor(0.9913, device='cuda:0')\n",
            "81284 tensor(0.9943, device='cuda:0')\n",
            "81285 tensor(0.9989, device='cuda:0')\n",
            "81288 tensor(0.9913, device='cuda:0')\n",
            "81290 tensor(0.9998, device='cuda:0')\n",
            "81292 tensor(0.9997, device='cuda:0')\n",
            "81295 tensor(0.9987, device='cuda:0')\n",
            "81296 tensor(0.9929, device='cuda:0')\n",
            "81298 tensor(0.9915, device='cuda:0')\n",
            "81303 tensor(0.9955, device='cuda:0')\n",
            "81307 tensor(0.9995, device='cuda:0')\n",
            "81316 tensor(0.9993, device='cuda:0')\n",
            "81317 tensor(0.9961, device='cuda:0')\n",
            "81321 tensor(0.9900, device='cuda:0')\n",
            "81326 tensor(0.9973, device='cuda:0')\n",
            "81336 tensor(0.9923, device='cuda:0')\n",
            "81342 tensor(0.9990, device='cuda:0')\n",
            "81346 tensor(0.9979, device='cuda:0')\n",
            "81353 tensor(0.9979, device='cuda:0')\n",
            "81356 tensor(0.9998, device='cuda:0')\n",
            "81357 tensor(0.9969, device='cuda:0')\n",
            "81359 tensor(0.9907, device='cuda:0')\n",
            "81366 tensor(0.9998, device='cuda:0')\n",
            "81370 tensor(0.9956, device='cuda:0')\n",
            "81374 tensor(0.9995, device='cuda:0')\n",
            "81376 tensor(0.9982, device='cuda:0')\n",
            "81381 tensor(0.9947, device='cuda:0')\n",
            "81393 tensor(0.9989, device='cuda:0')\n",
            "81399 tensor(0.9995, device='cuda:0')\n",
            "81408 tensor(0.9973, device='cuda:0')\n",
            "81409 tensor(0.9958, device='cuda:0')\n",
            "81412 tensor(0.9970, device='cuda:0')\n",
            "81417 tensor(0.9994, device='cuda:0')\n",
            "81422 tensor(0.9959, device='cuda:0')\n",
            "81424 tensor(0.9983, device='cuda:0')\n",
            "81427 tensor(0.9994, device='cuda:0')\n",
            "81431 tensor(0.9967, device='cuda:0')\n",
            "81435 tensor(0.9905, device='cuda:0')\n",
            "81450 tensor(0.9953, device='cuda:0')\n",
            "81453 tensor(0.9917, device='cuda:0')\n",
            "81457 tensor(0.9999, device='cuda:0')\n",
            "81458 tensor(0.9953, device='cuda:0')\n",
            "81467 tensor(0.9967, device='cuda:0')\n",
            "81473 tensor(0.9951, device='cuda:0')\n",
            "81477 tensor(0.9942, device='cuda:0')\n",
            "81479 tensor(0.9988, device='cuda:0')\n",
            "81483 tensor(0.9994, device='cuda:0')\n",
            "81489 tensor(0.9931, device='cuda:0')\n",
            "81490 tensor(0.9983, device='cuda:0')\n",
            "81492 tensor(0.9972, device='cuda:0')\n",
            "81495 tensor(0.9964, device='cuda:0')\n",
            "81500 tensor(0.9972, device='cuda:0')\n",
            "81524 tensor(0.9974, device='cuda:0')\n",
            "81528 tensor(0.9923, device='cuda:0')\n",
            "81532 tensor(0.9924, device='cuda:0')\n",
            "81534 tensor(0.9938, device='cuda:0')\n",
            "81541 tensor(0.9914, device='cuda:0')\n",
            "81542 tensor(0.9999, device='cuda:0')\n",
            "81553 tensor(0.9999, device='cuda:0')\n",
            "81559 tensor(0.9990, device='cuda:0')\n",
            "81561 tensor(0.9921, device='cuda:0')\n",
            "81564 tensor(0.9953, device='cuda:0')\n",
            "81571 tensor(0.9955, device='cuda:0')\n",
            "81573 tensor(0.9984, device='cuda:0')\n",
            "81574 tensor(0.9975, device='cuda:0')\n",
            "81578 tensor(0.9994, device='cuda:0')\n",
            "81580 tensor(0.9986, device='cuda:0')\n",
            "81585 tensor(0.9985, device='cuda:0')\n",
            "81590 tensor(0.9970, device='cuda:0')\n",
            "81592 tensor(0.9983, device='cuda:0')\n",
            "81599 tensor(0.9937, device='cuda:0')\n",
            "81637 tensor(0.9948, device='cuda:0')\n",
            "81638 tensor(0.9991, device='cuda:0')\n",
            "81643 tensor(0.9978, device='cuda:0')\n",
            "81652 tensor(0.9973, device='cuda:0')\n",
            "81655 tensor(0.9976, device='cuda:0')\n",
            "81660 tensor(0.9973, device='cuda:0')\n",
            "81661 tensor(0.9971, device='cuda:0')\n",
            "81665 tensor(0.9946, device='cuda:0')\n",
            "81667 tensor(0.9998, device='cuda:0')\n",
            "81679 tensor(0.9997, device='cuda:0')\n",
            "81681 tensor(0.9989, device='cuda:0')\n",
            "81687 tensor(0.9974, device='cuda:0')\n",
            "81694 tensor(0.9979, device='cuda:0')\n",
            "81697 tensor(0.9923, device='cuda:0')\n",
            "81698 tensor(0.9929, device='cuda:0')\n",
            "81699 tensor(0.9910, device='cuda:0')\n",
            "81704 tensor(0.9945, device='cuda:0')\n",
            "81706 tensor(0.9946, device='cuda:0')\n",
            "81713 tensor(0.9952, device='cuda:0')\n",
            "81715 tensor(0.9994, device='cuda:0')\n",
            "81726 tensor(0.9908, device='cuda:0')\n",
            "81730 tensor(0.9996, device='cuda:0')\n",
            "81732 tensor(0.9987, device='cuda:0')\n",
            "81738 tensor(0.9984, device='cuda:0')\n",
            "81739 tensor(0.9968, device='cuda:0')\n",
            "81763 tensor(0.9939, device='cuda:0')\n",
            "81765 tensor(0.9900, device='cuda:0')\n",
            "81778 tensor(0.9984, device='cuda:0')\n",
            "81780 tensor(0.9983, device='cuda:0')\n",
            "81783 tensor(0.9993, device='cuda:0')\n",
            "81784 tensor(0.9927, device='cuda:0')\n",
            "81790 tensor(0.9977, device='cuda:0')\n",
            "81791 tensor(0.9979, device='cuda:0')\n",
            "81796 tensor(0.9976, device='cuda:0')\n",
            "81798 tensor(0.9970, device='cuda:0')\n",
            "81803 tensor(0.9990, device='cuda:0')\n",
            "81807 tensor(0.9960, device='cuda:0')\n",
            "81810 tensor(0.9920, device='cuda:0')\n",
            "81820 tensor(0.9942, device='cuda:0')\n",
            "81824 tensor(0.9985, device='cuda:0')\n",
            "81840 tensor(0.9988, device='cuda:0')\n",
            "81847 tensor(0.9957, device='cuda:0')\n",
            "81852 tensor(0.9977, device='cuda:0')\n",
            "81870 tensor(0.9980, device='cuda:0')\n",
            "81871 tensor(0.9972, device='cuda:0')\n",
            "81888 tensor(0.9961, device='cuda:0')\n",
            "81891 tensor(0.9981, device='cuda:0')\n",
            "81892 tensor(0.9994, device='cuda:0')\n",
            "81895 tensor(0.9910, device='cuda:0')\n",
            "81900 tensor(0.9992, device='cuda:0')\n",
            "81901 tensor(0.9936, device='cuda:0')\n",
            "81904 tensor(0.9958, device='cuda:0')\n",
            "81905 tensor(0.9999, device='cuda:0')\n",
            "81906 tensor(0.9951, device='cuda:0')\n",
            "81908 tensor(0.9990, device='cuda:0')\n",
            "81915 tensor(0.9973, device='cuda:0')\n",
            "81927 tensor(0.9955, device='cuda:0')\n",
            "81931 tensor(0.9960, device='cuda:0')\n",
            "81932 tensor(0.9917, device='cuda:0')\n",
            "81935 tensor(0.9999, device='cuda:0')\n",
            "81937 tensor(0.9982, device='cuda:0')\n",
            "81940 tensor(0.9959, device='cuda:0')\n",
            "81941 tensor(0.9911, device='cuda:0')\n",
            "81949 tensor(0.9986, device='cuda:0')\n",
            "81952 tensor(0.9933, device='cuda:0')\n",
            "81954 tensor(0.9973, device='cuda:0')\n",
            "81955 tensor(0.9955, device='cuda:0')\n",
            "81965 tensor(0.9979, device='cuda:0')\n",
            "81966 tensor(0.9994, device='cuda:0')\n",
            "81968 tensor(0.9994, device='cuda:0')\n",
            "81973 tensor(0.9949, device='cuda:0')\n",
            "81978 tensor(0.9925, device='cuda:0')\n",
            "81980 tensor(0.9938, device='cuda:0')\n",
            "81981 tensor(0.9995, device='cuda:0')\n",
            "81983 tensor(0.9999, device='cuda:0')\n",
            "81986 tensor(0.9997, device='cuda:0')\n",
            "81989 tensor(0.9968, device='cuda:0')\n",
            "82010 tensor(0.9987, device='cuda:0')\n",
            "82016 tensor(0.9950, device='cuda:0')\n",
            "82017 tensor(0.9998, device='cuda:0')\n",
            "82018 tensor(0.9998, device='cuda:0')\n",
            "82030 tensor(0.9973, device='cuda:0')\n",
            "82033 tensor(0.9978, device='cuda:0')\n",
            "82042 tensor(0.9969, device='cuda:0')\n",
            "82044 tensor(0.9966, device='cuda:0')\n",
            "82045 tensor(0.9986, device='cuda:0')\n",
            "82052 tensor(0.9982, device='cuda:0')\n",
            "82055 tensor(0.9915, device='cuda:0')\n",
            "82070 tensor(0.9936, device='cuda:0')\n",
            "82079 tensor(0.9995, device='cuda:0')\n",
            "82084 tensor(0.9915, device='cuda:0')\n",
            "82091 tensor(0.9937, device='cuda:0')\n",
            "82092 tensor(0.9909, device='cuda:0')\n",
            "82103 tensor(0.9900, device='cuda:0')\n",
            "82105 tensor(0.9960, device='cuda:0')\n",
            "82108 tensor(0.9977, device='cuda:0')\n",
            "82136 tensor(0.9943, device='cuda:0')\n",
            "82146 tensor(0.9907, device='cuda:0')\n",
            "82147 tensor(0.9929, device='cuda:0')\n",
            "82154 tensor(0.9998, device='cuda:0')\n",
            "82158 tensor(0.9951, device='cuda:0')\n",
            "82160 tensor(0.9988, device='cuda:0')\n",
            "82163 tensor(0.9907, device='cuda:0')\n",
            "82168 tensor(0.9979, device='cuda:0')\n",
            "82169 tensor(0.9939, device='cuda:0')\n",
            "82170 tensor(0.9995, device='cuda:0')\n",
            "82171 tensor(0.9968, device='cuda:0')\n",
            "82178 tensor(0.9984, device='cuda:0')\n",
            "82181 tensor(0.9934, device='cuda:0')\n",
            "82192 tensor(0.9952, device='cuda:0')\n",
            "82195 tensor(0.9932, device='cuda:0')\n",
            "82202 tensor(0.9949, device='cuda:0')\n",
            "82207 tensor(1.0000, device='cuda:0')\n",
            "82210 tensor(0.9927, device='cuda:0')\n",
            "82219 tensor(0.9990, device='cuda:0')\n",
            "82220 tensor(0.9986, device='cuda:0')\n",
            "82223 tensor(0.9936, device='cuda:0')\n",
            "82224 tensor(0.9981, device='cuda:0')\n",
            "82230 tensor(0.9999, device='cuda:0')\n",
            "82242 tensor(0.9946, device='cuda:0')\n",
            "82250 tensor(0.9996, device='cuda:0')\n",
            "82251 tensor(0.9998, device='cuda:0')\n",
            "82264 tensor(0.9966, device='cuda:0')\n",
            "82268 tensor(0.9955, device='cuda:0')\n",
            "82270 tensor(0.9957, device='cuda:0')\n",
            "82276 tensor(0.9962, device='cuda:0')\n",
            "82277 tensor(0.9986, device='cuda:0')\n",
            "82283 tensor(0.9997, device='cuda:0')\n",
            "82287 tensor(0.9904, device='cuda:0')\n",
            "82289 tensor(0.9961, device='cuda:0')\n",
            "82290 tensor(0.9960, device='cuda:0')\n",
            "82295 tensor(0.9968, device='cuda:0')\n",
            "82302 tensor(0.9921, device='cuda:0')\n",
            "82311 tensor(0.9911, device='cuda:0')\n",
            "82319 tensor(0.9912, device='cuda:0')\n",
            "82326 tensor(0.9997, device='cuda:0')\n",
            "82327 tensor(0.9935, device='cuda:0')\n",
            "82333 tensor(0.9993, device='cuda:0')\n",
            "82338 tensor(0.9984, device='cuda:0')\n",
            "82343 tensor(0.9995, device='cuda:0')\n",
            "82347 tensor(0.9901, device='cuda:0')\n",
            "82353 tensor(0.9967, device='cuda:0')\n",
            "82357 tensor(0.9974, device='cuda:0')\n",
            "82364 tensor(0.9944, device='cuda:0')\n",
            "82365 tensor(0.9999, device='cuda:0')\n",
            "82374 tensor(0.9946, device='cuda:0')\n",
            "82375 tensor(0.9982, device='cuda:0')\n",
            "82376 tensor(0.9915, device='cuda:0')\n",
            "82378 tensor(0.9997, device='cuda:0')\n",
            "82380 tensor(0.9999, device='cuda:0')\n",
            "82388 tensor(0.9982, device='cuda:0')\n",
            "82394 tensor(0.9913, device='cuda:0')\n",
            "82395 tensor(0.9995, device='cuda:0')\n",
            "82400 tensor(0.9998, device='cuda:0')\n",
            "82405 tensor(0.9983, device='cuda:0')\n",
            "82414 tensor(0.9962, device='cuda:0')\n",
            "82429 tensor(0.9999, device='cuda:0')\n",
            "82433 tensor(0.9905, device='cuda:0')\n",
            "82437 tensor(0.9937, device='cuda:0')\n",
            "82439 tensor(0.9926, device='cuda:0')\n",
            "82444 tensor(0.9982, device='cuda:0')\n",
            "82447 tensor(0.9995, device='cuda:0')\n",
            "82454 tensor(0.9971, device='cuda:0')\n",
            "82461 tensor(0.9939, device='cuda:0')\n",
            "82464 tensor(0.9968, device='cuda:0')\n",
            "82474 tensor(0.9956, device='cuda:0')\n",
            "82475 tensor(0.9987, device='cuda:0')\n",
            "82477 tensor(0.9994, device='cuda:0')\n",
            "82480 tensor(0.9995, device='cuda:0')\n",
            "82485 tensor(0.9991, device='cuda:0')\n",
            "82496 tensor(0.9932, device='cuda:0')\n",
            "82499 tensor(0.9978, device='cuda:0')\n",
            "82500 tensor(0.9941, device='cuda:0')\n",
            "82503 tensor(0.9957, device='cuda:0')\n",
            "82504 tensor(0.9925, device='cuda:0')\n",
            "82508 tensor(0.9923, device='cuda:0')\n",
            "82517 tensor(0.9946, device='cuda:0')\n",
            "82520 tensor(0.9974, device='cuda:0')\n",
            "82522 tensor(0.9954, device='cuda:0')\n",
            "82526 tensor(0.9954, device='cuda:0')\n",
            "82527 tensor(0.9984, device='cuda:0')\n",
            "82535 tensor(0.9946, device='cuda:0')\n",
            "82540 tensor(0.9953, device='cuda:0')\n",
            "82546 tensor(0.9979, device='cuda:0')\n",
            "82553 tensor(0.9956, device='cuda:0')\n",
            "82568 tensor(0.9945, device='cuda:0')\n",
            "82571 tensor(0.9914, device='cuda:0')\n",
            "82573 tensor(0.9999, device='cuda:0')\n",
            "82578 tensor(0.9972, device='cuda:0')\n",
            "82586 tensor(0.9931, device='cuda:0')\n",
            "82600 tensor(0.9984, device='cuda:0')\n",
            "82601 tensor(0.9983, device='cuda:0')\n",
            "82604 tensor(0.9998, device='cuda:0')\n",
            "82612 tensor(0.9973, device='cuda:0')\n",
            "82623 tensor(0.9989, device='cuda:0')\n",
            "82624 tensor(0.9986, device='cuda:0')\n",
            "82626 tensor(0.9998, device='cuda:0')\n",
            "82628 tensor(0.9937, device='cuda:0')\n",
            "82635 tensor(0.9969, device='cuda:0')\n",
            "82638 tensor(0.9951, device='cuda:0')\n",
            "82639 tensor(0.9913, device='cuda:0')\n",
            "82640 tensor(0.9940, device='cuda:0')\n",
            "82647 tensor(0.9907, device='cuda:0')\n",
            "82648 tensor(0.9913, device='cuda:0')\n",
            "82654 tensor(0.9978, device='cuda:0')\n",
            "82660 tensor(0.9994, device='cuda:0')\n",
            "82666 tensor(0.9985, device='cuda:0')\n",
            "82668 tensor(0.9995, device='cuda:0')\n",
            "82671 tensor(0.9924, device='cuda:0')\n",
            "82674 tensor(0.9960, device='cuda:0')\n",
            "82693 tensor(0.9902, device='cuda:0')\n",
            "82697 tensor(0.9997, device='cuda:0')\n",
            "82698 tensor(0.9946, device='cuda:0')\n",
            "82703 tensor(0.9986, device='cuda:0')\n",
            "82721 tensor(0.9979, device='cuda:0')\n",
            "82724 tensor(0.9996, device='cuda:0')\n",
            "82725 tensor(0.9920, device='cuda:0')\n",
            "82731 tensor(0.9986, device='cuda:0')\n",
            "82737 tensor(0.9917, device='cuda:0')\n",
            "82740 tensor(0.9986, device='cuda:0')\n",
            "82751 tensor(0.9984, device='cuda:0')\n",
            "82754 tensor(0.9961, device='cuda:0')\n",
            "82759 tensor(0.9973, device='cuda:0')\n",
            "82763 tensor(0.9996, device='cuda:0')\n",
            "82770 tensor(0.9989, device='cuda:0')\n",
            "82771 tensor(0.9915, device='cuda:0')\n",
            "82773 tensor(0.9968, device='cuda:0')\n",
            "82779 tensor(0.9994, device='cuda:0')\n",
            "82783 tensor(0.9959, device='cuda:0')\n",
            "82784 tensor(0.9913, device='cuda:0')\n",
            "82790 tensor(0.9981, device='cuda:0')\n",
            "82794 tensor(0.9968, device='cuda:0')\n",
            "82798 tensor(0.9968, device='cuda:0')\n",
            "82801 tensor(0.9972, device='cuda:0')\n",
            "82804 tensor(0.9989, device='cuda:0')\n",
            "82821 tensor(0.9997, device='cuda:0')\n",
            "82827 tensor(0.9986, device='cuda:0')\n",
            "82835 tensor(0.9997, device='cuda:0')\n",
            "82838 tensor(0.9933, device='cuda:0')\n",
            "82839 tensor(0.9998, device='cuda:0')\n",
            "82840 tensor(0.9970, device='cuda:0')\n",
            "82846 tensor(0.9990, device='cuda:0')\n",
            "82859 tensor(0.9975, device='cuda:0')\n",
            "82868 tensor(0.9963, device='cuda:0')\n",
            "82872 tensor(0.9996, device='cuda:0')\n",
            "82875 tensor(0.9985, device='cuda:0')\n",
            "82878 tensor(0.9916, device='cuda:0')\n",
            "82890 tensor(0.9981, device='cuda:0')\n",
            "82892 tensor(0.9935, device='cuda:0')\n",
            "82895 tensor(0.9999, device='cuda:0')\n",
            "82899 tensor(0.9953, device='cuda:0')\n",
            "82925 tensor(0.9978, device='cuda:0')\n",
            "82927 tensor(0.9982, device='cuda:0')\n",
            "82931 tensor(0.9985, device='cuda:0')\n",
            "82932 tensor(0.9983, device='cuda:0')\n",
            "82933 tensor(0.9996, device='cuda:0')\n",
            "82935 tensor(0.9993, device='cuda:0')\n",
            "82936 tensor(0.9941, device='cuda:0')\n",
            "82938 tensor(0.9978, device='cuda:0')\n",
            "82944 tensor(0.9914, device='cuda:0')\n",
            "82948 tensor(0.9975, device='cuda:0')\n",
            "82949 tensor(0.9912, device='cuda:0')\n",
            "82953 tensor(0.9966, device='cuda:0')\n",
            "82956 tensor(0.9993, device='cuda:0')\n",
            "82973 tensor(0.9925, device='cuda:0')\n",
            "82975 tensor(0.9984, device='cuda:0')\n",
            "82981 tensor(0.9998, device='cuda:0')\n",
            "82986 tensor(0.9945, device='cuda:0')\n",
            "82988 tensor(0.9999, device='cuda:0')\n",
            "82991 tensor(0.9932, device='cuda:0')\n",
            "82998 tensor(0.9999, device='cuda:0')\n",
            "82999 tensor(0.9978, device='cuda:0')\n",
            "83007 tensor(0.9994, device='cuda:0')\n",
            "83010 tensor(0.9999, device='cuda:0')\n",
            "83012 tensor(0.9920, device='cuda:0')\n",
            "83038 tensor(0.9984, device='cuda:0')\n",
            "83043 tensor(0.9924, device='cuda:0')\n",
            "83045 tensor(0.9974, device='cuda:0')\n",
            "83073 tensor(0.9921, device='cuda:0')\n",
            "83080 tensor(0.9920, device='cuda:0')\n",
            "83083 tensor(0.9965, device='cuda:0')\n",
            "83090 tensor(0.9937, device='cuda:0')\n",
            "83104 tensor(0.9919, device='cuda:0')\n",
            "83111 tensor(0.9997, device='cuda:0')\n",
            "83114 tensor(0.9980, device='cuda:0')\n",
            "83116 tensor(0.9980, device='cuda:0')\n",
            "83117 tensor(0.9931, device='cuda:0')\n",
            "83118 tensor(0.9954, device='cuda:0')\n",
            "83131 tensor(0.9987, device='cuda:0')\n",
            "83134 tensor(0.9996, device='cuda:0')\n",
            "83148 tensor(0.9992, device='cuda:0')\n",
            "83154 tensor(0.9953, device='cuda:0')\n",
            "83157 tensor(0.9943, device='cuda:0')\n",
            "83159 tensor(0.9906, device='cuda:0')\n",
            "83161 tensor(0.9982, device='cuda:0')\n",
            "83179 tensor(0.9988, device='cuda:0')\n",
            "83183 tensor(0.9961, device='cuda:0')\n",
            "83186 tensor(0.9961, device='cuda:0')\n",
            "83190 tensor(0.9963, device='cuda:0')\n",
            "83193 tensor(0.9934, device='cuda:0')\n",
            "83194 tensor(0.9999, device='cuda:0')\n",
            "83199 tensor(0.9915, device='cuda:0')\n",
            "83200 tensor(0.9994, device='cuda:0')\n",
            "83203 tensor(0.9903, device='cuda:0')\n",
            "83204 tensor(0.9988, device='cuda:0')\n",
            "83205 tensor(0.9994, device='cuda:0')\n",
            "83206 tensor(0.9957, device='cuda:0')\n",
            "83207 tensor(0.9996, device='cuda:0')\n",
            "83209 tensor(0.9901, device='cuda:0')\n",
            "83212 tensor(0.9998, device='cuda:0')\n",
            "83217 tensor(0.9963, device='cuda:0')\n",
            "83219 tensor(0.9919, device='cuda:0')\n",
            "83221 tensor(0.9915, device='cuda:0')\n",
            "83224 tensor(0.9995, device='cuda:0')\n",
            "83237 tensor(0.9995, device='cuda:0')\n",
            "83243 tensor(0.9916, device='cuda:0')\n",
            "83244 tensor(0.9983, device='cuda:0')\n",
            "83250 tensor(0.9926, device='cuda:0')\n",
            "83251 tensor(0.9980, device='cuda:0')\n",
            "83254 tensor(0.9923, device='cuda:0')\n",
            "83256 tensor(0.9944, device='cuda:0')\n",
            "83258 tensor(0.9992, device='cuda:0')\n",
            "83263 tensor(0.9991, device='cuda:0')\n",
            "83264 tensor(0.9995, device='cuda:0')\n",
            "83265 tensor(0.9959, device='cuda:0')\n",
            "83267 tensor(0.9989, device='cuda:0')\n",
            "83281 tensor(0.9998, device='cuda:0')\n",
            "83285 tensor(0.9963, device='cuda:0')\n",
            "83291 tensor(0.9986, device='cuda:0')\n",
            "83293 tensor(0.9948, device='cuda:0')\n",
            "83299 tensor(0.9920, device='cuda:0')\n",
            "83305 tensor(0.9933, device='cuda:0')\n",
            "83306 tensor(0.9970, device='cuda:0')\n",
            "83311 tensor(0.9989, device='cuda:0')\n",
            "83317 tensor(0.9996, device='cuda:0')\n",
            "83321 tensor(0.9973, device='cuda:0')\n",
            "83323 tensor(0.9990, device='cuda:0')\n",
            "83333 tensor(0.9998, device='cuda:0')\n",
            "83354 tensor(0.9990, device='cuda:0')\n",
            "83359 tensor(0.9910, device='cuda:0')\n",
            "83360 tensor(0.9979, device='cuda:0')\n",
            "83366 tensor(0.9996, device='cuda:0')\n",
            "83367 tensor(0.9979, device='cuda:0')\n",
            "83369 tensor(0.9916, device='cuda:0')\n",
            "83377 tensor(0.9997, device='cuda:0')\n",
            "83378 tensor(0.9948, device='cuda:0')\n",
            "83380 tensor(0.9961, device='cuda:0')\n",
            "83384 tensor(0.9944, device='cuda:0')\n",
            "83385 tensor(0.9965, device='cuda:0')\n",
            "83390 tensor(0.9974, device='cuda:0')\n",
            "83392 tensor(0.9950, device='cuda:0')\n",
            "83398 tensor(0.9940, device='cuda:0')\n",
            "83399 tensor(0.9946, device='cuda:0')\n",
            "83402 tensor(0.9999, device='cuda:0')\n",
            "83405 tensor(0.9968, device='cuda:0')\n",
            "83410 tensor(0.9990, device='cuda:0')\n",
            "83418 tensor(0.9997, device='cuda:0')\n",
            "83419 tensor(0.9999, device='cuda:0')\n",
            "83421 tensor(0.9935, device='cuda:0')\n",
            "83422 tensor(0.9990, device='cuda:0')\n",
            "83429 tensor(0.9995, device='cuda:0')\n",
            "83431 tensor(0.9993, device='cuda:0')\n",
            "83435 tensor(0.9972, device='cuda:0')\n",
            "83438 tensor(0.9984, device='cuda:0')\n",
            "83449 tensor(0.9986, device='cuda:0')\n",
            "83454 tensor(0.9957, device='cuda:0')\n",
            "83455 tensor(0.9978, device='cuda:0')\n",
            "83456 tensor(0.9995, device='cuda:0')\n",
            "83464 tensor(0.9993, device='cuda:0')\n",
            "83470 tensor(0.9993, device='cuda:0')\n",
            "83471 tensor(0.9994, device='cuda:0')\n",
            "83472 tensor(0.9992, device='cuda:0')\n",
            "83475 tensor(0.9985, device='cuda:0')\n",
            "83478 tensor(0.9983, device='cuda:0')\n",
            "83484 tensor(0.9995, device='cuda:0')\n",
            "83486 tensor(0.9946, device='cuda:0')\n",
            "83493 tensor(0.9916, device='cuda:0')\n",
            "83504 tensor(0.9914, device='cuda:0')\n",
            "83505 tensor(0.9942, device='cuda:0')\n",
            "83518 tensor(0.9946, device='cuda:0')\n",
            "83522 tensor(0.9919, device='cuda:0')\n",
            "83527 tensor(0.9996, device='cuda:0')\n",
            "83529 tensor(0.9996, device='cuda:0')\n",
            "83539 tensor(0.9958, device='cuda:0')\n",
            "83545 tensor(0.9962, device='cuda:0')\n",
            "83550 tensor(0.9991, device='cuda:0')\n",
            "83558 tensor(0.9992, device='cuda:0')\n",
            "83576 tensor(0.9903, device='cuda:0')\n",
            "83590 tensor(0.9997, device='cuda:0')\n",
            "83592 tensor(0.9955, device='cuda:0')\n",
            "83594 tensor(0.9998, device='cuda:0')\n",
            "83596 tensor(0.9929, device='cuda:0')\n",
            "83598 tensor(0.9972, device='cuda:0')\n",
            "83600 tensor(0.9923, device='cuda:0')\n",
            "83603 tensor(0.9998, device='cuda:0')\n",
            "83605 tensor(0.9995, device='cuda:0')\n",
            "83606 tensor(0.9994, device='cuda:0')\n",
            "83616 tensor(0.9910, device='cuda:0')\n",
            "83625 tensor(0.9901, device='cuda:0')\n",
            "83626 tensor(0.9936, device='cuda:0')\n",
            "83627 tensor(0.9985, device='cuda:0')\n",
            "83632 tensor(0.9984, device='cuda:0')\n",
            "83638 tensor(0.9950, device='cuda:0')\n",
            "83641 tensor(0.9994, device='cuda:0')\n",
            "83642 tensor(0.9947, device='cuda:0')\n",
            "83648 tensor(0.9982, device='cuda:0')\n",
            "83652 tensor(0.9997, device='cuda:0')\n",
            "83655 tensor(0.9989, device='cuda:0')\n",
            "83659 tensor(0.9998, device='cuda:0')\n",
            "83676 tensor(0.9935, device='cuda:0')\n",
            "83677 tensor(0.9984, device='cuda:0')\n",
            "83678 tensor(0.9993, device='cuda:0')\n",
            "83680 tensor(0.9951, device='cuda:0')\n",
            "83682 tensor(0.9935, device='cuda:0')\n",
            "83688 tensor(0.9991, device='cuda:0')\n",
            "83697 tensor(0.9998, device='cuda:0')\n",
            "83701 tensor(0.9994, device='cuda:0')\n",
            "83706 tensor(0.9991, device='cuda:0')\n",
            "83710 tensor(0.9906, device='cuda:0')\n",
            "83731 tensor(0.9982, device='cuda:0')\n",
            "83734 tensor(0.9913, device='cuda:0')\n",
            "83735 tensor(0.9980, device='cuda:0')\n",
            "83752 tensor(0.9958, device='cuda:0')\n",
            "83762 tensor(0.9980, device='cuda:0')\n",
            "83763 tensor(0.9991, device='cuda:0')\n",
            "83767 tensor(0.9998, device='cuda:0')\n",
            "83773 tensor(0.9937, device='cuda:0')\n",
            "83781 tensor(0.9954, device='cuda:0')\n",
            "83788 tensor(0.9911, device='cuda:0')\n",
            "83789 tensor(0.9982, device='cuda:0')\n",
            "83803 tensor(0.9993, device='cuda:0')\n",
            "83811 tensor(0.9954, device='cuda:0')\n",
            "83813 tensor(0.9922, device='cuda:0')\n",
            "83816 tensor(0.9971, device='cuda:0')\n",
            "83821 tensor(0.9975, device='cuda:0')\n",
            "83822 tensor(0.9999, device='cuda:0')\n",
            "83828 tensor(0.9932, device='cuda:0')\n",
            "83833 tensor(0.9951, device='cuda:0')\n",
            "83835 tensor(0.9978, device='cuda:0')\n",
            "83838 tensor(0.9989, device='cuda:0')\n",
            "83843 tensor(0.9974, device='cuda:0')\n",
            "83849 tensor(0.9976, device='cuda:0')\n",
            "83861 tensor(0.9918, device='cuda:0')\n",
            "83870 tensor(0.9969, device='cuda:0')\n",
            "83872 tensor(0.9989, device='cuda:0')\n",
            "83873 tensor(0.9967, device='cuda:0')\n",
            "83880 tensor(0.9947, device='cuda:0')\n",
            "83884 tensor(0.9994, device='cuda:0')\n",
            "83888 tensor(0.9983, device='cuda:0')\n",
            "83889 tensor(0.9995, device='cuda:0')\n",
            "83893 tensor(0.9928, device='cuda:0')\n",
            "83894 tensor(0.9938, device='cuda:0')\n",
            "83901 tensor(0.9984, device='cuda:0')\n",
            "83908 tensor(0.9974, device='cuda:0')\n",
            "83937 tensor(0.9998, device='cuda:0')\n",
            "83951 tensor(0.9998, device='cuda:0')\n",
            "83953 tensor(0.9999, device='cuda:0')\n",
            "83968 tensor(0.9921, device='cuda:0')\n",
            "83969 tensor(0.9930, device='cuda:0')\n",
            "83974 tensor(0.9900, device='cuda:0')\n",
            "83975 tensor(0.9919, device='cuda:0')\n",
            "83983 tensor(0.9999, device='cuda:0')\n",
            "83990 tensor(0.9995, device='cuda:0')\n",
            "83993 tensor(0.9996, device='cuda:0')\n",
            "84001 tensor(0.9906, device='cuda:0')\n",
            "84004 tensor(0.9970, device='cuda:0')\n",
            "84008 tensor(0.9910, device='cuda:0')\n",
            "84009 tensor(0.9975, device='cuda:0')\n",
            "84021 tensor(0.9930, device='cuda:0')\n",
            "84026 tensor(0.9960, device='cuda:0')\n",
            "84036 tensor(0.9912, device='cuda:0')\n",
            "84041 tensor(0.9940, device='cuda:0')\n",
            "84065 tensor(0.9944, device='cuda:0')\n",
            "84067 tensor(0.9946, device='cuda:0')\n",
            "84078 tensor(0.9991, device='cuda:0')\n",
            "84092 tensor(0.9915, device='cuda:0')\n",
            "84095 tensor(0.9910, device='cuda:0')\n",
            "84098 tensor(0.9995, device='cuda:0')\n",
            "84107 tensor(0.9978, device='cuda:0')\n",
            "84108 tensor(0.9973, device='cuda:0')\n",
            "84109 tensor(0.9999, device='cuda:0')\n",
            "84120 tensor(0.9992, device='cuda:0')\n",
            "84123 tensor(0.9905, device='cuda:0')\n",
            "84132 tensor(0.9981, device='cuda:0')\n",
            "84134 tensor(0.9987, device='cuda:0')\n",
            "84137 tensor(0.9994, device='cuda:0')\n",
            "84142 tensor(0.9998, device='cuda:0')\n",
            "84162 tensor(0.9927, device='cuda:0')\n",
            "84167 tensor(0.9979, device='cuda:0')\n",
            "84177 tensor(0.9946, device='cuda:0')\n",
            "84185 tensor(0.9949, device='cuda:0')\n",
            "84186 tensor(0.9931, device='cuda:0')\n",
            "84187 tensor(0.9929, device='cuda:0')\n",
            "84191 tensor(0.9947, device='cuda:0')\n",
            "84192 tensor(0.9990, device='cuda:0')\n",
            "84196 tensor(0.9986, device='cuda:0')\n",
            "84203 tensor(0.9999, device='cuda:0')\n",
            "84208 tensor(0.9931, device='cuda:0')\n",
            "84217 tensor(0.9998, device='cuda:0')\n",
            "84231 tensor(0.9955, device='cuda:0')\n",
            "84232 tensor(0.9956, device='cuda:0')\n",
            "84236 tensor(0.9983, device='cuda:0')\n",
            "84239 tensor(0.9935, device='cuda:0')\n",
            "84252 tensor(0.9982, device='cuda:0')\n",
            "84253 tensor(0.9985, device='cuda:0')\n",
            "84255 tensor(0.9931, device='cuda:0')\n",
            "84256 tensor(0.9947, device='cuda:0')\n",
            "84257 tensor(0.9996, device='cuda:0')\n",
            "84258 tensor(0.9932, device='cuda:0')\n",
            "84261 tensor(0.9946, device='cuda:0')\n",
            "84262 tensor(0.9992, device='cuda:0')\n",
            "84266 tensor(0.9987, device='cuda:0')\n",
            "84274 tensor(0.9992, device='cuda:0')\n",
            "84278 tensor(0.9940, device='cuda:0')\n",
            "84280 tensor(0.9955, device='cuda:0')\n",
            "84281 tensor(0.9958, device='cuda:0')\n",
            "84288 tensor(0.9973, device='cuda:0')\n",
            "84289 tensor(0.9992, device='cuda:0')\n",
            "84292 tensor(0.9972, device='cuda:0')\n",
            "84293 tensor(0.9963, device='cuda:0')\n",
            "84300 tensor(0.9933, device='cuda:0')\n",
            "84304 tensor(0.9984, device='cuda:0')\n",
            "84311 tensor(0.9975, device='cuda:0')\n",
            "84315 tensor(0.9990, device='cuda:0')\n",
            "84319 tensor(0.9996, device='cuda:0')\n",
            "84320 tensor(0.9996, device='cuda:0')\n",
            "84322 tensor(0.9901, device='cuda:0')\n",
            "84326 tensor(0.9928, device='cuda:0')\n",
            "84332 tensor(0.9999, device='cuda:0')\n",
            "84342 tensor(0.9998, device='cuda:0')\n",
            "84346 tensor(0.9998, device='cuda:0')\n",
            "84349 tensor(0.9969, device='cuda:0')\n",
            "84356 tensor(0.9993, device='cuda:0')\n",
            "84359 tensor(0.9951, device='cuda:0')\n",
            "84364 tensor(0.9995, device='cuda:0')\n",
            "84374 tensor(0.9900, device='cuda:0')\n",
            "84377 tensor(0.9938, device='cuda:0')\n",
            "84380 tensor(0.9986, device='cuda:0')\n",
            "84385 tensor(0.9982, device='cuda:0')\n",
            "84386 tensor(1.0000, device='cuda:0')\n",
            "84388 tensor(0.9991, device='cuda:0')\n",
            "84390 tensor(0.9948, device='cuda:0')\n",
            "84392 tensor(0.9999, device='cuda:0')\n",
            "84396 tensor(0.9956, device='cuda:0')\n",
            "84399 tensor(0.9983, device='cuda:0')\n",
            "84404 tensor(0.9964, device='cuda:0')\n",
            "84406 tensor(0.9972, device='cuda:0')\n",
            "84415 tensor(0.9966, device='cuda:0')\n",
            "84420 tensor(0.9938, device='cuda:0')\n",
            "84429 tensor(0.9936, device='cuda:0')\n",
            "84430 tensor(0.9975, device='cuda:0')\n",
            "84437 tensor(0.9905, device='cuda:0')\n",
            "84440 tensor(0.9980, device='cuda:0')\n",
            "84444 tensor(0.9943, device='cuda:0')\n",
            "84445 tensor(0.9986, device='cuda:0')\n",
            "84451 tensor(0.9921, device='cuda:0')\n",
            "84455 tensor(0.9995, device='cuda:0')\n",
            "84456 tensor(0.9947, device='cuda:0')\n",
            "84461 tensor(0.9935, device='cuda:0')\n",
            "84464 tensor(0.9999, device='cuda:0')\n",
            "84467 tensor(0.9980, device='cuda:0')\n",
            "84468 tensor(0.9999, device='cuda:0')\n",
            "84470 tensor(0.9998, device='cuda:0')\n",
            "84472 tensor(0.9922, device='cuda:0')\n",
            "84478 tensor(0.9952, device='cuda:0')\n",
            "84479 tensor(0.9984, device='cuda:0')\n",
            "84496 tensor(0.9987, device='cuda:0')\n",
            "84504 tensor(0.9993, device='cuda:0')\n",
            "84513 tensor(0.9983, device='cuda:0')\n",
            "84514 tensor(0.9984, device='cuda:0')\n",
            "84516 tensor(0.9985, device='cuda:0')\n",
            "84518 tensor(0.9983, device='cuda:0')\n",
            "84522 tensor(0.9988, device='cuda:0')\n",
            "84532 tensor(0.9901, device='cuda:0')\n",
            "84534 tensor(0.9931, device='cuda:0')\n",
            "84538 tensor(0.9987, device='cuda:0')\n",
            "84539 tensor(0.9990, device='cuda:0')\n",
            "84540 tensor(0.9973, device='cuda:0')\n",
            "84543 tensor(0.9926, device='cuda:0')\n",
            "84544 tensor(0.9964, device='cuda:0')\n",
            "84551 tensor(0.9997, device='cuda:0')\n",
            "84566 tensor(0.9930, device='cuda:0')\n",
            "84570 tensor(0.9947, device='cuda:0')\n",
            "84571 tensor(0.9942, device='cuda:0')\n",
            "84588 tensor(0.9986, device='cuda:0')\n",
            "84590 tensor(0.9992, device='cuda:0')\n",
            "84592 tensor(0.9995, device='cuda:0')\n",
            "84593 tensor(0.9996, device='cuda:0')\n",
            "84595 tensor(0.9925, device='cuda:0')\n",
            "84601 tensor(0.9998, device='cuda:0')\n",
            "84603 tensor(0.9911, device='cuda:0')\n",
            "84610 tensor(0.9930, device='cuda:0')\n",
            "84618 tensor(0.9931, device='cuda:0')\n",
            "84630 tensor(0.9931, device='cuda:0')\n",
            "84632 tensor(0.9987, device='cuda:0')\n",
            "84633 tensor(0.9987, device='cuda:0')\n",
            "84636 tensor(0.9977, device='cuda:0')\n",
            "84643 tensor(0.9959, device='cuda:0')\n",
            "84647 tensor(0.9993, device='cuda:0')\n",
            "84650 tensor(0.9939, device='cuda:0')\n",
            "84655 tensor(0.9963, device='cuda:0')\n",
            "84656 tensor(0.9920, device='cuda:0')\n",
            "84659 tensor(0.9999, device='cuda:0')\n",
            "84663 tensor(0.9996, device='cuda:0')\n",
            "84664 tensor(0.9982, device='cuda:0')\n",
            "84669 tensor(0.9983, device='cuda:0')\n",
            "84672 tensor(0.9925, device='cuda:0')\n",
            "84680 tensor(0.9993, device='cuda:0')\n",
            "84681 tensor(0.9997, device='cuda:0')\n",
            "84685 tensor(0.9983, device='cuda:0')\n",
            "84690 tensor(0.9988, device='cuda:0')\n",
            "84701 tensor(0.9988, device='cuda:0')\n",
            "84710 tensor(0.9923, device='cuda:0')\n",
            "84712 tensor(0.9987, device='cuda:0')\n",
            "84715 tensor(0.9946, device='cuda:0')\n",
            "84718 tensor(0.9973, device='cuda:0')\n",
            "84719 tensor(0.9994, device='cuda:0')\n",
            "84722 tensor(0.9959, device='cuda:0')\n",
            "84724 tensor(0.9999, device='cuda:0')\n",
            "84727 tensor(0.9925, device='cuda:0')\n",
            "84729 tensor(0.9957, device='cuda:0')\n",
            "84733 tensor(0.9989, device='cuda:0')\n",
            "84737 tensor(0.9904, device='cuda:0')\n",
            "84753 tensor(0.9938, device='cuda:0')\n",
            "84754 tensor(0.9996, device='cuda:0')\n",
            "84763 tensor(0.9974, device='cuda:0')\n",
            "84772 tensor(0.9957, device='cuda:0')\n",
            "84783 tensor(0.9926, device='cuda:0')\n",
            "84787 tensor(0.9913, device='cuda:0')\n",
            "84795 tensor(0.9948, device='cuda:0')\n",
            "84814 tensor(0.9999, device='cuda:0')\n",
            "84821 tensor(0.9955, device='cuda:0')\n",
            "84827 tensor(0.9910, device='cuda:0')\n",
            "84829 tensor(0.9909, device='cuda:0')\n",
            "84831 tensor(0.9996, device='cuda:0')\n",
            "84835 tensor(0.9997, device='cuda:0')\n",
            "84836 tensor(0.9990, device='cuda:0')\n",
            "84841 tensor(0.9909, device='cuda:0')\n",
            "84845 tensor(0.9947, device='cuda:0')\n",
            "84846 tensor(0.9954, device='cuda:0')\n",
            "84850 tensor(0.9978, device='cuda:0')\n",
            "84857 tensor(0.9998, device='cuda:0')\n",
            "84859 tensor(0.9998, device='cuda:0')\n",
            "84860 tensor(0.9971, device='cuda:0')\n",
            "84865 tensor(0.9996, device='cuda:0')\n",
            "84880 tensor(0.9988, device='cuda:0')\n",
            "84881 tensor(0.9991, device='cuda:0')\n",
            "84887 tensor(0.9994, device='cuda:0')\n",
            "84903 tensor(0.9980, device='cuda:0')\n",
            "84911 tensor(0.9987, device='cuda:0')\n",
            "84916 tensor(0.9996, device='cuda:0')\n",
            "84922 tensor(0.9997, device='cuda:0')\n",
            "84924 tensor(0.9981, device='cuda:0')\n",
            "84930 tensor(0.9960, device='cuda:0')\n",
            "84941 tensor(0.9930, device='cuda:0')\n",
            "84949 tensor(0.9988, device='cuda:0')\n",
            "84967 tensor(0.9950, device='cuda:0')\n",
            "84973 tensor(0.9975, device='cuda:0')\n",
            "84975 tensor(0.9964, device='cuda:0')\n",
            "84980 tensor(0.9920, device='cuda:0')\n",
            "84982 tensor(0.9930, device='cuda:0')\n",
            "84984 tensor(0.9927, device='cuda:0')\n",
            "84994 tensor(0.9989, device='cuda:0')\n",
            "84995 tensor(0.9999, device='cuda:0')\n",
            "84997 tensor(0.9976, device='cuda:0')\n",
            "85003 tensor(0.9927, device='cuda:0')\n",
            "85008 tensor(0.9988, device='cuda:0')\n",
            "85015 tensor(0.9975, device='cuda:0')\n",
            "85016 tensor(0.9989, device='cuda:0')\n",
            "85019 tensor(0.9911, device='cuda:0')\n",
            "85021 tensor(0.9982, device='cuda:0')\n",
            "85023 tensor(0.9999, device='cuda:0')\n",
            "85028 tensor(0.9990, device='cuda:0')\n",
            "85030 tensor(0.9971, device='cuda:0')\n",
            "85034 tensor(0.9998, device='cuda:0')\n",
            "85035 tensor(0.9919, device='cuda:0')\n",
            "85038 tensor(0.9992, device='cuda:0')\n",
            "85039 tensor(0.9961, device='cuda:0')\n",
            "85057 tensor(0.9934, device='cuda:0')\n",
            "85063 tensor(0.9959, device='cuda:0')\n",
            "85068 tensor(0.9977, device='cuda:0')\n",
            "85073 tensor(0.9969, device='cuda:0')\n",
            "85076 tensor(0.9975, device='cuda:0')\n",
            "85084 tensor(0.9925, device='cuda:0')\n",
            "85085 tensor(0.9989, device='cuda:0')\n",
            "85086 tensor(0.9919, device='cuda:0')\n",
            "85096 tensor(0.9969, device='cuda:0')\n",
            "85099 tensor(0.9955, device='cuda:0')\n",
            "85108 tensor(0.9986, device='cuda:0')\n",
            "85109 tensor(0.9990, device='cuda:0')\n",
            "85110 tensor(0.9994, device='cuda:0')\n",
            "85116 tensor(0.9996, device='cuda:0')\n",
            "85129 tensor(0.9961, device='cuda:0')\n",
            "85135 tensor(0.9996, device='cuda:0')\n",
            "85136 tensor(0.9921, device='cuda:0')\n",
            "85148 tensor(0.9954, device='cuda:0')\n",
            "85160 tensor(0.9973, device='cuda:0')\n",
            "85171 tensor(0.9975, device='cuda:0')\n",
            "85172 tensor(0.9995, device='cuda:0')\n",
            "85177 tensor(0.9970, device='cuda:0')\n",
            "85179 tensor(0.9948, device='cuda:0')\n",
            "85184 tensor(0.9999, device='cuda:0')\n",
            "85189 tensor(0.9987, device='cuda:0')\n",
            "85192 tensor(0.9949, device='cuda:0')\n",
            "85198 tensor(0.9977, device='cuda:0')\n",
            "85200 tensor(0.9965, device='cuda:0')\n",
            "85204 tensor(0.9947, device='cuda:0')\n",
            "85205 tensor(0.9995, device='cuda:0')\n",
            "85212 tensor(0.9974, device='cuda:0')\n",
            "85220 tensor(0.9995, device='cuda:0')\n",
            "85226 tensor(0.9922, device='cuda:0')\n",
            "85243 tensor(0.9999, device='cuda:0')\n",
            "85251 tensor(0.9972, device='cuda:0')\n",
            "85252 tensor(0.9979, device='cuda:0')\n",
            "85258 tensor(0.9915, device='cuda:0')\n",
            "85262 tensor(0.9974, device='cuda:0')\n",
            "85267 tensor(0.9987, device='cuda:0')\n",
            "85274 tensor(0.9991, device='cuda:0')\n",
            "85276 tensor(0.9906, device='cuda:0')\n",
            "85279 tensor(0.9958, device='cuda:0')\n",
            "85280 tensor(0.9956, device='cuda:0')\n",
            "85281 tensor(0.9984, device='cuda:0')\n",
            "85282 tensor(0.9999, device='cuda:0')\n",
            "85283 tensor(0.9979, device='cuda:0')\n",
            "85285 tensor(0.9987, device='cuda:0')\n",
            "85291 tensor(0.9992, device='cuda:0')\n",
            "85292 tensor(1.0000, device='cuda:0')\n",
            "85298 tensor(0.9950, device='cuda:0')\n",
            "85301 tensor(0.9921, device='cuda:0')\n",
            "85310 tensor(0.9973, device='cuda:0')\n",
            "85311 tensor(0.9942, device='cuda:0')\n",
            "85313 tensor(0.9972, device='cuda:0')\n",
            "85314 tensor(0.9908, device='cuda:0')\n",
            "85318 tensor(0.9991, device='cuda:0')\n",
            "85324 tensor(0.9967, device='cuda:0')\n",
            "85331 tensor(0.9995, device='cuda:0')\n",
            "85332 tensor(0.9988, device='cuda:0')\n",
            "85336 tensor(0.9948, device='cuda:0')\n",
            "85343 tensor(0.9957, device='cuda:0')\n",
            "85349 tensor(0.9993, device='cuda:0')\n",
            "85351 tensor(0.9999, device='cuda:0')\n",
            "85357 tensor(0.9961, device='cuda:0')\n",
            "85365 tensor(0.9994, device='cuda:0')\n",
            "85369 tensor(0.9998, device='cuda:0')\n",
            "85372 tensor(0.9957, device='cuda:0')\n",
            "85375 tensor(0.9996, device='cuda:0')\n",
            "85378 tensor(0.9989, device='cuda:0')\n",
            "85384 tensor(0.9996, device='cuda:0')\n",
            "85385 tensor(0.9964, device='cuda:0')\n",
            "85387 tensor(0.9979, device='cuda:0')\n",
            "85396 tensor(0.9921, device='cuda:0')\n",
            "85420 tensor(0.9925, device='cuda:0')\n",
            "85422 tensor(0.9964, device='cuda:0')\n",
            "85426 tensor(0.9994, device='cuda:0')\n",
            "85431 tensor(0.9985, device='cuda:0')\n",
            "85433 tensor(0.9995, device='cuda:0')\n",
            "85440 tensor(0.9980, device='cuda:0')\n",
            "85446 tensor(0.9995, device='cuda:0')\n",
            "85462 tensor(0.9988, device='cuda:0')\n",
            "85468 tensor(0.9979, device='cuda:0')\n",
            "85473 tensor(0.9988, device='cuda:0')\n",
            "85479 tensor(0.9968, device='cuda:0')\n",
            "85491 tensor(0.9972, device='cuda:0')\n",
            "85493 tensor(0.9962, device='cuda:0')\n",
            "85495 tensor(0.9983, device='cuda:0')\n",
            "85498 tensor(0.9906, device='cuda:0')\n",
            "85500 tensor(0.9931, device='cuda:0')\n",
            "85506 tensor(0.9997, device='cuda:0')\n",
            "85507 tensor(0.9975, device='cuda:0')\n",
            "85513 tensor(0.9987, device='cuda:0')\n",
            "85517 tensor(0.9942, device='cuda:0')\n",
            "85518 tensor(0.9920, device='cuda:0')\n",
            "85519 tensor(0.9955, device='cuda:0')\n",
            "85521 tensor(0.9981, device='cuda:0')\n",
            "85526 tensor(0.9975, device='cuda:0')\n",
            "85533 tensor(0.9904, device='cuda:0')\n",
            "85541 tensor(0.9997, device='cuda:0')\n",
            "85543 tensor(0.9965, device='cuda:0')\n",
            "85545 tensor(0.9968, device='cuda:0')\n",
            "85555 tensor(0.9942, device='cuda:0')\n",
            "85561 tensor(0.9980, device='cuda:0')\n",
            "85562 tensor(0.9984, device='cuda:0')\n",
            "85563 tensor(0.9956, device='cuda:0')\n",
            "85569 tensor(0.9980, device='cuda:0')\n",
            "85571 tensor(0.9992, device='cuda:0')\n",
            "85572 tensor(0.9999, device='cuda:0')\n",
            "85580 tensor(0.9932, device='cuda:0')\n",
            "85581 tensor(0.9937, device='cuda:0')\n",
            "85585 tensor(0.9939, device='cuda:0')\n",
            "85586 tensor(0.9955, device='cuda:0')\n",
            "85587 tensor(0.9938, device='cuda:0')\n",
            "85588 tensor(0.9934, device='cuda:0')\n",
            "85594 tensor(0.9998, device='cuda:0')\n",
            "85596 tensor(0.9997, device='cuda:0')\n",
            "85597 tensor(0.9996, device='cuda:0')\n",
            "85601 tensor(0.9999, device='cuda:0')\n",
            "85603 tensor(0.9993, device='cuda:0')\n",
            "85605 tensor(0.9975, device='cuda:0')\n",
            "85608 tensor(0.9992, device='cuda:0')\n",
            "85616 tensor(0.9999, device='cuda:0')\n",
            "85626 tensor(0.9993, device='cuda:0')\n",
            "85630 tensor(0.9961, device='cuda:0')\n",
            "85633 tensor(0.9979, device='cuda:0')\n",
            "85637 tensor(0.9993, device='cuda:0')\n",
            "85638 tensor(0.9923, device='cuda:0')\n",
            "85653 tensor(0.9950, device='cuda:0')\n",
            "85654 tensor(0.9997, device='cuda:0')\n",
            "85655 tensor(0.9915, device='cuda:0')\n",
            "85657 tensor(0.9973, device='cuda:0')\n",
            "85676 tensor(0.9955, device='cuda:0')\n",
            "85682 tensor(0.9981, device='cuda:0')\n",
            "85692 tensor(0.9934, device='cuda:0')\n",
            "85697 tensor(0.9998, device='cuda:0')\n",
            "85707 tensor(0.9989, device='cuda:0')\n",
            "85711 tensor(0.9969, device='cuda:0')\n",
            "85728 tensor(0.9951, device='cuda:0')\n",
            "85732 tensor(0.9938, device='cuda:0')\n",
            "85738 tensor(0.9934, device='cuda:0')\n",
            "85740 tensor(0.9994, device='cuda:0')\n",
            "85742 tensor(0.9928, device='cuda:0')\n",
            "85751 tensor(0.9959, device='cuda:0')\n",
            "85761 tensor(0.9965, device='cuda:0')\n",
            "85763 tensor(0.9931, device='cuda:0')\n",
            "85764 tensor(0.9982, device='cuda:0')\n",
            "85774 tensor(0.9939, device='cuda:0')\n",
            "85781 tensor(0.9999, device='cuda:0')\n",
            "85784 tensor(0.9993, device='cuda:0')\n",
            "85787 tensor(0.9956, device='cuda:0')\n",
            "85792 tensor(0.9960, device='cuda:0')\n",
            "85802 tensor(0.9998, device='cuda:0')\n",
            "85811 tensor(0.9949, device='cuda:0')\n",
            "85812 tensor(0.9959, device='cuda:0')\n",
            "85814 tensor(0.9994, device='cuda:0')\n",
            "85816 tensor(0.9949, device='cuda:0')\n",
            "85823 tensor(0.9930, device='cuda:0')\n",
            "85826 tensor(0.9986, device='cuda:0')\n",
            "85830 tensor(0.9991, device='cuda:0')\n",
            "85833 tensor(0.9991, device='cuda:0')\n",
            "85835 tensor(0.9997, device='cuda:0')\n",
            "85839 tensor(0.9993, device='cuda:0')\n",
            "85840 tensor(0.9982, device='cuda:0')\n",
            "85842 tensor(0.9948, device='cuda:0')\n",
            "85845 tensor(0.9964, device='cuda:0')\n",
            "85847 tensor(0.9950, device='cuda:0')\n",
            "85864 tensor(0.9950, device='cuda:0')\n",
            "85865 tensor(0.9968, device='cuda:0')\n",
            "85867 tensor(0.9970, device='cuda:0')\n",
            "85871 tensor(0.9991, device='cuda:0')\n",
            "85874 tensor(0.9994, device='cuda:0')\n",
            "85880 tensor(0.9913, device='cuda:0')\n",
            "85885 tensor(0.9987, device='cuda:0')\n",
            "85888 tensor(0.9988, device='cuda:0')\n",
            "85908 tensor(0.9979, device='cuda:0')\n",
            "85915 tensor(0.9971, device='cuda:0')\n",
            "85923 tensor(0.9939, device='cuda:0')\n",
            "85929 tensor(0.9960, device='cuda:0')\n",
            "85934 tensor(0.9964, device='cuda:0')\n",
            "85936 tensor(0.9977, device='cuda:0')\n",
            "85939 tensor(0.9999, device='cuda:0')\n",
            "85941 tensor(0.9973, device='cuda:0')\n",
            "85953 tensor(0.9994, device='cuda:0')\n",
            "85954 tensor(0.9988, device='cuda:0')\n",
            "85964 tensor(0.9946, device='cuda:0')\n",
            "85966 tensor(0.9974, device='cuda:0')\n",
            "85968 tensor(0.9967, device='cuda:0')\n",
            "85974 tensor(0.9921, device='cuda:0')\n",
            "85980 tensor(0.9944, device='cuda:0')\n",
            "85990 tensor(0.9997, device='cuda:0')\n",
            "85992 tensor(0.9957, device='cuda:0')\n",
            "85993 tensor(0.9944, device='cuda:0')\n",
            "86000 tensor(0.9952, device='cuda:0')\n",
            "86004 tensor(0.9970, device='cuda:0')\n",
            "86006 tensor(0.9997, device='cuda:0')\n",
            "86010 tensor(0.9984, device='cuda:0')\n",
            "86011 tensor(0.9996, device='cuda:0')\n",
            "86013 tensor(0.9997, device='cuda:0')\n",
            "86014 tensor(0.9904, device='cuda:0')\n",
            "86021 tensor(0.9992, device='cuda:0')\n",
            "86031 tensor(0.9963, device='cuda:0')\n",
            "86040 tensor(0.9910, device='cuda:0')\n",
            "86043 tensor(0.9954, device='cuda:0')\n",
            "86058 tensor(0.9929, device='cuda:0')\n",
            "86064 tensor(0.9961, device='cuda:0')\n",
            "86065 tensor(0.9986, device='cuda:0')\n",
            "86068 tensor(0.9996, device='cuda:0')\n",
            "86073 tensor(0.9902, device='cuda:0')\n",
            "86089 tensor(0.9926, device='cuda:0')\n",
            "86099 tensor(0.9958, device='cuda:0')\n",
            "86101 tensor(0.9983, device='cuda:0')\n",
            "86108 tensor(0.9963, device='cuda:0')\n",
            "86119 tensor(0.9991, device='cuda:0')\n",
            "86124 tensor(0.9995, device='cuda:0')\n",
            "86128 tensor(0.9981, device='cuda:0')\n",
            "86133 tensor(0.9945, device='cuda:0')\n",
            "86136 tensor(0.9905, device='cuda:0')\n",
            "86142 tensor(0.9927, device='cuda:0')\n",
            "86144 tensor(0.9989, device='cuda:0')\n",
            "86156 tensor(0.9918, device='cuda:0')\n",
            "86159 tensor(0.9948, device='cuda:0')\n",
            "86161 tensor(0.9996, device='cuda:0')\n",
            "86165 tensor(0.9929, device='cuda:0')\n",
            "86168 tensor(0.9995, device='cuda:0')\n",
            "86178 tensor(0.9991, device='cuda:0')\n",
            "86184 tensor(0.9918, device='cuda:0')\n",
            "86185 tensor(0.9996, device='cuda:0')\n",
            "86186 tensor(0.9972, device='cuda:0')\n",
            "86187 tensor(0.9974, device='cuda:0')\n",
            "86194 tensor(0.9959, device='cuda:0')\n",
            "86207 tensor(0.9984, device='cuda:0')\n",
            "86225 tensor(0.9989, device='cuda:0')\n",
            "86228 tensor(0.9985, device='cuda:0')\n",
            "86229 tensor(0.9993, device='cuda:0')\n",
            "86231 tensor(0.9971, device='cuda:0')\n",
            "86232 tensor(0.9905, device='cuda:0')\n",
            "86238 tensor(0.9950, device='cuda:0')\n",
            "86253 tensor(0.9979, device='cuda:0')\n",
            "86254 tensor(0.9921, device='cuda:0')\n",
            "86256 tensor(0.9992, device='cuda:0')\n",
            "86260 tensor(0.9976, device='cuda:0')\n",
            "86261 tensor(0.9988, device='cuda:0')\n",
            "86264 tensor(0.9987, device='cuda:0')\n",
            "86266 tensor(0.9935, device='cuda:0')\n",
            "86273 tensor(0.9998, device='cuda:0')\n",
            "86283 tensor(0.9912, device='cuda:0')\n",
            "86284 tensor(0.9934, device='cuda:0')\n",
            "86288 tensor(0.9967, device='cuda:0')\n",
            "86289 tensor(0.9984, device='cuda:0')\n",
            "86297 tensor(0.9988, device='cuda:0')\n",
            "86302 tensor(0.9946, device='cuda:0')\n",
            "86303 tensor(0.9996, device='cuda:0')\n",
            "86305 tensor(0.9903, device='cuda:0')\n",
            "86311 tensor(0.9996, device='cuda:0')\n",
            "86316 tensor(0.9971, device='cuda:0')\n",
            "86323 tensor(0.9998, device='cuda:0')\n",
            "86325 tensor(0.9982, device='cuda:0')\n",
            "86349 tensor(0.9999, device='cuda:0')\n",
            "86364 tensor(0.9930, device='cuda:0')\n",
            "86366 tensor(0.9999, device='cuda:0')\n",
            "86372 tensor(0.9985, device='cuda:0')\n",
            "86375 tensor(0.9962, device='cuda:0')\n",
            "86376 tensor(0.9994, device='cuda:0')\n",
            "86378 tensor(0.9955, device='cuda:0')\n",
            "86388 tensor(0.9982, device='cuda:0')\n",
            "86403 tensor(0.9998, device='cuda:0')\n",
            "86404 tensor(0.9998, device='cuda:0')\n",
            "86406 tensor(0.9979, device='cuda:0')\n",
            "86407 tensor(0.9946, device='cuda:0')\n",
            "86413 tensor(0.9943, device='cuda:0')\n",
            "86414 tensor(0.9988, device='cuda:0')\n",
            "86417 tensor(0.9988, device='cuda:0')\n",
            "86432 tensor(0.9965, device='cuda:0')\n",
            "86436 tensor(0.9997, device='cuda:0')\n",
            "86444 tensor(0.9908, device='cuda:0')\n",
            "86447 tensor(0.9919, device='cuda:0')\n",
            "86449 tensor(0.9985, device='cuda:0')\n",
            "86452 tensor(0.9998, device='cuda:0')\n",
            "86460 tensor(0.9998, device='cuda:0')\n",
            "86461 tensor(0.9963, device='cuda:0')\n",
            "86465 tensor(0.9996, device='cuda:0')\n",
            "86474 tensor(0.9963, device='cuda:0')\n",
            "86476 tensor(0.9998, device='cuda:0')\n",
            "86479 tensor(0.9921, device='cuda:0')\n",
            "86485 tensor(0.9989, device='cuda:0')\n",
            "86488 tensor(0.9942, device='cuda:0')\n",
            "86489 tensor(0.9948, device='cuda:0')\n",
            "86496 tensor(0.9957, device='cuda:0')\n",
            "86498 tensor(0.9991, device='cuda:0')\n",
            "86504 tensor(0.9990, device='cuda:0')\n",
            "86526 tensor(0.9993, device='cuda:0')\n",
            "86527 tensor(0.9985, device='cuda:0')\n",
            "86543 tensor(0.9971, device='cuda:0')\n",
            "86546 tensor(0.9995, device='cuda:0')\n",
            "86550 tensor(0.9964, device='cuda:0')\n",
            "86566 tensor(0.9990, device='cuda:0')\n",
            "86569 tensor(0.9935, device='cuda:0')\n",
            "86571 tensor(0.9919, device='cuda:0')\n",
            "86581 tensor(0.9977, device='cuda:0')\n",
            "86585 tensor(0.9975, device='cuda:0')\n",
            "86586 tensor(0.9996, device='cuda:0')\n",
            "86588 tensor(0.9999, device='cuda:0')\n",
            "86590 tensor(0.9929, device='cuda:0')\n",
            "86593 tensor(0.9996, device='cuda:0')\n",
            "86602 tensor(0.9991, device='cuda:0')\n",
            "86606 tensor(0.9920, device='cuda:0')\n",
            "86610 tensor(0.9971, device='cuda:0')\n",
            "86617 tensor(0.9964, device='cuda:0')\n",
            "86628 tensor(0.9944, device='cuda:0')\n",
            "86630 tensor(0.9988, device='cuda:0')\n",
            "86636 tensor(0.9974, device='cuda:0')\n",
            "86637 tensor(0.9977, device='cuda:0')\n",
            "86644 tensor(0.9977, device='cuda:0')\n",
            "86653 tensor(0.9926, device='cuda:0')\n",
            "86658 tensor(0.9926, device='cuda:0')\n",
            "86670 tensor(0.9951, device='cuda:0')\n",
            "86671 tensor(0.9923, device='cuda:0')\n",
            "86677 tensor(0.9926, device='cuda:0')\n",
            "86687 tensor(0.9916, device='cuda:0')\n",
            "86689 tensor(0.9934, device='cuda:0')\n",
            "86696 tensor(0.9994, device='cuda:0')\n",
            "86698 tensor(0.9942, device='cuda:0')\n",
            "86702 tensor(0.9963, device='cuda:0')\n",
            "86704 tensor(0.9968, device='cuda:0')\n",
            "86707 tensor(0.9937, device='cuda:0')\n",
            "86717 tensor(0.9991, device='cuda:0')\n",
            "86723 tensor(0.9947, device='cuda:0')\n",
            "86725 tensor(0.9973, device='cuda:0')\n",
            "86726 tensor(0.9998, device='cuda:0')\n",
            "86730 tensor(0.9984, device='cuda:0')\n",
            "86745 tensor(0.9999, device='cuda:0')\n",
            "86747 tensor(0.9998, device='cuda:0')\n",
            "86751 tensor(0.9999, device='cuda:0')\n",
            "86754 tensor(0.9952, device='cuda:0')\n",
            "86757 tensor(0.9999, device='cuda:0')\n",
            "86760 tensor(0.9962, device='cuda:0')\n",
            "86765 tensor(0.9980, device='cuda:0')\n",
            "86766 tensor(0.9931, device='cuda:0')\n",
            "86774 tensor(0.9998, device='cuda:0')\n",
            "86786 tensor(0.9979, device='cuda:0')\n",
            "86789 tensor(0.9991, device='cuda:0')\n",
            "86793 tensor(0.9989, device='cuda:0')\n",
            "86798 tensor(0.9965, device='cuda:0')\n",
            "86801 tensor(0.9991, device='cuda:0')\n",
            "86817 tensor(0.9964, device='cuda:0')\n",
            "86820 tensor(0.9947, device='cuda:0')\n",
            "86841 tensor(0.9921, device='cuda:0')\n",
            "86849 tensor(0.9946, device='cuda:0')\n",
            "86858 tensor(0.9966, device='cuda:0')\n",
            "86861 tensor(0.9998, device='cuda:0')\n",
            "86869 tensor(0.9964, device='cuda:0')\n",
            "86876 tensor(0.9948, device='cuda:0')\n",
            "86877 tensor(0.9996, device='cuda:0')\n",
            "86883 tensor(0.9990, device='cuda:0')\n",
            "86884 tensor(0.9991, device='cuda:0')\n",
            "86886 tensor(0.9991, device='cuda:0')\n",
            "86887 tensor(0.9913, device='cuda:0')\n",
            "86889 tensor(0.9990, device='cuda:0')\n",
            "86890 tensor(0.9960, device='cuda:0')\n",
            "86895 tensor(0.9915, device='cuda:0')\n",
            "86899 tensor(0.9946, device='cuda:0')\n",
            "86910 tensor(0.9965, device='cuda:0')\n",
            "86913 tensor(0.9953, device='cuda:0')\n",
            "86918 tensor(0.9990, device='cuda:0')\n",
            "86926 tensor(0.9961, device='cuda:0')\n",
            "86956 tensor(0.9999, device='cuda:0')\n",
            "86958 tensor(0.9953, device='cuda:0')\n",
            "86960 tensor(0.9981, device='cuda:0')\n",
            "86962 tensor(0.9967, device='cuda:0')\n",
            "86966 tensor(0.9993, device='cuda:0')\n",
            "86967 tensor(0.9917, device='cuda:0')\n",
            "86972 tensor(0.9975, device='cuda:0')\n",
            "86974 tensor(0.9996, device='cuda:0')\n",
            "86980 tensor(0.9960, device='cuda:0')\n",
            "86984 tensor(0.9956, device='cuda:0')\n",
            "86986 tensor(0.9999, device='cuda:0')\n",
            "86987 tensor(0.9989, device='cuda:0')\n",
            "86988 tensor(0.9992, device='cuda:0')\n",
            "86991 tensor(0.9948, device='cuda:0')\n",
            "86996 tensor(0.9931, device='cuda:0')\n",
            "87002 tensor(0.9999, device='cuda:0')\n",
            "87004 tensor(0.9946, device='cuda:0')\n",
            "87006 tensor(0.9939, device='cuda:0')\n",
            "87012 tensor(0.9997, device='cuda:0')\n",
            "87019 tensor(0.9995, device='cuda:0')\n",
            "87030 tensor(0.9988, device='cuda:0')\n",
            "87035 tensor(0.9995, device='cuda:0')\n",
            "87037 tensor(0.9930, device='cuda:0')\n",
            "87051 tensor(0.9956, device='cuda:0')\n",
            "87061 tensor(0.9997, device='cuda:0')\n",
            "87062 tensor(0.9988, device='cuda:0')\n",
            "87070 tensor(0.9929, device='cuda:0')\n",
            "87079 tensor(0.9939, device='cuda:0')\n",
            "87080 tensor(0.9920, device='cuda:0')\n",
            "87095 tensor(0.9997, device='cuda:0')\n",
            "87108 tensor(0.9975, device='cuda:0')\n",
            "87127 tensor(0.9946, device='cuda:0')\n",
            "87137 tensor(0.9937, device='cuda:0')\n",
            "87152 tensor(0.9993, device='cuda:0')\n",
            "87165 tensor(0.9989, device='cuda:0')\n",
            "87172 tensor(0.9901, device='cuda:0')\n",
            "87174 tensor(0.9998, device='cuda:0')\n",
            "87175 tensor(0.9912, device='cuda:0')\n",
            "87176 tensor(0.9945, device='cuda:0')\n",
            "87186 tensor(0.9997, device='cuda:0')\n",
            "87195 tensor(0.9948, device='cuda:0')\n",
            "87197 tensor(0.9944, device='cuda:0')\n",
            "87201 tensor(0.9975, device='cuda:0')\n",
            "87205 tensor(0.9930, device='cuda:0')\n",
            "87208 tensor(0.9998, device='cuda:0')\n",
            "87222 tensor(0.9999, device='cuda:0')\n",
            "87227 tensor(0.9996, device='cuda:0')\n",
            "87229 tensor(0.9982, device='cuda:0')\n",
            "87230 tensor(0.9971, device='cuda:0')\n",
            "87236 tensor(0.9931, device='cuda:0')\n",
            "87240 tensor(0.9938, device='cuda:0')\n",
            "87242 tensor(0.9996, device='cuda:0')\n",
            "87246 tensor(0.9989, device='cuda:0')\n",
            "87254 tensor(0.9995, device='cuda:0')\n",
            "87269 tensor(0.9958, device='cuda:0')\n",
            "87291 tensor(0.9906, device='cuda:0')\n",
            "87294 tensor(0.9987, device='cuda:0')\n",
            "87301 tensor(0.9983, device='cuda:0')\n",
            "87305 tensor(0.9985, device='cuda:0')\n",
            "87316 tensor(0.9945, device='cuda:0')\n",
            "87318 tensor(0.9998, device='cuda:0')\n",
            "87320 tensor(0.9950, device='cuda:0')\n",
            "87327 tensor(0.9990, device='cuda:0')\n",
            "87330 tensor(0.9952, device='cuda:0')\n",
            "87331 tensor(0.9932, device='cuda:0')\n",
            "87334 tensor(0.9997, device='cuda:0')\n",
            "87347 tensor(0.9916, device='cuda:0')\n",
            "87350 tensor(0.9914, device='cuda:0')\n",
            "87355 tensor(0.9989, device='cuda:0')\n",
            "87356 tensor(0.9922, device='cuda:0')\n",
            "87367 tensor(0.9998, device='cuda:0')\n",
            "87391 tensor(0.9995, device='cuda:0')\n",
            "87394 tensor(0.9949, device='cuda:0')\n",
            "87396 tensor(0.9989, device='cuda:0')\n",
            "87398 tensor(0.9959, device='cuda:0')\n",
            "87400 tensor(0.9939, device='cuda:0')\n",
            "87402 tensor(0.9917, device='cuda:0')\n",
            "87403 tensor(0.9973, device='cuda:0')\n",
            "87408 tensor(0.9997, device='cuda:0')\n",
            "87409 tensor(0.9971, device='cuda:0')\n",
            "87413 tensor(0.9903, device='cuda:0')\n",
            "87414 tensor(0.9987, device='cuda:0')\n",
            "87417 tensor(0.9950, device='cuda:0')\n",
            "87422 tensor(0.9984, device='cuda:0')\n",
            "87434 tensor(0.9917, device='cuda:0')\n",
            "87440 tensor(0.9955, device='cuda:0')\n",
            "87444 tensor(0.9959, device='cuda:0')\n",
            "87449 tensor(0.9961, device='cuda:0')\n",
            "87455 tensor(0.9979, device='cuda:0')\n",
            "87469 tensor(0.9994, device='cuda:0')\n",
            "87476 tensor(0.9990, device='cuda:0')\n",
            "87478 tensor(0.9964, device='cuda:0')\n",
            "87480 tensor(0.9964, device='cuda:0')\n",
            "87485 tensor(0.9927, device='cuda:0')\n",
            "87488 tensor(0.9999, device='cuda:0')\n",
            "87490 tensor(0.9984, device='cuda:0')\n",
            "87498 tensor(0.9933, device='cuda:0')\n",
            "87500 tensor(0.9926, device='cuda:0')\n",
            "87502 tensor(0.9942, device='cuda:0')\n",
            "87503 tensor(0.9996, device='cuda:0')\n",
            "87507 tensor(0.9970, device='cuda:0')\n",
            "87513 tensor(0.9960, device='cuda:0')\n",
            "87517 tensor(0.9977, device='cuda:0')\n",
            "87519 tensor(0.9989, device='cuda:0')\n",
            "87524 tensor(0.9947, device='cuda:0')\n",
            "87527 tensor(0.9926, device='cuda:0')\n",
            "87528 tensor(0.9950, device='cuda:0')\n",
            "87529 tensor(0.9981, device='cuda:0')\n",
            "87536 tensor(0.9955, device='cuda:0')\n",
            "87541 tensor(0.9962, device='cuda:0')\n",
            "87549 tensor(0.9999, device='cuda:0')\n",
            "87566 tensor(0.9978, device='cuda:0')\n",
            "87571 tensor(0.9996, device='cuda:0')\n",
            "87576 tensor(0.9978, device='cuda:0')\n",
            "87586 tensor(0.9960, device='cuda:0')\n",
            "87589 tensor(0.9998, device='cuda:0')\n",
            "87590 tensor(0.9946, device='cuda:0')\n",
            "87593 tensor(1.0000, device='cuda:0')\n",
            "87600 tensor(0.9990, device='cuda:0')\n",
            "87603 tensor(0.9980, device='cuda:0')\n",
            "87611 tensor(0.9994, device='cuda:0')\n",
            "87627 tensor(0.9986, device='cuda:0')\n",
            "87636 tensor(0.9978, device='cuda:0')\n",
            "87639 tensor(0.9983, device='cuda:0')\n",
            "87643 tensor(0.9981, device='cuda:0')\n",
            "87648 tensor(0.9983, device='cuda:0')\n",
            "87670 tensor(0.9939, device='cuda:0')\n",
            "87673 tensor(0.9982, device='cuda:0')\n",
            "87683 tensor(0.9997, device='cuda:0')\n",
            "87695 tensor(1.0000, device='cuda:0')\n",
            "87696 tensor(0.9914, device='cuda:0')\n",
            "87699 tensor(0.9994, device='cuda:0')\n",
            "87704 tensor(0.9997, device='cuda:0')\n",
            "87726 tensor(0.9929, device='cuda:0')\n",
            "87748 tensor(0.9975, device='cuda:0')\n",
            "87750 tensor(0.9969, device='cuda:0')\n",
            "87773 tensor(0.9932, device='cuda:0')\n",
            "87778 tensor(0.9977, device='cuda:0')\n",
            "87783 tensor(0.9989, device='cuda:0')\n",
            "87784 tensor(0.9991, device='cuda:0')\n",
            "87786 tensor(0.9946, device='cuda:0')\n",
            "87788 tensor(0.9977, device='cuda:0')\n",
            "87793 tensor(0.9962, device='cuda:0')\n",
            "87796 tensor(0.9922, device='cuda:0')\n",
            "87813 tensor(0.9901, device='cuda:0')\n",
            "87814 tensor(0.9957, device='cuda:0')\n",
            "87822 tensor(0.9974, device='cuda:0')\n",
            "87828 tensor(0.9904, device='cuda:0')\n",
            "87837 tensor(0.9980, device='cuda:0')\n",
            "87849 tensor(0.9927, device='cuda:0')\n",
            "87851 tensor(0.9981, device='cuda:0')\n",
            "87852 tensor(0.9913, device='cuda:0')\n",
            "87855 tensor(0.9983, device='cuda:0')\n",
            "87858 tensor(0.9994, device='cuda:0')\n",
            "87867 tensor(0.9984, device='cuda:0')\n",
            "87872 tensor(0.9998, device='cuda:0')\n",
            "87874 tensor(0.9998, device='cuda:0')\n",
            "87878 tensor(0.9922, device='cuda:0')\n",
            "87888 tensor(0.9959, device='cuda:0')\n",
            "87896 tensor(0.9944, device='cuda:0')\n",
            "87904 tensor(0.9968, device='cuda:0')\n",
            "87908 tensor(0.9946, device='cuda:0')\n",
            "87912 tensor(0.9983, device='cuda:0')\n",
            "87913 tensor(0.9920, device='cuda:0')\n",
            "87920 tensor(0.9947, device='cuda:0')\n",
            "87923 tensor(0.9977, device='cuda:0')\n",
            "87927 tensor(0.9969, device='cuda:0')\n",
            "87936 tensor(0.9999, device='cuda:0')\n",
            "87941 tensor(0.9977, device='cuda:0')\n",
            "87946 tensor(0.9991, device='cuda:0')\n",
            "87949 tensor(0.9963, device='cuda:0')\n",
            "87956 tensor(0.9947, device='cuda:0')\n",
            "87962 tensor(0.9932, device='cuda:0')\n",
            "87964 tensor(0.9988, device='cuda:0')\n",
            "87971 tensor(0.9905, device='cuda:0')\n",
            "87978 tensor(0.9984, device='cuda:0')\n",
            "87979 tensor(0.9985, device='cuda:0')\n",
            "87982 tensor(0.9985, device='cuda:0')\n",
            "87984 tensor(0.9999, device='cuda:0')\n",
            "87990 tensor(0.9903, device='cuda:0')\n",
            "87992 tensor(0.9988, device='cuda:0')\n",
            "87996 tensor(0.9955, device='cuda:0')\n",
            "88000 tensor(0.9928, device='cuda:0')\n",
            "88002 tensor(0.9927, device='cuda:0')\n",
            "88006 tensor(0.9988, device='cuda:0')\n",
            "88010 tensor(0.9902, device='cuda:0')\n",
            "88018 tensor(0.9992, device='cuda:0')\n",
            "88022 tensor(0.9972, device='cuda:0')\n",
            "88024 tensor(0.9993, device='cuda:0')\n",
            "88036 tensor(0.9915, device='cuda:0')\n",
            "88038 tensor(0.9987, device='cuda:0')\n",
            "88041 tensor(0.9987, device='cuda:0')\n",
            "88050 tensor(0.9915, device='cuda:0')\n",
            "88053 tensor(0.9943, device='cuda:0')\n",
            "88054 tensor(0.9974, device='cuda:0')\n",
            "88059 tensor(0.9907, device='cuda:0')\n",
            "88060 tensor(0.9937, device='cuda:0')\n",
            "88061 tensor(0.9920, device='cuda:0')\n",
            "88062 tensor(0.9941, device='cuda:0')\n",
            "88066 tensor(0.9993, device='cuda:0')\n",
            "88075 tensor(0.9920, device='cuda:0')\n",
            "88076 tensor(0.9997, device='cuda:0')\n",
            "88077 tensor(0.9991, device='cuda:0')\n",
            "88083 tensor(0.9994, device='cuda:0')\n",
            "88097 tensor(0.9997, device='cuda:0')\n",
            "88104 tensor(0.9999, device='cuda:0')\n",
            "88115 tensor(0.9983, device='cuda:0')\n",
            "88122 tensor(0.9948, device='cuda:0')\n",
            "88134 tensor(0.9995, device='cuda:0')\n",
            "88137 tensor(0.9978, device='cuda:0')\n",
            "88143 tensor(0.9953, device='cuda:0')\n",
            "88145 tensor(0.9989, device='cuda:0')\n",
            "88152 tensor(0.9966, device='cuda:0')\n",
            "88157 tensor(0.9980, device='cuda:0')\n",
            "88158 tensor(0.9969, device='cuda:0')\n",
            "88166 tensor(0.9947, device='cuda:0')\n",
            "88171 tensor(0.9997, device='cuda:0')\n",
            "88172 tensor(0.9993, device='cuda:0')\n",
            "88175 tensor(0.9981, device='cuda:0')\n",
            "88181 tensor(0.9971, device='cuda:0')\n",
            "88185 tensor(0.9986, device='cuda:0')\n",
            "88195 tensor(0.9994, device='cuda:0')\n",
            "88201 tensor(0.9982, device='cuda:0')\n",
            "88203 tensor(0.9992, device='cuda:0')\n",
            "88212 tensor(0.9988, device='cuda:0')\n",
            "88216 tensor(0.9907, device='cuda:0')\n",
            "88218 tensor(0.9999, device='cuda:0')\n",
            "88221 tensor(0.9978, device='cuda:0')\n",
            "88223 tensor(0.9987, device='cuda:0')\n",
            "88225 tensor(1.0000, device='cuda:0')\n",
            "88228 tensor(0.9901, device='cuda:0')\n",
            "88232 tensor(0.9930, device='cuda:0')\n",
            "88234 tensor(0.9998, device='cuda:0')\n",
            "88235 tensor(0.9989, device='cuda:0')\n",
            "88236 tensor(0.9995, device='cuda:0')\n",
            "88238 tensor(0.9965, device='cuda:0')\n",
            "88241 tensor(0.9925, device='cuda:0')\n",
            "88254 tensor(0.9914, device='cuda:0')\n",
            "88259 tensor(0.9931, device='cuda:0')\n",
            "88270 tensor(0.9956, device='cuda:0')\n",
            "88283 tensor(0.9971, device='cuda:0')\n",
            "88290 tensor(0.9984, device='cuda:0')\n",
            "88293 tensor(0.9975, device='cuda:0')\n",
            "88303 tensor(0.9918, device='cuda:0')\n",
            "88311 tensor(0.9978, device='cuda:0')\n",
            "88321 tensor(0.9967, device='cuda:0')\n",
            "88325 tensor(0.9998, device='cuda:0')\n",
            "88328 tensor(0.9982, device='cuda:0')\n",
            "88341 tensor(0.9999, device='cuda:0')\n",
            "88343 tensor(0.9962, device='cuda:0')\n",
            "88347 tensor(0.9926, device='cuda:0')\n",
            "88348 tensor(0.9979, device='cuda:0')\n",
            "88349 tensor(0.9954, device='cuda:0')\n",
            "88358 tensor(0.9919, device='cuda:0')\n",
            "88364 tensor(0.9987, device='cuda:0')\n",
            "88367 tensor(0.9931, device='cuda:0')\n",
            "88370 tensor(0.9984, device='cuda:0')\n",
            "88376 tensor(0.9978, device='cuda:0')\n",
            "88388 tensor(0.9979, device='cuda:0')\n",
            "88392 tensor(0.9950, device='cuda:0')\n",
            "88397 tensor(0.9992, device='cuda:0')\n",
            "88402 tensor(0.9964, device='cuda:0')\n",
            "88407 tensor(0.9934, device='cuda:0')\n",
            "88409 tensor(0.9996, device='cuda:0')\n",
            "88411 tensor(0.9981, device='cuda:0')\n",
            "88413 tensor(0.9973, device='cuda:0')\n",
            "88428 tensor(0.9962, device='cuda:0')\n",
            "88429 tensor(0.9937, device='cuda:0')\n",
            "88431 tensor(0.9915, device='cuda:0')\n",
            "88434 tensor(0.9937, device='cuda:0')\n",
            "88439 tensor(0.9978, device='cuda:0')\n",
            "88451 tensor(0.9983, device='cuda:0')\n",
            "88458 tensor(0.9992, device='cuda:0')\n",
            "88470 tensor(0.9979, device='cuda:0')\n",
            "88475 tensor(0.9973, device='cuda:0')\n",
            "88483 tensor(0.9915, device='cuda:0')\n",
            "88487 tensor(0.9977, device='cuda:0')\n",
            "88488 tensor(0.9996, device='cuda:0')\n",
            "88489 tensor(0.9986, device='cuda:0')\n",
            "88492 tensor(0.9985, device='cuda:0')\n",
            "88496 tensor(0.9990, device='cuda:0')\n",
            "88498 tensor(0.9991, device='cuda:0')\n",
            "88516 tensor(0.9996, device='cuda:0')\n",
            "88527 tensor(0.9970, device='cuda:0')\n",
            "88535 tensor(0.9971, device='cuda:0')\n",
            "88538 tensor(0.9977, device='cuda:0')\n",
            "88542 tensor(0.9901, device='cuda:0')\n",
            "88546 tensor(0.9957, device='cuda:0')\n",
            "88550 tensor(0.9995, device='cuda:0')\n",
            "88574 tensor(0.9986, device='cuda:0')\n",
            "88584 tensor(0.9978, device='cuda:0')\n",
            "88589 tensor(0.9980, device='cuda:0')\n",
            "88591 tensor(0.9967, device='cuda:0')\n",
            "88592 tensor(0.9975, device='cuda:0')\n",
            "88594 tensor(0.9976, device='cuda:0')\n",
            "88596 tensor(0.9929, device='cuda:0')\n",
            "88600 tensor(0.9911, device='cuda:0')\n",
            "88606 tensor(0.9991, device='cuda:0')\n",
            "88613 tensor(0.9975, device='cuda:0')\n",
            "88615 tensor(0.9957, device='cuda:0')\n",
            "88627 tensor(0.9994, device='cuda:0')\n",
            "88638 tensor(0.9996, device='cuda:0')\n",
            "88639 tensor(0.9965, device='cuda:0')\n",
            "88640 tensor(0.9964, device='cuda:0')\n",
            "88643 tensor(0.9902, device='cuda:0')\n",
            "88649 tensor(0.9983, device='cuda:0')\n",
            "88659 tensor(0.9949, device='cuda:0')\n",
            "88660 tensor(0.9948, device='cuda:0')\n",
            "88664 tensor(0.9913, device='cuda:0')\n",
            "88669 tensor(0.9986, device='cuda:0')\n",
            "88672 tensor(0.9903, device='cuda:0')\n",
            "88675 tensor(0.9952, device='cuda:0')\n",
            "88682 tensor(0.9999, device='cuda:0')\n",
            "88689 tensor(0.9936, device='cuda:0')\n",
            "88699 tensor(0.9975, device='cuda:0')\n",
            "88702 tensor(0.9933, device='cuda:0')\n",
            "88704 tensor(0.9937, device='cuda:0')\n",
            "88709 tensor(0.9976, device='cuda:0')\n",
            "88710 tensor(0.9941, device='cuda:0')\n",
            "88721 tensor(0.9994, device='cuda:0')\n",
            "88727 tensor(0.9987, device='cuda:0')\n",
            "88728 tensor(0.9971, device='cuda:0')\n",
            "88730 tensor(0.9938, device='cuda:0')\n",
            "88731 tensor(0.9961, device='cuda:0')\n",
            "88734 tensor(0.9984, device='cuda:0')\n",
            "88739 tensor(0.9959, device='cuda:0')\n",
            "88753 tensor(0.9979, device='cuda:0')\n",
            "88754 tensor(0.9986, device='cuda:0')\n",
            "88767 tensor(0.9965, device='cuda:0')\n",
            "88769 tensor(0.9946, device='cuda:0')\n",
            "88770 tensor(0.9939, device='cuda:0')\n",
            "88773 tensor(0.9946, device='cuda:0')\n",
            "88774 tensor(0.9948, device='cuda:0')\n",
            "88776 tensor(0.9989, device='cuda:0')\n",
            "88790 tensor(0.9982, device='cuda:0')\n",
            "88792 tensor(0.9939, device='cuda:0')\n",
            "88794 tensor(0.9953, device='cuda:0')\n",
            "88795 tensor(0.9998, device='cuda:0')\n",
            "88796 tensor(0.9990, device='cuda:0')\n",
            "88807 tensor(0.9997, device='cuda:0')\n",
            "88816 tensor(0.9995, device='cuda:0')\n",
            "88820 tensor(0.9972, device='cuda:0')\n",
            "88825 tensor(0.9948, device='cuda:0')\n",
            "88827 tensor(0.9993, device='cuda:0')\n",
            "88833 tensor(0.9952, device='cuda:0')\n",
            "88839 tensor(0.9904, device='cuda:0')\n",
            "88843 tensor(0.9986, device='cuda:0')\n",
            "88844 tensor(0.9993, device='cuda:0')\n",
            "88853 tensor(0.9931, device='cuda:0')\n",
            "88861 tensor(0.9932, device='cuda:0')\n",
            "88862 tensor(0.9992, device='cuda:0')\n",
            "88863 tensor(0.9993, device='cuda:0')\n",
            "88867 tensor(0.9955, device='cuda:0')\n",
            "88870 tensor(0.9999, device='cuda:0')\n",
            "88874 tensor(0.9987, device='cuda:0')\n",
            "88876 tensor(0.9945, device='cuda:0')\n",
            "88885 tensor(0.9926, device='cuda:0')\n",
            "88891 tensor(0.9904, device='cuda:0')\n",
            "88893 tensor(0.9905, device='cuda:0')\n",
            "88901 tensor(0.9973, device='cuda:0')\n",
            "88902 tensor(0.9944, device='cuda:0')\n",
            "88909 tensor(0.9982, device='cuda:0')\n",
            "88921 tensor(0.9929, device='cuda:0')\n",
            "88926 tensor(0.9931, device='cuda:0')\n",
            "88934 tensor(0.9959, device='cuda:0')\n",
            "88936 tensor(0.9971, device='cuda:0')\n",
            "88939 tensor(0.9929, device='cuda:0')\n",
            "88941 tensor(0.9936, device='cuda:0')\n",
            "88942 tensor(0.9980, device='cuda:0')\n",
            "88946 tensor(0.9951, device='cuda:0')\n",
            "88951 tensor(0.9968, device='cuda:0')\n",
            "88963 tensor(0.9978, device='cuda:0')\n",
            "88967 tensor(0.9988, device='cuda:0')\n",
            "88973 tensor(0.9916, device='cuda:0')\n",
            "88978 tensor(0.9923, device='cuda:0')\n",
            "88981 tensor(0.9909, device='cuda:0')\n",
            "88982 tensor(0.9965, device='cuda:0')\n",
            "88983 tensor(0.9932, device='cuda:0')\n",
            "88997 tensor(0.9964, device='cuda:0')\n",
            "88998 tensor(0.9994, device='cuda:0')\n",
            "89006 tensor(0.9997, device='cuda:0')\n",
            "89010 tensor(0.9931, device='cuda:0')\n",
            "89012 tensor(0.9961, device='cuda:0')\n",
            "89018 tensor(0.9955, device='cuda:0')\n",
            "89039 tensor(0.9965, device='cuda:0')\n",
            "89057 tensor(0.9945, device='cuda:0')\n",
            "89058 tensor(0.9986, device='cuda:0')\n",
            "89064 tensor(0.9987, device='cuda:0')\n",
            "89065 tensor(0.9982, device='cuda:0')\n",
            "89074 tensor(0.9967, device='cuda:0')\n",
            "89095 tensor(0.9917, device='cuda:0')\n",
            "89102 tensor(0.9982, device='cuda:0')\n",
            "89103 tensor(0.9982, device='cuda:0')\n",
            "89121 tensor(0.9945, device='cuda:0')\n",
            "89126 tensor(0.9929, device='cuda:0')\n",
            "89130 tensor(0.9982, device='cuda:0')\n",
            "89137 tensor(0.9980, device='cuda:0')\n",
            "89144 tensor(0.9980, device='cuda:0')\n",
            "89151 tensor(0.9969, device='cuda:0')\n",
            "89164 tensor(0.9988, device='cuda:0')\n",
            "89175 tensor(0.9939, device='cuda:0')\n",
            "89180 tensor(0.9989, device='cuda:0')\n",
            "89189 tensor(0.9975, device='cuda:0')\n",
            "89195 tensor(0.9983, device='cuda:0')\n",
            "89201 tensor(0.9995, device='cuda:0')\n",
            "89202 tensor(0.9962, device='cuda:0')\n",
            "89221 tensor(0.9951, device='cuda:0')\n",
            "89228 tensor(0.9971, device='cuda:0')\n",
            "89233 tensor(0.9993, device='cuda:0')\n",
            "89239 tensor(0.9952, device='cuda:0')\n",
            "89245 tensor(0.9997, device='cuda:0')\n",
            "89261 tensor(0.9980, device='cuda:0')\n",
            "89273 tensor(0.9992, device='cuda:0')\n",
            "89278 tensor(0.9997, device='cuda:0')\n",
            "89285 tensor(0.9968, device='cuda:0')\n",
            "89289 tensor(0.9994, device='cuda:0')\n",
            "89295 tensor(0.9995, device='cuda:0')\n",
            "89296 tensor(0.9959, device='cuda:0')\n",
            "89312 tensor(0.9973, device='cuda:0')\n",
            "89317 tensor(0.9968, device='cuda:0')\n",
            "89320 tensor(0.9999, device='cuda:0')\n",
            "89329 tensor(0.9973, device='cuda:0')\n",
            "89338 tensor(0.9944, device='cuda:0')\n",
            "89339 tensor(0.9991, device='cuda:0')\n",
            "89341 tensor(0.9919, device='cuda:0')\n",
            "89351 tensor(0.9937, device='cuda:0')\n",
            "89354 tensor(0.9953, device='cuda:0')\n",
            "89360 tensor(0.9965, device='cuda:0')\n",
            "89365 tensor(0.9991, device='cuda:0')\n",
            "89366 tensor(0.9996, device='cuda:0')\n",
            "89367 tensor(0.9958, device='cuda:0')\n",
            "89370 tensor(0.9953, device='cuda:0')\n",
            "89375 tensor(0.9950, device='cuda:0')\n",
            "89379 tensor(0.9945, device='cuda:0')\n",
            "89382 tensor(0.9954, device='cuda:0')\n",
            "89384 tensor(0.9907, device='cuda:0')\n",
            "89385 tensor(0.9927, device='cuda:0')\n",
            "89390 tensor(0.9961, device='cuda:0')\n",
            "89391 tensor(0.9990, device='cuda:0')\n",
            "89399 tensor(0.9935, device='cuda:0')\n",
            "89403 tensor(0.9999, device='cuda:0')\n",
            "89408 tensor(0.9966, device='cuda:0')\n",
            "89422 tensor(0.9998, device='cuda:0')\n",
            "89425 tensor(0.9928, device='cuda:0')\n",
            "89430 tensor(0.9965, device='cuda:0')\n",
            "89440 tensor(0.9992, device='cuda:0')\n",
            "89443 tensor(0.9922, device='cuda:0')\n",
            "89453 tensor(0.9973, device='cuda:0')\n",
            "89458 tensor(0.9948, device='cuda:0')\n",
            "89461 tensor(0.9994, device='cuda:0')\n",
            "89468 tensor(0.9976, device='cuda:0')\n",
            "89484 tensor(0.9985, device='cuda:0')\n",
            "89486 tensor(0.9976, device='cuda:0')\n",
            "89494 tensor(0.9925, device='cuda:0')\n",
            "89496 tensor(0.9985, device='cuda:0')\n",
            "89503 tensor(0.9988, device='cuda:0')\n",
            "89512 tensor(0.9986, device='cuda:0')\n",
            "89514 tensor(0.9983, device='cuda:0')\n",
            "89519 tensor(0.9968, device='cuda:0')\n",
            "89526 tensor(0.9988, device='cuda:0')\n",
            "89545 tensor(0.9996, device='cuda:0')\n",
            "89549 tensor(0.9990, device='cuda:0')\n",
            "89551 tensor(0.9971, device='cuda:0')\n",
            "89554 tensor(0.9993, device='cuda:0')\n",
            "89573 tensor(0.9981, device='cuda:0')\n",
            "89580 tensor(0.9982, device='cuda:0')\n",
            "89581 tensor(0.9973, device='cuda:0')\n",
            "89584 tensor(0.9999, device='cuda:0')\n",
            "89602 tensor(0.9972, device='cuda:0')\n",
            "89604 tensor(0.9998, device='cuda:0')\n",
            "89611 tensor(0.9976, device='cuda:0')\n",
            "89616 tensor(0.9958, device='cuda:0')\n",
            "89621 tensor(0.9984, device='cuda:0')\n",
            "89628 tensor(0.9998, device='cuda:0')\n",
            "89632 tensor(0.9997, device='cuda:0')\n",
            "89633 tensor(0.9997, device='cuda:0')\n",
            "89636 tensor(0.9971, device='cuda:0')\n",
            "89637 tensor(0.9985, device='cuda:0')\n",
            "89641 tensor(0.9972, device='cuda:0')\n",
            "89658 tensor(0.9992, device='cuda:0')\n",
            "89668 tensor(0.9993, device='cuda:0')\n",
            "89674 tensor(0.9933, device='cuda:0')\n",
            "89677 tensor(0.9936, device='cuda:0')\n",
            "89685 tensor(0.9993, device='cuda:0')\n",
            "89687 tensor(0.9926, device='cuda:0')\n",
            "89692 tensor(0.9912, device='cuda:0')\n",
            "89695 tensor(0.9986, device='cuda:0')\n",
            "89696 tensor(0.9984, device='cuda:0')\n",
            "89697 tensor(0.9978, device='cuda:0')\n",
            "89704 tensor(0.9992, device='cuda:0')\n",
            "89705 tensor(0.9999, device='cuda:0')\n",
            "89706 tensor(0.9990, device='cuda:0')\n",
            "89710 tensor(0.9977, device='cuda:0')\n",
            "89713 tensor(0.9921, device='cuda:0')\n",
            "89721 tensor(0.9998, device='cuda:0')\n",
            "89733 tensor(0.9957, device='cuda:0')\n",
            "89734 tensor(0.9984, device='cuda:0')\n",
            "89745 tensor(0.9989, device='cuda:0')\n",
            "89758 tensor(0.9997, device='cuda:0')\n",
            "89761 tensor(0.9909, device='cuda:0')\n",
            "89772 tensor(0.9978, device='cuda:0')\n",
            "89773 tensor(0.9994, device='cuda:0')\n",
            "89775 tensor(0.9984, device='cuda:0')\n",
            "89781 tensor(0.9975, device='cuda:0')\n",
            "89782 tensor(0.9978, device='cuda:0')\n",
            "89784 tensor(0.9920, device='cuda:0')\n",
            "89797 tensor(0.9907, device='cuda:0')\n",
            "89804 tensor(0.9998, device='cuda:0')\n",
            "89809 tensor(0.9999, device='cuda:0')\n",
            "89816 tensor(0.9989, device='cuda:0')\n",
            "89822 tensor(0.9931, device='cuda:0')\n",
            "89828 tensor(0.9979, device='cuda:0')\n",
            "89833 tensor(0.9996, device='cuda:0')\n",
            "89838 tensor(0.9969, device='cuda:0')\n",
            "89844 tensor(0.9984, device='cuda:0')\n",
            "89845 tensor(0.9994, device='cuda:0')\n",
            "89858 tensor(0.9924, device='cuda:0')\n",
            "89862 tensor(0.9977, device='cuda:0')\n",
            "89865 tensor(0.9997, device='cuda:0')\n",
            "89874 tensor(0.9981, device='cuda:0')\n",
            "89877 tensor(0.9994, device='cuda:0')\n",
            "89881 tensor(0.9959, device='cuda:0')\n",
            "89882 tensor(0.9986, device='cuda:0')\n",
            "89883 tensor(0.9990, device='cuda:0')\n",
            "89897 tensor(0.9995, device='cuda:0')\n",
            "89901 tensor(0.9953, device='cuda:0')\n",
            "89905 tensor(0.9961, device='cuda:0')\n",
            "89906 tensor(0.9979, device='cuda:0')\n",
            "89907 tensor(0.9925, device='cuda:0')\n",
            "89908 tensor(0.9906, device='cuda:0')\n",
            "89909 tensor(0.9995, device='cuda:0')\n",
            "89911 tensor(0.9977, device='cuda:0')\n",
            "89913 tensor(1.0000, device='cuda:0')\n",
            "89921 tensor(0.9961, device='cuda:0')\n",
            "89928 tensor(0.9997, device='cuda:0')\n",
            "89932 tensor(0.9913, device='cuda:0')\n",
            "89933 tensor(0.9957, device='cuda:0')\n",
            "89934 tensor(0.9946, device='cuda:0')\n",
            "89943 tensor(0.9987, device='cuda:0')\n",
            "89954 tensor(0.9991, device='cuda:0')\n",
            "89956 tensor(0.9906, device='cuda:0')\n",
            "89958 tensor(0.9982, device='cuda:0')\n",
            "89982 tensor(0.9981, device='cuda:0')\n",
            "89985 tensor(0.9986, device='cuda:0')\n",
            "89990 tensor(0.9926, device='cuda:0')\n",
            "89995 tensor(0.9986, device='cuda:0')\n",
            "90010 tensor(0.9989, device='cuda:0')\n",
            "90016 tensor(0.9934, device='cuda:0')\n",
            "90019 tensor(0.9956, device='cuda:0')\n",
            "90020 tensor(0.9911, device='cuda:0')\n",
            "90024 tensor(0.9964, device='cuda:0')\n",
            "90031 tensor(0.9976, device='cuda:0')\n",
            "90032 tensor(0.9953, device='cuda:0')\n",
            "90034 tensor(0.9983, device='cuda:0')\n",
            "90037 tensor(0.9968, device='cuda:0')\n",
            "90039 tensor(0.9975, device='cuda:0')\n",
            "90040 tensor(0.9988, device='cuda:0')\n",
            "90042 tensor(0.9999, device='cuda:0')\n",
            "90047 tensor(0.9961, device='cuda:0')\n",
            "90052 tensor(0.9907, device='cuda:0')\n",
            "90053 tensor(0.9971, device='cuda:0')\n",
            "90063 tensor(0.9977, device='cuda:0')\n",
            "90070 tensor(0.9964, device='cuda:0')\n",
            "90071 tensor(0.9999, device='cuda:0')\n",
            "90074 tensor(0.9941, device='cuda:0')\n",
            "90076 tensor(0.9989, device='cuda:0')\n",
            "90080 tensor(0.9974, device='cuda:0')\n",
            "90082 tensor(0.9967, device='cuda:0')\n",
            "90097 tensor(0.9906, device='cuda:0')\n",
            "90101 tensor(0.9998, device='cuda:0')\n",
            "90102 tensor(0.9993, device='cuda:0')\n",
            "90108 tensor(0.9995, device='cuda:0')\n",
            "90120 tensor(0.9902, device='cuda:0')\n",
            "90124 tensor(0.9961, device='cuda:0')\n",
            "90129 tensor(0.9991, device='cuda:0')\n",
            "90132 tensor(0.9985, device='cuda:0')\n",
            "90145 tensor(0.9993, device='cuda:0')\n",
            "90147 tensor(0.9988, device='cuda:0')\n",
            "90157 tensor(0.9970, device='cuda:0')\n",
            "90161 tensor(0.9986, device='cuda:0')\n",
            "90162 tensor(0.9996, device='cuda:0')\n",
            "90163 tensor(0.9980, device='cuda:0')\n",
            "90165 tensor(0.9993, device='cuda:0')\n",
            "90166 tensor(0.9962, device='cuda:0')\n",
            "90167 tensor(0.9999, device='cuda:0')\n",
            "90168 tensor(0.9922, device='cuda:0')\n",
            "90171 tensor(0.9963, device='cuda:0')\n",
            "90173 tensor(0.9982, device='cuda:0')\n",
            "90184 tensor(0.9992, device='cuda:0')\n",
            "90186 tensor(0.9990, device='cuda:0')\n",
            "90191 tensor(0.9912, device='cuda:0')\n",
            "90196 tensor(0.9969, device='cuda:0')\n",
            "90197 tensor(0.9994, device='cuda:0')\n",
            "90202 tensor(0.9963, device='cuda:0')\n",
            "90207 tensor(0.9980, device='cuda:0')\n",
            "90208 tensor(0.9999, device='cuda:0')\n",
            "90214 tensor(0.9992, device='cuda:0')\n",
            "90230 tensor(0.9959, device='cuda:0')\n",
            "90235 tensor(0.9911, device='cuda:0')\n",
            "90244 tensor(0.9996, device='cuda:0')\n",
            "90246 tensor(0.9938, device='cuda:0')\n",
            "90252 tensor(0.9955, device='cuda:0')\n",
            "90256 tensor(0.9951, device='cuda:0')\n",
            "90261 tensor(0.9949, device='cuda:0')\n",
            "90264 tensor(0.9984, device='cuda:0')\n",
            "90265 tensor(0.9979, device='cuda:0')\n",
            "90266 tensor(0.9984, device='cuda:0')\n",
            "90275 tensor(0.9955, device='cuda:0')\n",
            "90276 tensor(0.9913, device='cuda:0')\n",
            "90279 tensor(0.9922, device='cuda:0')\n",
            "90281 tensor(0.9995, device='cuda:0')\n",
            "90288 tensor(0.9986, device='cuda:0')\n",
            "90291 tensor(0.9959, device='cuda:0')\n",
            "90303 tensor(0.9954, device='cuda:0')\n",
            "90307 tensor(0.9976, device='cuda:0')\n",
            "90308 tensor(0.9960, device='cuda:0')\n",
            "90312 tensor(0.9966, device='cuda:0')\n",
            "90314 tensor(0.9928, device='cuda:0')\n",
            "90319 tensor(0.9903, device='cuda:0')\n",
            "90320 tensor(0.9993, device='cuda:0')\n",
            "90331 tensor(0.9936, device='cuda:0')\n",
            "90333 tensor(0.9955, device='cuda:0')\n",
            "90342 tensor(0.9982, device='cuda:0')\n",
            "90351 tensor(0.9980, device='cuda:0')\n",
            "90354 tensor(0.9924, device='cuda:0')\n",
            "90357 tensor(0.9989, device='cuda:0')\n",
            "90369 tensor(0.9983, device='cuda:0')\n",
            "90373 tensor(0.9999, device='cuda:0')\n",
            "90374 tensor(0.9985, device='cuda:0')\n",
            "90376 tensor(0.9999, device='cuda:0')\n",
            "90391 tensor(0.9943, device='cuda:0')\n",
            "90397 tensor(0.9921, device='cuda:0')\n",
            "90401 tensor(0.9903, device='cuda:0')\n",
            "90402 tensor(0.9976, device='cuda:0')\n",
            "90406 tensor(0.9993, device='cuda:0')\n",
            "90417 tensor(0.9946, device='cuda:0')\n",
            "90418 tensor(0.9998, device='cuda:0')\n",
            "90421 tensor(0.9914, device='cuda:0')\n",
            "90423 tensor(0.9997, device='cuda:0')\n",
            "90428 tensor(0.9997, device='cuda:0')\n",
            "90433 tensor(0.9934, device='cuda:0')\n",
            "90436 tensor(0.9936, device='cuda:0')\n",
            "90439 tensor(0.9983, device='cuda:0')\n",
            "90440 tensor(0.9933, device='cuda:0')\n",
            "90445 tensor(0.9932, device='cuda:0')\n",
            "90446 tensor(0.9996, device='cuda:0')\n",
            "90467 tensor(0.9995, device='cuda:0')\n",
            "90468 tensor(0.9996, device='cuda:0')\n",
            "90476 tensor(0.9995, device='cuda:0')\n",
            "90483 tensor(0.9988, device='cuda:0')\n",
            "90487 tensor(0.9984, device='cuda:0')\n",
            "90488 tensor(0.9999, device='cuda:0')\n",
            "90492 tensor(0.9999, device='cuda:0')\n",
            "90493 tensor(0.9980, device='cuda:0')\n",
            "90499 tensor(0.9993, device='cuda:0')\n",
            "90514 tensor(0.9992, device='cuda:0')\n",
            "90532 tensor(0.9980, device='cuda:0')\n",
            "90533 tensor(0.9976, device='cuda:0')\n",
            "90534 tensor(0.9925, device='cuda:0')\n",
            "90536 tensor(1.0000, device='cuda:0')\n",
            "90537 tensor(0.9982, device='cuda:0')\n",
            "90539 tensor(0.9962, device='cuda:0')\n",
            "90544 tensor(0.9943, device='cuda:0')\n",
            "90559 tensor(0.9974, device='cuda:0')\n",
            "90564 tensor(0.9990, device='cuda:0')\n",
            "90567 tensor(0.9919, device='cuda:0')\n",
            "90569 tensor(0.9990, device='cuda:0')\n",
            "90573 tensor(0.9990, device='cuda:0')\n",
            "90579 tensor(0.9924, device='cuda:0')\n",
            "90582 tensor(0.9947, device='cuda:0')\n",
            "90591 tensor(0.9931, device='cuda:0')\n",
            "90596 tensor(0.9962, device='cuda:0')\n",
            "90597 tensor(0.9993, device='cuda:0')\n",
            "90602 tensor(0.9971, device='cuda:0')\n",
            "90608 tensor(0.9996, device='cuda:0')\n",
            "90612 tensor(0.9990, device='cuda:0')\n",
            "90616 tensor(0.9986, device='cuda:0')\n",
            "90619 tensor(0.9990, device='cuda:0')\n",
            "90629 tensor(0.9921, device='cuda:0')\n",
            "90631 tensor(0.9967, device='cuda:0')\n",
            "90633 tensor(0.9987, device='cuda:0')\n",
            "90641 tensor(0.9922, device='cuda:0')\n",
            "90648 tensor(0.9994, device='cuda:0')\n",
            "90652 tensor(0.9995, device='cuda:0')\n",
            "90653 tensor(0.9984, device='cuda:0')\n",
            "90657 tensor(0.9925, device='cuda:0')\n",
            "90658 tensor(0.9997, device='cuda:0')\n",
            "90659 tensor(0.9986, device='cuda:0')\n",
            "90660 tensor(0.9964, device='cuda:0')\n",
            "90665 tensor(0.9972, device='cuda:0')\n",
            "90666 tensor(0.9997, device='cuda:0')\n",
            "90671 tensor(0.9952, device='cuda:0')\n",
            "90672 tensor(0.9907, device='cuda:0')\n",
            "90677 tensor(0.9987, device='cuda:0')\n",
            "90700 tensor(0.9979, device='cuda:0')\n",
            "90705 tensor(0.9991, device='cuda:0')\n",
            "90739 tensor(0.9945, device='cuda:0')\n",
            "90741 tensor(0.9988, device='cuda:0')\n",
            "90747 tensor(0.9991, device='cuda:0')\n",
            "90748 tensor(0.9987, device='cuda:0')\n",
            "90757 tensor(0.9993, device='cuda:0')\n",
            "90774 tensor(0.9987, device='cuda:0')\n",
            "90781 tensor(0.9937, device='cuda:0')\n",
            "90789 tensor(0.9986, device='cuda:0')\n",
            "90798 tensor(0.9993, device='cuda:0')\n",
            "90800 tensor(0.9973, device='cuda:0')\n",
            "90802 tensor(0.9989, device='cuda:0')\n",
            "90803 tensor(0.9995, device='cuda:0')\n",
            "90825 tensor(0.9998, device='cuda:0')\n",
            "90832 tensor(0.9994, device='cuda:0')\n",
            "90833 tensor(0.9981, device='cuda:0')\n",
            "90840 tensor(0.9986, device='cuda:0')\n",
            "90846 tensor(0.9992, device='cuda:0')\n",
            "90848 tensor(0.9992, device='cuda:0')\n",
            "90861 tensor(0.9945, device='cuda:0')\n",
            "90865 tensor(0.9989, device='cuda:0')\n",
            "90868 tensor(0.9904, device='cuda:0')\n",
            "90873 tensor(0.9993, device='cuda:0')\n",
            "90877 tensor(0.9926, device='cuda:0')\n",
            "90882 tensor(0.9954, device='cuda:0')\n",
            "90889 tensor(0.9995, device='cuda:0')\n",
            "90895 tensor(0.9929, device='cuda:0')\n",
            "90896 tensor(0.9989, device='cuda:0')\n",
            "90905 tensor(0.9979, device='cuda:0')\n",
            "90907 tensor(0.9995, device='cuda:0')\n",
            "90909 tensor(0.9917, device='cuda:0')\n",
            "90917 tensor(0.9991, device='cuda:0')\n",
            "90918 tensor(0.9997, device='cuda:0')\n",
            "90919 tensor(0.9997, device='cuda:0')\n",
            "90920 tensor(0.9980, device='cuda:0')\n",
            "90938 tensor(0.9900, device='cuda:0')\n",
            "90951 tensor(0.9956, device='cuda:0')\n",
            "90958 tensor(0.9997, device='cuda:0')\n",
            "90959 tensor(0.9993, device='cuda:0')\n",
            "90960 tensor(0.9974, device='cuda:0')\n",
            "90962 tensor(0.9991, device='cuda:0')\n",
            "90965 tensor(0.9997, device='cuda:0')\n",
            "90966 tensor(0.9964, device='cuda:0')\n",
            "90983 tensor(0.9981, device='cuda:0')\n",
            "90993 tensor(1.0000, device='cuda:0')\n",
            "90996 tensor(0.9990, device='cuda:0')\n",
            "91004 tensor(0.9906, device='cuda:0')\n",
            "91014 tensor(0.9935, device='cuda:0')\n",
            "91018 tensor(0.9921, device='cuda:0')\n",
            "91019 tensor(0.9965, device='cuda:0')\n",
            "91029 tensor(0.9972, device='cuda:0')\n",
            "91030 tensor(0.9993, device='cuda:0')\n",
            "91031 tensor(0.9998, device='cuda:0')\n",
            "91035 tensor(0.9943, device='cuda:0')\n",
            "91040 tensor(0.9950, device='cuda:0')\n",
            "91041 tensor(0.9908, device='cuda:0')\n",
            "91042 tensor(0.9987, device='cuda:0')\n",
            "91048 tensor(0.9948, device='cuda:0')\n",
            "91054 tensor(0.9953, device='cuda:0')\n",
            "91058 tensor(0.9993, device='cuda:0')\n",
            "91069 tensor(0.9964, device='cuda:0')\n",
            "91070 tensor(0.9998, device='cuda:0')\n",
            "91079 tensor(0.9955, device='cuda:0')\n",
            "91082 tensor(0.9939, device='cuda:0')\n",
            "91083 tensor(0.9957, device='cuda:0')\n",
            "91089 tensor(1.0000, device='cuda:0')\n",
            "91094 tensor(0.9995, device='cuda:0')\n",
            "91095 tensor(0.9992, device='cuda:0')\n",
            "91096 tensor(0.9997, device='cuda:0')\n",
            "91097 tensor(0.9989, device='cuda:0')\n",
            "91104 tensor(0.9993, device='cuda:0')\n",
            "91105 tensor(0.9994, device='cuda:0')\n",
            "91106 tensor(0.9986, device='cuda:0')\n",
            "91108 tensor(0.9989, device='cuda:0')\n",
            "91109 tensor(0.9985, device='cuda:0')\n",
            "91116 tensor(0.9992, device='cuda:0')\n",
            "91123 tensor(0.9998, device='cuda:0')\n",
            "91125 tensor(0.9990, device='cuda:0')\n",
            "91126 tensor(0.9920, device='cuda:0')\n",
            "91131 tensor(0.9992, device='cuda:0')\n",
            "91135 tensor(0.9953, device='cuda:0')\n",
            "91144 tensor(0.9998, device='cuda:0')\n",
            "91146 tensor(0.9973, device='cuda:0')\n",
            "91156 tensor(0.9979, device='cuda:0')\n",
            "91157 tensor(0.9933, device='cuda:0')\n",
            "91161 tensor(0.9994, device='cuda:0')\n",
            "91166 tensor(0.9985, device='cuda:0')\n",
            "91167 tensor(0.9901, device='cuda:0')\n",
            "91170 tensor(0.9971, device='cuda:0')\n",
            "91172 tensor(0.9977, device='cuda:0')\n",
            "91174 tensor(0.9988, device='cuda:0')\n",
            "91179 tensor(0.9998, device='cuda:0')\n",
            "91182 tensor(0.9983, device='cuda:0')\n",
            "91185 tensor(0.9961, device='cuda:0')\n",
            "91186 tensor(0.9964, device='cuda:0')\n",
            "91188 tensor(0.9996, device='cuda:0')\n",
            "91190 tensor(0.9988, device='cuda:0')\n",
            "91194 tensor(0.9918, device='cuda:0')\n",
            "91199 tensor(0.9926, device='cuda:0')\n",
            "91213 tensor(0.9919, device='cuda:0')\n",
            "91216 tensor(0.9993, device='cuda:0')\n",
            "91221 tensor(0.9942, device='cuda:0')\n",
            "91222 tensor(0.9937, device='cuda:0')\n",
            "91226 tensor(0.9992, device='cuda:0')\n",
            "91230 tensor(0.9978, device='cuda:0')\n",
            "91237 tensor(0.9990, device='cuda:0')\n",
            "91238 tensor(0.9984, device='cuda:0')\n",
            "91241 tensor(0.9939, device='cuda:0')\n",
            "91244 tensor(0.9957, device='cuda:0')\n",
            "91259 tensor(0.9926, device='cuda:0')\n",
            "91268 tensor(0.9964, device='cuda:0')\n",
            "91269 tensor(0.9993, device='cuda:0')\n",
            "91270 tensor(0.9975, device='cuda:0')\n",
            "91271 tensor(0.9981, device='cuda:0')\n",
            "91272 tensor(0.9975, device='cuda:0')\n",
            "91275 tensor(0.9996, device='cuda:0')\n",
            "91280 tensor(0.9997, device='cuda:0')\n",
            "91296 tensor(0.9937, device='cuda:0')\n",
            "91297 tensor(0.9945, device='cuda:0')\n",
            "91303 tensor(0.9971, device='cuda:0')\n",
            "91307 tensor(0.9990, device='cuda:0')\n",
            "91309 tensor(0.9999, device='cuda:0')\n",
            "91310 tensor(0.9966, device='cuda:0')\n",
            "91315 tensor(0.9924, device='cuda:0')\n",
            "91316 tensor(0.9955, device='cuda:0')\n",
            "91324 tensor(0.9987, device='cuda:0')\n",
            "91333 tensor(0.9957, device='cuda:0')\n",
            "91336 tensor(0.9961, device='cuda:0')\n",
            "91337 tensor(0.9982, device='cuda:0')\n",
            "91341 tensor(0.9984, device='cuda:0')\n",
            "91350 tensor(0.9996, device='cuda:0')\n",
            "91358 tensor(0.9996, device='cuda:0')\n",
            "91362 tensor(0.9995, device='cuda:0')\n",
            "91363 tensor(0.9931, device='cuda:0')\n",
            "91364 tensor(0.9994, device='cuda:0')\n",
            "91365 tensor(0.9902, device='cuda:0')\n",
            "91366 tensor(0.9940, device='cuda:0')\n",
            "91372 tensor(0.9910, device='cuda:0')\n",
            "91374 tensor(0.9999, device='cuda:0')\n",
            "91375 tensor(0.9983, device='cuda:0')\n",
            "91382 tensor(0.9942, device='cuda:0')\n",
            "91383 tensor(0.9978, device='cuda:0')\n",
            "91388 tensor(0.9989, device='cuda:0')\n",
            "91393 tensor(1.0000, device='cuda:0')\n",
            "91397 tensor(0.9966, device='cuda:0')\n",
            "91401 tensor(0.9977, device='cuda:0')\n",
            "91402 tensor(0.9996, device='cuda:0')\n",
            "91404 tensor(0.9996, device='cuda:0')\n",
            "91407 tensor(0.9984, device='cuda:0')\n",
            "91410 tensor(0.9925, device='cuda:0')\n",
            "91415 tensor(0.9997, device='cuda:0')\n",
            "91419 tensor(0.9994, device='cuda:0')\n",
            "91420 tensor(0.9920, device='cuda:0')\n",
            "91421 tensor(0.9943, device='cuda:0')\n",
            "91434 tensor(0.9979, device='cuda:0')\n",
            "91450 tensor(0.9982, device='cuda:0')\n",
            "91469 tensor(0.9998, device='cuda:0')\n",
            "91478 tensor(0.9923, device='cuda:0')\n",
            "91482 tensor(0.9995, device='cuda:0')\n",
            "91489 tensor(0.9912, device='cuda:0')\n",
            "91495 tensor(0.9987, device='cuda:0')\n",
            "91497 tensor(0.9947, device='cuda:0')\n",
            "91498 tensor(0.9998, device='cuda:0')\n",
            "91507 tensor(0.9994, device='cuda:0')\n",
            "91514 tensor(0.9947, device='cuda:0')\n",
            "91520 tensor(0.9918, device='cuda:0')\n",
            "91525 tensor(0.9936, device='cuda:0')\n",
            "91538 tensor(0.9996, device='cuda:0')\n",
            "91541 tensor(0.9962, device='cuda:0')\n",
            "91542 tensor(0.9972, device='cuda:0')\n",
            "91551 tensor(0.9902, device='cuda:0')\n",
            "91567 tensor(0.9997, device='cuda:0')\n",
            "91572 tensor(0.9998, device='cuda:0')\n",
            "91575 tensor(0.9966, device='cuda:0')\n",
            "91592 tensor(0.9972, device='cuda:0')\n",
            "91606 tensor(0.9912, device='cuda:0')\n",
            "91609 tensor(0.9925, device='cuda:0')\n",
            "91612 tensor(0.9909, device='cuda:0')\n",
            "91621 tensor(0.9944, device='cuda:0')\n",
            "91627 tensor(0.9987, device='cuda:0')\n",
            "91641 tensor(0.9989, device='cuda:0')\n",
            "91644 tensor(0.9996, device='cuda:0')\n",
            "91646 tensor(0.9945, device='cuda:0')\n",
            "91649 tensor(0.9904, device='cuda:0')\n",
            "91652 tensor(0.9951, device='cuda:0')\n",
            "91663 tensor(0.9928, device='cuda:0')\n",
            "91664 tensor(0.9991, device='cuda:0')\n",
            "91671 tensor(0.9956, device='cuda:0')\n",
            "91675 tensor(0.9980, device='cuda:0')\n",
            "91676 tensor(0.9986, device='cuda:0')\n",
            "91681 tensor(0.9910, device='cuda:0')\n",
            "91685 tensor(0.9965, device='cuda:0')\n",
            "91691 tensor(0.9905, device='cuda:0')\n",
            "91721 tensor(0.9970, device='cuda:0')\n",
            "91725 tensor(0.9997, device='cuda:0')\n",
            "91727 tensor(0.9995, device='cuda:0')\n",
            "91733 tensor(0.9980, device='cuda:0')\n",
            "91736 tensor(0.9910, device='cuda:0')\n",
            "91753 tensor(0.9979, device='cuda:0')\n",
            "91762 tensor(0.9946, device='cuda:0')\n",
            "91780 tensor(0.9976, device='cuda:0')\n",
            "91781 tensor(0.9997, device='cuda:0')\n",
            "91782 tensor(0.9998, device='cuda:0')\n",
            "91785 tensor(0.9970, device='cuda:0')\n",
            "91790 tensor(0.9977, device='cuda:0')\n",
            "91797 tensor(0.9997, device='cuda:0')\n",
            "91827 tensor(0.9939, device='cuda:0')\n",
            "91831 tensor(0.9990, device='cuda:0')\n",
            "91843 tensor(0.9949, device='cuda:0')\n",
            "91849 tensor(0.9975, device='cuda:0')\n",
            "91851 tensor(0.9998, device='cuda:0')\n",
            "91861 tensor(0.9915, device='cuda:0')\n",
            "91878 tensor(0.9998, device='cuda:0')\n",
            "91883 tensor(0.9986, device='cuda:0')\n",
            "91886 tensor(0.9924, device='cuda:0')\n",
            "91888 tensor(0.9999, device='cuda:0')\n",
            "91889 tensor(0.9978, device='cuda:0')\n",
            "91894 tensor(0.9946, device='cuda:0')\n",
            "91896 tensor(0.9956, device='cuda:0')\n",
            "91905 tensor(0.9994, device='cuda:0')\n",
            "91916 tensor(0.9954, device='cuda:0')\n",
            "91921 tensor(0.9918, device='cuda:0')\n",
            "91922 tensor(0.9997, device='cuda:0')\n",
            "91931 tensor(0.9980, device='cuda:0')\n",
            "91934 tensor(0.9992, device='cuda:0')\n",
            "91938 tensor(0.9996, device='cuda:0')\n",
            "91943 tensor(0.9934, device='cuda:0')\n",
            "91949 tensor(0.9956, device='cuda:0')\n",
            "91950 tensor(0.9996, device='cuda:0')\n",
            "91957 tensor(0.9910, device='cuda:0')\n",
            "91963 tensor(0.9983, device='cuda:0')\n",
            "91965 tensor(1.0000, device='cuda:0')\n",
            "91968 tensor(0.9994, device='cuda:0')\n",
            "91969 tensor(0.9959, device='cuda:0')\n",
            "91976 tensor(0.9970, device='cuda:0')\n",
            "91989 tensor(0.9937, device='cuda:0')\n",
            "91991 tensor(0.9965, device='cuda:0')\n",
            "91996 tensor(0.9998, device='cuda:0')\n",
            "92001 tensor(0.9976, device='cuda:0')\n",
            "92006 tensor(0.9978, device='cuda:0')\n",
            "92008 tensor(0.9907, device='cuda:0')\n",
            "92012 tensor(0.9980, device='cuda:0')\n",
            "92018 tensor(0.9998, device='cuda:0')\n",
            "92020 tensor(0.9967, device='cuda:0')\n",
            "92021 tensor(0.9998, device='cuda:0')\n",
            "92023 tensor(1.0000, device='cuda:0')\n",
            "92033 tensor(0.9988, device='cuda:0')\n",
            "92040 tensor(0.9952, device='cuda:0')\n",
            "92043 tensor(0.9962, device='cuda:0')\n",
            "92053 tensor(0.9996, device='cuda:0')\n",
            "92056 tensor(0.9981, device='cuda:0')\n",
            "92057 tensor(0.9917, device='cuda:0')\n",
            "92058 tensor(0.9954, device='cuda:0')\n",
            "92059 tensor(0.9999, device='cuda:0')\n",
            "92067 tensor(0.9946, device='cuda:0')\n",
            "92068 tensor(0.9999, device='cuda:0')\n",
            "92071 tensor(0.9937, device='cuda:0')\n",
            "92085 tensor(0.9988, device='cuda:0')\n",
            "92091 tensor(0.9996, device='cuda:0')\n",
            "92093 tensor(0.9968, device='cuda:0')\n",
            "92124 tensor(0.9971, device='cuda:0')\n",
            "92129 tensor(0.9930, device='cuda:0')\n",
            "92135 tensor(0.9997, device='cuda:0')\n",
            "92136 tensor(0.9994, device='cuda:0')\n",
            "92139 tensor(0.9917, device='cuda:0')\n",
            "92145 tensor(0.9989, device='cuda:0')\n",
            "92161 tensor(0.9961, device='cuda:0')\n",
            "92163 tensor(0.9980, device='cuda:0')\n",
            "92170 tensor(0.9963, device='cuda:0')\n",
            "92171 tensor(0.9989, device='cuda:0')\n",
            "92181 tensor(0.9959, device='cuda:0')\n",
            "92185 tensor(0.9941, device='cuda:0')\n",
            "92186 tensor(0.9980, device='cuda:0')\n",
            "92188 tensor(0.9991, device='cuda:0')\n",
            "92193 tensor(0.9974, device='cuda:0')\n",
            "92196 tensor(0.9988, device='cuda:0')\n",
            "92211 tensor(0.9987, device='cuda:0')\n",
            "92225 tensor(0.9988, device='cuda:0')\n",
            "92229 tensor(0.9942, device='cuda:0')\n",
            "92232 tensor(0.9999, device='cuda:0')\n",
            "92241 tensor(0.9937, device='cuda:0')\n",
            "92256 tensor(0.9965, device='cuda:0')\n",
            "92261 tensor(0.9967, device='cuda:0')\n",
            "92265 tensor(0.9990, device='cuda:0')\n",
            "92266 tensor(0.9968, device='cuda:0')\n",
            "92270 tensor(0.9995, device='cuda:0')\n",
            "92276 tensor(0.9949, device='cuda:0')\n",
            "92282 tensor(0.9946, device='cuda:0')\n",
            "92284 tensor(0.9946, device='cuda:0')\n",
            "92286 tensor(0.9985, device='cuda:0')\n",
            "92290 tensor(0.9993, device='cuda:0')\n",
            "92297 tensor(0.9987, device='cuda:0')\n",
            "92300 tensor(0.9978, device='cuda:0')\n",
            "92305 tensor(0.9990, device='cuda:0')\n",
            "92315 tensor(0.9988, device='cuda:0')\n",
            "92318 tensor(0.9997, device='cuda:0')\n",
            "92322 tensor(0.9954, device='cuda:0')\n",
            "92326 tensor(0.9947, device='cuda:0')\n",
            "92334 tensor(0.9983, device='cuda:0')\n",
            "92337 tensor(0.9981, device='cuda:0')\n",
            "92342 tensor(0.9920, device='cuda:0')\n",
            "92345 tensor(0.9935, device='cuda:0')\n",
            "92346 tensor(0.9998, device='cuda:0')\n",
            "92349 tensor(0.9985, device='cuda:0')\n",
            "92353 tensor(0.9983, device='cuda:0')\n",
            "92354 tensor(0.9978, device='cuda:0')\n",
            "92355 tensor(0.9996, device='cuda:0')\n",
            "92360 tensor(0.9999, device='cuda:0')\n",
            "92365 tensor(0.9955, device='cuda:0')\n",
            "92373 tensor(0.9955, device='cuda:0')\n",
            "92377 tensor(0.9962, device='cuda:0')\n",
            "92388 tensor(0.9949, device='cuda:0')\n",
            "92389 tensor(0.9936, device='cuda:0')\n",
            "92399 tensor(0.9995, device='cuda:0')\n",
            "92400 tensor(0.9918, device='cuda:0')\n",
            "92406 tensor(0.9956, device='cuda:0')\n",
            "92412 tensor(0.9981, device='cuda:0')\n",
            "92416 tensor(0.9964, device='cuda:0')\n",
            "92417 tensor(0.9973, device='cuda:0')\n",
            "92421 tensor(0.9974, device='cuda:0')\n",
            "92426 tensor(0.9946, device='cuda:0')\n",
            "92432 tensor(0.9940, device='cuda:0')\n",
            "92435 tensor(0.9999, device='cuda:0')\n",
            "92437 tensor(0.9996, device='cuda:0')\n",
            "92450 tensor(0.9966, device='cuda:0')\n",
            "92452 tensor(0.9954, device='cuda:0')\n",
            "92464 tensor(0.9912, device='cuda:0')\n",
            "92465 tensor(0.9923, device='cuda:0')\n",
            "92471 tensor(0.9991, device='cuda:0')\n",
            "92474 tensor(0.9989, device='cuda:0')\n",
            "92484 tensor(0.9982, device='cuda:0')\n",
            "92486 tensor(0.9982, device='cuda:0')\n",
            "92491 tensor(0.9958, device='cuda:0')\n",
            "92494 tensor(0.9920, device='cuda:0')\n",
            "92506 tensor(0.9916, device='cuda:0')\n",
            "92510 tensor(0.9942, device='cuda:0')\n",
            "92514 tensor(0.9983, device='cuda:0')\n",
            "92517 tensor(0.9995, device='cuda:0')\n",
            "92518 tensor(0.9984, device='cuda:0')\n",
            "92534 tensor(0.9940, device='cuda:0')\n",
            "92539 tensor(0.9997, device='cuda:0')\n",
            "92544 tensor(0.9963, device='cuda:0')\n",
            "92548 tensor(0.9943, device='cuda:0')\n",
            "92551 tensor(0.9970, device='cuda:0')\n",
            "92552 tensor(0.9930, device='cuda:0')\n",
            "92554 tensor(0.9994, device='cuda:0')\n",
            "92561 tensor(0.9970, device='cuda:0')\n",
            "92567 tensor(0.9998, device='cuda:0')\n",
            "92568 tensor(0.9948, device='cuda:0')\n",
            "92570 tensor(0.9992, device='cuda:0')\n",
            "92572 tensor(0.9959, device='cuda:0')\n",
            "92573 tensor(0.9999, device='cuda:0')\n",
            "92576 tensor(0.9983, device='cuda:0')\n",
            "92577 tensor(0.9992, device='cuda:0')\n",
            "92580 tensor(0.9997, device='cuda:0')\n",
            "92582 tensor(0.9968, device='cuda:0')\n",
            "92583 tensor(0.9948, device='cuda:0')\n",
            "92584 tensor(0.9991, device='cuda:0')\n",
            "92591 tensor(0.9993, device='cuda:0')\n",
            "92594 tensor(0.9980, device='cuda:0')\n",
            "92596 tensor(0.9988, device='cuda:0')\n",
            "92601 tensor(0.9978, device='cuda:0')\n",
            "92604 tensor(0.9996, device='cuda:0')\n",
            "92617 tensor(0.9986, device='cuda:0')\n",
            "92626 tensor(0.9995, device='cuda:0')\n",
            "92630 tensor(0.9915, device='cuda:0')\n",
            "92642 tensor(0.9993, device='cuda:0')\n",
            "92645 tensor(0.9917, device='cuda:0')\n",
            "92648 tensor(0.9976, device='cuda:0')\n",
            "92649 tensor(0.9993, device='cuda:0')\n",
            "92654 tensor(0.9953, device='cuda:0')\n",
            "92655 tensor(0.9960, device='cuda:0')\n",
            "92657 tensor(0.9997, device='cuda:0')\n",
            "92658 tensor(0.9999, device='cuda:0')\n",
            "92662 tensor(0.9941, device='cuda:0')\n",
            "92665 tensor(0.9993, device='cuda:0')\n",
            "92671 tensor(0.9967, device='cuda:0')\n",
            "92676 tensor(0.9911, device='cuda:0')\n",
            "92683 tensor(0.9998, device='cuda:0')\n",
            "92690 tensor(0.9968, device='cuda:0')\n",
            "92698 tensor(0.9998, device='cuda:0')\n",
            "92705 tensor(0.9996, device='cuda:0')\n",
            "92718 tensor(0.9927, device='cuda:0')\n",
            "92730 tensor(0.9999, device='cuda:0')\n",
            "92735 tensor(0.9916, device='cuda:0')\n",
            "92736 tensor(0.9921, device='cuda:0')\n",
            "92739 tensor(0.9995, device='cuda:0')\n",
            "92748 tensor(0.9988, device='cuda:0')\n",
            "92754 tensor(0.9973, device='cuda:0')\n",
            "92766 tensor(0.9991, device='cuda:0')\n",
            "92771 tensor(0.9983, device='cuda:0')\n",
            "92776 tensor(0.9970, device='cuda:0')\n",
            "92778 tensor(0.9995, device='cuda:0')\n",
            "92782 tensor(0.9929, device='cuda:0')\n",
            "92785 tensor(0.9999, device='cuda:0')\n",
            "92787 tensor(0.9979, device='cuda:0')\n",
            "92790 tensor(0.9999, device='cuda:0')\n",
            "92800 tensor(0.9950, device='cuda:0')\n",
            "92806 tensor(0.9974, device='cuda:0')\n",
            "92812 tensor(0.9988, device='cuda:0')\n",
            "92815 tensor(0.9996, device='cuda:0')\n",
            "92836 tensor(0.9979, device='cuda:0')\n",
            "92842 tensor(0.9994, device='cuda:0')\n",
            "92843 tensor(0.9997, device='cuda:0')\n",
            "92844 tensor(0.9919, device='cuda:0')\n",
            "92851 tensor(0.9976, device='cuda:0')\n",
            "92853 tensor(0.9991, device='cuda:0')\n",
            "92856 tensor(0.9954, device='cuda:0')\n",
            "92881 tensor(0.9992, device='cuda:0')\n",
            "92885 tensor(0.9951, device='cuda:0')\n",
            "92890 tensor(0.9982, device='cuda:0')\n",
            "92891 tensor(0.9958, device='cuda:0')\n",
            "92905 tensor(0.9988, device='cuda:0')\n",
            "92906 tensor(0.9984, device='cuda:0')\n",
            "92908 tensor(0.9952, device='cuda:0')\n",
            "92910 tensor(0.9999, device='cuda:0')\n",
            "92917 tensor(0.9992, device='cuda:0')\n",
            "92919 tensor(0.9905, device='cuda:0')\n",
            "92933 tensor(0.9995, device='cuda:0')\n",
            "92938 tensor(0.9960, device='cuda:0')\n",
            "92939 tensor(0.9987, device='cuda:0')\n",
            "92941 tensor(0.9997, device='cuda:0')\n",
            "92945 tensor(0.9993, device='cuda:0')\n",
            "92951 tensor(0.9902, device='cuda:0')\n",
            "92956 tensor(0.9947, device='cuda:0')\n",
            "92957 tensor(0.9958, device='cuda:0')\n",
            "92968 tensor(0.9971, device='cuda:0')\n",
            "92974 tensor(0.9981, device='cuda:0')\n",
            "92975 tensor(0.9953, device='cuda:0')\n",
            "92976 tensor(0.9997, device='cuda:0')\n",
            "92979 tensor(0.9999, device='cuda:0')\n",
            "92980 tensor(0.9988, device='cuda:0')\n",
            "92990 tensor(0.9990, device='cuda:0')\n",
            "92992 tensor(0.9969, device='cuda:0')\n",
            "92993 tensor(0.9951, device='cuda:0')\n",
            "92996 tensor(0.9989, device='cuda:0')\n",
            "93004 tensor(0.9954, device='cuda:0')\n",
            "93005 tensor(0.9914, device='cuda:0')\n",
            "93015 tensor(0.9990, device='cuda:0')\n",
            "93017 tensor(0.9952, device='cuda:0')\n",
            "93020 tensor(0.9996, device='cuda:0')\n",
            "93025 tensor(0.9990, device='cuda:0')\n",
            "93027 tensor(0.9998, device='cuda:0')\n",
            "93031 tensor(0.9958, device='cuda:0')\n",
            "93037 tensor(0.9998, device='cuda:0')\n",
            "93042 tensor(0.9986, device='cuda:0')\n",
            "93044 tensor(0.9914, device='cuda:0')\n",
            "93051 tensor(0.9907, device='cuda:0')\n",
            "93060 tensor(0.9951, device='cuda:0')\n",
            "93064 tensor(0.9965, device='cuda:0')\n",
            "93068 tensor(0.9990, device='cuda:0')\n",
            "93071 tensor(0.9901, device='cuda:0')\n",
            "93074 tensor(0.9919, device='cuda:0')\n",
            "93080 tensor(0.9980, device='cuda:0')\n",
            "93092 tensor(0.9946, device='cuda:0')\n",
            "93093 tensor(0.9997, device='cuda:0')\n",
            "93102 tensor(0.9901, device='cuda:0')\n",
            "93106 tensor(0.9979, device='cuda:0')\n",
            "93108 tensor(0.9965, device='cuda:0')\n",
            "93110 tensor(0.9966, device='cuda:0')\n",
            "93123 tensor(0.9970, device='cuda:0')\n",
            "93125 tensor(0.9924, device='cuda:0')\n",
            "93135 tensor(0.9972, device='cuda:0')\n",
            "93136 tensor(0.9998, device='cuda:0')\n",
            "93138 tensor(0.9977, device='cuda:0')\n",
            "93141 tensor(0.9989, device='cuda:0')\n",
            "93160 tensor(0.9987, device='cuda:0')\n",
            "93162 tensor(0.9917, device='cuda:0')\n",
            "93164 tensor(0.9986, device='cuda:0')\n",
            "93168 tensor(0.9981, device='cuda:0')\n",
            "93172 tensor(0.9974, device='cuda:0')\n",
            "93177 tensor(0.9912, device='cuda:0')\n",
            "93179 tensor(0.9996, device='cuda:0')\n",
            "93181 tensor(0.9982, device='cuda:0')\n",
            "93183 tensor(0.9992, device='cuda:0')\n",
            "93199 tensor(0.9976, device='cuda:0')\n",
            "93201 tensor(0.9931, device='cuda:0')\n",
            "93202 tensor(0.9980, device='cuda:0')\n",
            "93205 tensor(0.9998, device='cuda:0')\n",
            "93214 tensor(0.9978, device='cuda:0')\n",
            "93218 tensor(0.9962, device='cuda:0')\n",
            "93226 tensor(0.9925, device='cuda:0')\n",
            "93227 tensor(0.9999, device='cuda:0')\n",
            "93232 tensor(0.9925, device='cuda:0')\n",
            "93239 tensor(0.9912, device='cuda:0')\n",
            "93240 tensor(0.9994, device='cuda:0')\n",
            "93245 tensor(0.9922, device='cuda:0')\n",
            "93251 tensor(0.9958, device='cuda:0')\n",
            "93258 tensor(0.9923, device='cuda:0')\n",
            "93262 tensor(0.9932, device='cuda:0')\n",
            "93263 tensor(0.9985, device='cuda:0')\n",
            "93272 tensor(0.9977, device='cuda:0')\n",
            "93273 tensor(0.9929, device='cuda:0')\n",
            "93274 tensor(0.9918, device='cuda:0')\n",
            "93276 tensor(0.9944, device='cuda:0')\n",
            "93278 tensor(0.9919, device='cuda:0')\n",
            "93287 tensor(0.9917, device='cuda:0')\n",
            "93290 tensor(0.9965, device='cuda:0')\n",
            "93291 tensor(0.9960, device='cuda:0')\n",
            "93294 tensor(0.9910, device='cuda:0')\n",
            "93295 tensor(0.9996, device='cuda:0')\n",
            "93303 tensor(0.9970, device='cuda:0')\n",
            "93314 tensor(0.9930, device='cuda:0')\n",
            "93320 tensor(0.9990, device='cuda:0')\n",
            "93331 tensor(0.9973, device='cuda:0')\n",
            "93335 tensor(0.9910, device='cuda:0')\n",
            "93342 tensor(0.9998, device='cuda:0')\n",
            "93344 tensor(0.9990, device='cuda:0')\n",
            "93346 tensor(0.9950, device='cuda:0')\n",
            "93356 tensor(0.9966, device='cuda:0')\n",
            "93368 tensor(0.9987, device='cuda:0')\n",
            "93369 tensor(0.9975, device='cuda:0')\n",
            "93376 tensor(0.9930, device='cuda:0')\n",
            "93378 tensor(0.9986, device='cuda:0')\n",
            "93382 tensor(0.9924, device='cuda:0')\n",
            "93386 tensor(0.9908, device='cuda:0')\n",
            "93389 tensor(0.9999, device='cuda:0')\n",
            "93394 tensor(0.9900, device='cuda:0')\n",
            "93399 tensor(0.9983, device='cuda:0')\n",
            "93425 tensor(0.9927, device='cuda:0')\n",
            "93427 tensor(0.9951, device='cuda:0')\n",
            "93439 tensor(0.9924, device='cuda:0')\n",
            "93441 tensor(0.9957, device='cuda:0')\n",
            "93442 tensor(0.9970, device='cuda:0')\n",
            "93443 tensor(0.9993, device='cuda:0')\n",
            "93448 tensor(0.9985, device='cuda:0')\n",
            "93449 tensor(0.9912, device='cuda:0')\n",
            "93452 tensor(0.9989, device='cuda:0')\n",
            "93458 tensor(0.9938, device='cuda:0')\n",
            "93466 tensor(0.9923, device='cuda:0')\n",
            "93473 tensor(0.9989, device='cuda:0')\n",
            "93483 tensor(0.9931, device='cuda:0')\n",
            "93487 tensor(0.9942, device='cuda:0')\n",
            "93489 tensor(0.9992, device='cuda:0')\n",
            "93494 tensor(0.9967, device='cuda:0')\n",
            "93497 tensor(0.9901, device='cuda:0')\n",
            "93505 tensor(0.9959, device='cuda:0')\n",
            "93506 tensor(0.9990, device='cuda:0')\n",
            "93512 tensor(0.9971, device='cuda:0')\n",
            "93518 tensor(0.9945, device='cuda:0')\n",
            "93520 tensor(0.9981, device='cuda:0')\n",
            "93522 tensor(0.9990, device='cuda:0')\n",
            "93524 tensor(0.9948, device='cuda:0')\n",
            "93525 tensor(0.9987, device='cuda:0')\n",
            "93533 tensor(0.9950, device='cuda:0')\n",
            "93541 tensor(0.9961, device='cuda:0')\n",
            "93543 tensor(0.9988, device='cuda:0')\n",
            "93545 tensor(0.9989, device='cuda:0')\n",
            "93546 tensor(0.9927, device='cuda:0')\n",
            "93551 tensor(0.9970, device='cuda:0')\n",
            "93553 tensor(0.9984, device='cuda:0')\n",
            "93556 tensor(0.9998, device='cuda:0')\n",
            "93560 tensor(0.9998, device='cuda:0')\n",
            "93563 tensor(0.9915, device='cuda:0')\n",
            "93571 tensor(0.9935, device='cuda:0')\n",
            "93573 tensor(0.9997, device='cuda:0')\n",
            "93574 tensor(0.9960, device='cuda:0')\n",
            "93582 tensor(0.9995, device='cuda:0')\n",
            "93583 tensor(0.9988, device='cuda:0')\n",
            "93586 tensor(0.9922, device='cuda:0')\n",
            "93590 tensor(0.9907, device='cuda:0')\n",
            "93598 tensor(0.9934, device='cuda:0')\n",
            "93614 tensor(0.9973, device='cuda:0')\n",
            "93618 tensor(0.9998, device='cuda:0')\n",
            "93626 tensor(0.9979, device='cuda:0')\n",
            "93633 tensor(0.9992, device='cuda:0')\n",
            "93638 tensor(0.9984, device='cuda:0')\n",
            "93645 tensor(0.9946, device='cuda:0')\n",
            "93649 tensor(0.9984, device='cuda:0')\n",
            "93651 tensor(0.9983, device='cuda:0')\n",
            "93653 tensor(0.9981, device='cuda:0')\n",
            "93655 tensor(0.9950, device='cuda:0')\n",
            "93662 tensor(0.9949, device='cuda:0')\n",
            "93663 tensor(0.9973, device='cuda:0')\n",
            "93671 tensor(0.9998, device='cuda:0')\n",
            "93674 tensor(0.9988, device='cuda:0')\n",
            "93677 tensor(0.9977, device='cuda:0')\n",
            "93689 tensor(0.9935, device='cuda:0')\n",
            "93698 tensor(0.9959, device='cuda:0')\n",
            "93710 tensor(0.9905, device='cuda:0')\n",
            "93712 tensor(0.9992, device='cuda:0')\n",
            "93713 tensor(0.9960, device='cuda:0')\n",
            "93714 tensor(0.9993, device='cuda:0')\n",
            "93716 tensor(0.9969, device='cuda:0')\n",
            "93717 tensor(0.9989, device='cuda:0')\n",
            "93732 tensor(0.9940, device='cuda:0')\n",
            "93736 tensor(0.9996, device='cuda:0')\n",
            "93739 tensor(0.9978, device='cuda:0')\n",
            "93745 tensor(0.9986, device='cuda:0')\n",
            "93750 tensor(0.9935, device='cuda:0')\n",
            "93762 tensor(0.9989, device='cuda:0')\n",
            "93769 tensor(0.9984, device='cuda:0')\n",
            "93770 tensor(0.9955, device='cuda:0')\n",
            "93778 tensor(0.9938, device='cuda:0')\n",
            "93784 tensor(0.9997, device='cuda:0')\n",
            "93797 tensor(0.9935, device='cuda:0')\n",
            "93805 tensor(0.9961, device='cuda:0')\n",
            "93810 tensor(0.9980, device='cuda:0')\n",
            "93826 tensor(0.9966, device='cuda:0')\n",
            "93829 tensor(0.9951, device='cuda:0')\n",
            "93832 tensor(0.9959, device='cuda:0')\n",
            "93836 tensor(0.9973, device='cuda:0')\n",
            "93839 tensor(0.9962, device='cuda:0')\n",
            "93847 tensor(0.9988, device='cuda:0')\n",
            "93852 tensor(0.9943, device='cuda:0')\n",
            "93853 tensor(0.9994, device='cuda:0')\n",
            "93856 tensor(0.9955, device='cuda:0')\n",
            "93857 tensor(0.9992, device='cuda:0')\n",
            "93864 tensor(0.9900, device='cuda:0')\n",
            "93885 tensor(0.9990, device='cuda:0')\n",
            "93887 tensor(0.9989, device='cuda:0')\n",
            "93892 tensor(0.9984, device='cuda:0')\n",
            "93909 tensor(0.9999, device='cuda:0')\n",
            "93914 tensor(0.9974, device='cuda:0')\n",
            "93919 tensor(0.9986, device='cuda:0')\n",
            "93921 tensor(0.9997, device='cuda:0')\n",
            "93922 tensor(0.9992, device='cuda:0')\n",
            "93929 tensor(0.9988, device='cuda:0')\n",
            "93933 tensor(0.9913, device='cuda:0')\n",
            "93936 tensor(0.9995, device='cuda:0')\n",
            "93962 tensor(0.9990, device='cuda:0')\n",
            "93966 tensor(0.9956, device='cuda:0')\n",
            "93989 tensor(0.9938, device='cuda:0')\n",
            "93990 tensor(1.0000, device='cuda:0')\n",
            "93995 tensor(0.9962, device='cuda:0')\n",
            "94001 tensor(0.9969, device='cuda:0')\n",
            "94010 tensor(0.9998, device='cuda:0')\n",
            "94017 tensor(0.9950, device='cuda:0')\n",
            "94019 tensor(0.9942, device='cuda:0')\n",
            "94025 tensor(0.9950, device='cuda:0')\n",
            "94035 tensor(0.9902, device='cuda:0')\n",
            "94037 tensor(0.9927, device='cuda:0')\n",
            "94039 tensor(0.9936, device='cuda:0')\n",
            "94040 tensor(0.9998, device='cuda:0')\n",
            "94054 tensor(0.9988, device='cuda:0')\n",
            "94062 tensor(0.9970, device='cuda:0')\n",
            "94082 tensor(0.9990, device='cuda:0')\n",
            "94085 tensor(0.9913, device='cuda:0')\n",
            "94095 tensor(0.9966, device='cuda:0')\n",
            "94112 tensor(0.9961, device='cuda:0')\n",
            "94120 tensor(0.9965, device='cuda:0')\n",
            "94125 tensor(0.9969, device='cuda:0')\n",
            "94127 tensor(0.9955, device='cuda:0')\n",
            "94143 tensor(0.9929, device='cuda:0')\n",
            "94145 tensor(0.9967, device='cuda:0')\n",
            "94152 tensor(0.9964, device='cuda:0')\n",
            "94153 tensor(0.9990, device='cuda:0')\n",
            "94155 tensor(0.9990, device='cuda:0')\n",
            "94159 tensor(0.9926, device='cuda:0')\n",
            "94168 tensor(0.9906, device='cuda:0')\n",
            "94170 tensor(0.9987, device='cuda:0')\n",
            "94177 tensor(0.9987, device='cuda:0')\n",
            "94186 tensor(0.9996, device='cuda:0')\n",
            "94188 tensor(0.9998, device='cuda:0')\n",
            "94189 tensor(0.9986, device='cuda:0')\n",
            "94202 tensor(0.9997, device='cuda:0')\n",
            "94206 tensor(0.9984, device='cuda:0')\n",
            "94213 tensor(0.9994, device='cuda:0')\n",
            "94216 tensor(0.9982, device='cuda:0')\n",
            "94218 tensor(0.9975, device='cuda:0')\n",
            "94229 tensor(0.9995, device='cuda:0')\n",
            "94241 tensor(0.9996, device='cuda:0')\n",
            "94250 tensor(0.9945, device='cuda:0')\n",
            "94261 tensor(0.9996, device='cuda:0')\n",
            "94263 tensor(0.9953, device='cuda:0')\n",
            "94267 tensor(0.9972, device='cuda:0')\n",
            "94271 tensor(0.9942, device='cuda:0')\n",
            "94279 tensor(0.9993, device='cuda:0')\n",
            "94292 tensor(0.9984, device='cuda:0')\n",
            "94299 tensor(0.9997, device='cuda:0')\n",
            "94304 tensor(0.9979, device='cuda:0')\n",
            "94319 tensor(0.9998, device='cuda:0')\n",
            "94328 tensor(0.9976, device='cuda:0')\n",
            "94341 tensor(0.9973, device='cuda:0')\n",
            "94342 tensor(0.9905, device='cuda:0')\n",
            "94350 tensor(0.9996, device='cuda:0')\n",
            "94351 tensor(0.9997, device='cuda:0')\n",
            "94360 tensor(0.9926, device='cuda:0')\n",
            "94362 tensor(0.9922, device='cuda:0')\n",
            "94365 tensor(0.9983, device='cuda:0')\n",
            "94372 tensor(0.9989, device='cuda:0')\n",
            "94378 tensor(0.9999, device='cuda:0')\n",
            "94379 tensor(0.9995, device='cuda:0')\n",
            "94380 tensor(0.9996, device='cuda:0')\n",
            "94381 tensor(0.9980, device='cuda:0')\n",
            "94383 tensor(0.9908, device='cuda:0')\n",
            "94384 tensor(0.9964, device='cuda:0')\n",
            "94385 tensor(0.9980, device='cuda:0')\n",
            "94387 tensor(0.9969, device='cuda:0')\n",
            "94388 tensor(0.9997, device='cuda:0')\n",
            "94397 tensor(0.9940, device='cuda:0')\n",
            "94411 tensor(0.9998, device='cuda:0')\n",
            "94424 tensor(0.9992, device='cuda:0')\n",
            "94425 tensor(0.9971, device='cuda:0')\n",
            "94429 tensor(0.9981, device='cuda:0')\n",
            "94436 tensor(0.9965, device='cuda:0')\n",
            "94437 tensor(0.9985, device='cuda:0')\n",
            "94438 tensor(0.9997, device='cuda:0')\n",
            "94439 tensor(0.9941, device='cuda:0')\n",
            "94443 tensor(0.9962, device='cuda:0')\n",
            "94451 tensor(0.9929, device='cuda:0')\n",
            "94457 tensor(0.9966, device='cuda:0')\n",
            "94471 tensor(0.9958, device='cuda:0')\n",
            "94472 tensor(0.9960, device='cuda:0')\n",
            "94473 tensor(0.9926, device='cuda:0')\n",
            "94481 tensor(0.9919, device='cuda:0')\n",
            "94482 tensor(0.9951, device='cuda:0')\n",
            "94497 tensor(0.9957, device='cuda:0')\n",
            "94505 tensor(0.9965, device='cuda:0')\n",
            "94518 tensor(0.9988, device='cuda:0')\n",
            "94522 tensor(0.9997, device='cuda:0')\n",
            "94526 tensor(0.9995, device='cuda:0')\n",
            "94527 tensor(0.9939, device='cuda:0')\n",
            "94529 tensor(0.9997, device='cuda:0')\n",
            "94533 tensor(0.9984, device='cuda:0')\n",
            "94536 tensor(0.9930, device='cuda:0')\n",
            "94544 tensor(0.9977, device='cuda:0')\n",
            "94547 tensor(0.9996, device='cuda:0')\n",
            "94548 tensor(0.9997, device='cuda:0')\n",
            "94550 tensor(0.9922, device='cuda:0')\n",
            "94562 tensor(0.9984, device='cuda:0')\n",
            "94567 tensor(0.9998, device='cuda:0')\n",
            "94582 tensor(0.9915, device='cuda:0')\n",
            "94584 tensor(0.9986, device='cuda:0')\n",
            "94586 tensor(0.9974, device='cuda:0')\n",
            "94592 tensor(0.9984, device='cuda:0')\n",
            "94593 tensor(0.9995, device='cuda:0')\n",
            "94598 tensor(0.9996, device='cuda:0')\n",
            "94606 tensor(0.9964, device='cuda:0')\n",
            "94611 tensor(0.9982, device='cuda:0')\n",
            "94619 tensor(0.9972, device='cuda:0')\n",
            "94622 tensor(0.9951, device='cuda:0')\n",
            "94625 tensor(0.9997, device='cuda:0')\n",
            "94628 tensor(0.9976, device='cuda:0')\n",
            "94629 tensor(0.9979, device='cuda:0')\n",
            "94636 tensor(0.9909, device='cuda:0')\n",
            "94642 tensor(0.9958, device='cuda:0')\n",
            "94656 tensor(0.9992, device='cuda:0')\n",
            "94663 tensor(0.9931, device='cuda:0')\n",
            "94665 tensor(0.9907, device='cuda:0')\n",
            "94671 tensor(0.9916, device='cuda:0')\n",
            "94677 tensor(0.9980, device='cuda:0')\n",
            "94683 tensor(0.9928, device='cuda:0')\n",
            "94686 tensor(0.9966, device='cuda:0')\n",
            "94688 tensor(0.9989, device='cuda:0')\n",
            "94689 tensor(0.9991, device='cuda:0')\n",
            "94698 tensor(0.9968, device='cuda:0')\n",
            "94699 tensor(0.9976, device='cuda:0')\n",
            "94712 tensor(0.9986, device='cuda:0')\n",
            "94715 tensor(0.9975, device='cuda:0')\n",
            "94718 tensor(0.9962, device='cuda:0')\n",
            "94719 tensor(0.9986, device='cuda:0')\n",
            "94726 tensor(0.9975, device='cuda:0')\n",
            "94731 tensor(0.9982, device='cuda:0')\n",
            "94733 tensor(0.9958, device='cuda:0')\n",
            "94739 tensor(0.9992, device='cuda:0')\n",
            "94742 tensor(0.9932, device='cuda:0')\n",
            "94759 tensor(0.9992, device='cuda:0')\n",
            "94762 tensor(0.9997, device='cuda:0')\n",
            "94764 tensor(0.9977, device='cuda:0')\n",
            "94769 tensor(0.9971, device='cuda:0')\n",
            "94775 tensor(0.9950, device='cuda:0')\n",
            "94778 tensor(0.9988, device='cuda:0')\n",
            "94780 tensor(0.9976, device='cuda:0')\n",
            "94782 tensor(0.9971, device='cuda:0')\n",
            "94786 tensor(0.9982, device='cuda:0')\n",
            "94795 tensor(0.9997, device='cuda:0')\n",
            "94803 tensor(0.9902, device='cuda:0')\n",
            "94805 tensor(0.9911, device='cuda:0')\n",
            "94809 tensor(0.9994, device='cuda:0')\n",
            "94813 tensor(0.9928, device='cuda:0')\n",
            "94817 tensor(0.9956, device='cuda:0')\n",
            "94821 tensor(0.9934, device='cuda:0')\n",
            "94845 tensor(0.9988, device='cuda:0')\n",
            "94846 tensor(0.9930, device='cuda:0')\n",
            "94847 tensor(0.9935, device='cuda:0')\n",
            "94850 tensor(0.9956, device='cuda:0')\n",
            "94855 tensor(0.9996, device='cuda:0')\n",
            "94863 tensor(0.9995, device='cuda:0')\n",
            "94865 tensor(0.9997, device='cuda:0')\n",
            "94866 tensor(0.9990, device='cuda:0')\n",
            "94869 tensor(0.9941, device='cuda:0')\n",
            "94874 tensor(0.9985, device='cuda:0')\n",
            "94884 tensor(0.9993, device='cuda:0')\n",
            "94885 tensor(0.9990, device='cuda:0')\n",
            "94886 tensor(0.9923, device='cuda:0')\n",
            "94889 tensor(0.9992, device='cuda:0')\n",
            "94893 tensor(0.9998, device='cuda:0')\n",
            "94897 tensor(0.9991, device='cuda:0')\n",
            "94900 tensor(0.9998, device='cuda:0')\n",
            "94902 tensor(0.9989, device='cuda:0')\n",
            "94905 tensor(0.9984, device='cuda:0')\n",
            "94907 tensor(0.9971, device='cuda:0')\n",
            "94909 tensor(0.9985, device='cuda:0')\n",
            "94916 tensor(0.9998, device='cuda:0')\n",
            "94920 tensor(0.9984, device='cuda:0')\n",
            "94930 tensor(0.9999, device='cuda:0')\n",
            "94936 tensor(0.9957, device='cuda:0')\n",
            "94937 tensor(0.9998, device='cuda:0')\n",
            "94944 tensor(0.9929, device='cuda:0')\n",
            "94950 tensor(0.9997, device='cuda:0')\n",
            "94955 tensor(0.9933, device='cuda:0')\n",
            "94956 tensor(0.9990, device='cuda:0')\n",
            "94960 tensor(0.9979, device='cuda:0')\n",
            "94964 tensor(0.9973, device='cuda:0')\n",
            "94965 tensor(0.9905, device='cuda:0')\n",
            "94967 tensor(0.9992, device='cuda:0')\n",
            "94972 tensor(0.9930, device='cuda:0')\n",
            "94974 tensor(0.9989, device='cuda:0')\n",
            "94987 tensor(0.9922, device='cuda:0')\n",
            "94994 tensor(0.9990, device='cuda:0')\n",
            "94998 tensor(0.9994, device='cuda:0')\n",
            "95002 tensor(0.9999, device='cuda:0')\n",
            "95005 tensor(0.9913, device='cuda:0')\n",
            "95007 tensor(0.9928, device='cuda:0')\n",
            "95014 tensor(0.9944, device='cuda:0')\n",
            "95015 tensor(0.9967, device='cuda:0')\n",
            "95033 tensor(0.9954, device='cuda:0')\n",
            "95036 tensor(0.9951, device='cuda:0')\n",
            "95037 tensor(0.9995, device='cuda:0')\n",
            "95039 tensor(0.9918, device='cuda:0')\n",
            "95047 tensor(0.9973, device='cuda:0')\n",
            "95049 tensor(0.9995, device='cuda:0')\n",
            "95051 tensor(0.9995, device='cuda:0')\n",
            "95053 tensor(0.9950, device='cuda:0')\n",
            "95056 tensor(0.9913, device='cuda:0')\n",
            "95059 tensor(0.9997, device='cuda:0')\n",
            "95060 tensor(0.9904, device='cuda:0')\n",
            "95063 tensor(0.9995, device='cuda:0')\n",
            "95070 tensor(0.9947, device='cuda:0')\n",
            "95076 tensor(0.9984, device='cuda:0')\n",
            "95077 tensor(0.9993, device='cuda:0')\n",
            "95095 tensor(0.9929, device='cuda:0')\n",
            "95101 tensor(0.9999, device='cuda:0')\n",
            "95102 tensor(0.9957, device='cuda:0')\n",
            "95104 tensor(0.9929, device='cuda:0')\n",
            "95105 tensor(0.9981, device='cuda:0')\n",
            "95108 tensor(0.9979, device='cuda:0')\n",
            "95109 tensor(0.9991, device='cuda:0')\n",
            "95116 tensor(0.9977, device='cuda:0')\n",
            "95131 tensor(0.9923, device='cuda:0')\n",
            "95138 tensor(0.9941, device='cuda:0')\n",
            "95144 tensor(0.9927, device='cuda:0')\n",
            "95171 tensor(0.9993, device='cuda:0')\n",
            "95173 tensor(0.9943, device='cuda:0')\n",
            "95174 tensor(0.9942, device='cuda:0')\n",
            "95175 tensor(0.9995, device='cuda:0')\n",
            "95176 tensor(0.9919, device='cuda:0')\n",
            "95179 tensor(0.9941, device='cuda:0')\n",
            "95189 tensor(0.9940, device='cuda:0')\n",
            "95196 tensor(0.9997, device='cuda:0')\n",
            "95197 tensor(0.9990, device='cuda:0')\n",
            "95202 tensor(0.9953, device='cuda:0')\n",
            "95209 tensor(0.9998, device='cuda:0')\n",
            "95221 tensor(0.9938, device='cuda:0')\n",
            "95223 tensor(0.9978, device='cuda:0')\n",
            "95226 tensor(0.9928, device='cuda:0')\n",
            "95229 tensor(0.9966, device='cuda:0')\n",
            "95235 tensor(0.9903, device='cuda:0')\n",
            "95239 tensor(0.9991, device='cuda:0')\n",
            "95241 tensor(0.9992, device='cuda:0')\n",
            "95245 tensor(0.9998, device='cuda:0')\n",
            "95248 tensor(0.9992, device='cuda:0')\n",
            "95259 tensor(0.9996, device='cuda:0')\n",
            "95264 tensor(0.9974, device='cuda:0')\n",
            "95265 tensor(0.9938, device='cuda:0')\n",
            "95268 tensor(0.9906, device='cuda:0')\n",
            "95273 tensor(0.9942, device='cuda:0')\n",
            "95278 tensor(0.9990, device='cuda:0')\n",
            "95280 tensor(0.9924, device='cuda:0')\n",
            "95285 tensor(0.9987, device='cuda:0')\n",
            "95303 tensor(0.9987, device='cuda:0')\n",
            "95307 tensor(0.9959, device='cuda:0')\n",
            "95335 tensor(0.9903, device='cuda:0')\n",
            "95337 tensor(0.9909, device='cuda:0')\n",
            "95339 tensor(0.9994, device='cuda:0')\n",
            "95340 tensor(0.9967, device='cuda:0')\n",
            "95343 tensor(0.9929, device='cuda:0')\n",
            "95347 tensor(0.9947, device='cuda:0')\n",
            "95349 tensor(0.9952, device='cuda:0')\n",
            "95350 tensor(0.9957, device='cuda:0')\n",
            "95362 tensor(0.9949, device='cuda:0')\n",
            "95364 tensor(0.9934, device='cuda:0')\n",
            "95365 tensor(0.9970, device='cuda:0')\n",
            "95367 tensor(0.9998, device='cuda:0')\n",
            "95369 tensor(0.9981, device='cuda:0')\n",
            "95370 tensor(0.9988, device='cuda:0')\n",
            "95379 tensor(0.9981, device='cuda:0')\n",
            "95390 tensor(0.9988, device='cuda:0')\n",
            "95392 tensor(0.9963, device='cuda:0')\n",
            "95401 tensor(0.9986, device='cuda:0')\n",
            "95405 tensor(0.9976, device='cuda:0')\n",
            "95406 tensor(0.9976, device='cuda:0')\n",
            "95409 tensor(0.9990, device='cuda:0')\n",
            "95421 tensor(0.9996, device='cuda:0')\n",
            "95424 tensor(0.9998, device='cuda:0')\n",
            "95425 tensor(0.9994, device='cuda:0')\n",
            "95436 tensor(0.9973, device='cuda:0')\n",
            "95437 tensor(0.9958, device='cuda:0')\n",
            "95440 tensor(0.9996, device='cuda:0')\n",
            "95442 tensor(0.9995, device='cuda:0')\n",
            "95444 tensor(0.9969, device='cuda:0')\n",
            "95451 tensor(0.9971, device='cuda:0')\n",
            "95452 tensor(0.9992, device='cuda:0')\n",
            "95459 tensor(0.9917, device='cuda:0')\n",
            "95461 tensor(0.9925, device='cuda:0')\n",
            "95465 tensor(0.9986, device='cuda:0')\n",
            "95466 tensor(0.9915, device='cuda:0')\n",
            "95476 tensor(0.9982, device='cuda:0')\n",
            "95482 tensor(0.9995, device='cuda:0')\n",
            "95484 tensor(0.9996, device='cuda:0')\n",
            "95492 tensor(0.9956, device='cuda:0')\n",
            "95493 tensor(0.9997, device='cuda:0')\n",
            "95494 tensor(0.9996, device='cuda:0')\n",
            "95499 tensor(0.9997, device='cuda:0')\n",
            "95501 tensor(0.9988, device='cuda:0')\n",
            "95506 tensor(0.9974, device='cuda:0')\n",
            "95511 tensor(0.9960, device='cuda:0')\n",
            "95513 tensor(0.9987, device='cuda:0')\n",
            "95528 tensor(0.9934, device='cuda:0')\n",
            "95534 tensor(0.9962, device='cuda:0')\n",
            "95545 tensor(0.9985, device='cuda:0')\n",
            "95546 tensor(0.9997, device='cuda:0')\n",
            "95552 tensor(0.9942, device='cuda:0')\n",
            "95558 tensor(0.9986, device='cuda:0')\n",
            "95560 tensor(0.9946, device='cuda:0')\n",
            "95573 tensor(0.9983, device='cuda:0')\n",
            "95575 tensor(0.9994, device='cuda:0')\n",
            "95577 tensor(0.9961, device='cuda:0')\n",
            "95580 tensor(0.9998, device='cuda:0')\n",
            "95584 tensor(0.9944, device='cuda:0')\n",
            "95590 tensor(0.9966, device='cuda:0')\n",
            "95594 tensor(0.9923, device='cuda:0')\n",
            "95597 tensor(0.9944, device='cuda:0')\n",
            "95601 tensor(0.9953, device='cuda:0')\n",
            "95610 tensor(0.9990, device='cuda:0')\n",
            "95614 tensor(0.9983, device='cuda:0')\n",
            "95630 tensor(0.9980, device='cuda:0')\n",
            "95637 tensor(0.9983, device='cuda:0')\n",
            "95639 tensor(0.9982, device='cuda:0')\n",
            "95641 tensor(0.9944, device='cuda:0')\n",
            "95649 tensor(0.9957, device='cuda:0')\n",
            "95650 tensor(0.9997, device='cuda:0')\n",
            "95658 tensor(0.9923, device='cuda:0')\n",
            "95669 tensor(0.9936, device='cuda:0')\n",
            "95676 tensor(0.9994, device='cuda:0')\n",
            "95682 tensor(0.9912, device='cuda:0')\n",
            "95683 tensor(0.9963, device='cuda:0')\n",
            "95687 tensor(0.9974, device='cuda:0')\n",
            "95702 tensor(0.9953, device='cuda:0')\n",
            "95712 tensor(0.9978, device='cuda:0')\n",
            "95717 tensor(0.9963, device='cuda:0')\n",
            "95718 tensor(0.9903, device='cuda:0')\n",
            "95724 tensor(0.9993, device='cuda:0')\n",
            "95726 tensor(0.9987, device='cuda:0')\n",
            "95728 tensor(0.9998, device='cuda:0')\n",
            "95731 tensor(0.9975, device='cuda:0')\n",
            "95733 tensor(0.9970, device='cuda:0')\n",
            "95734 tensor(0.9974, device='cuda:0')\n",
            "95739 tensor(0.9936, device='cuda:0')\n",
            "95754 tensor(0.9995, device='cuda:0')\n",
            "95756 tensor(0.9927, device='cuda:0')\n",
            "95757 tensor(0.9996, device='cuda:0')\n",
            "95781 tensor(0.9907, device='cuda:0')\n",
            "95786 tensor(0.9971, device='cuda:0')\n",
            "95791 tensor(0.9927, device='cuda:0')\n",
            "95792 tensor(0.9998, device='cuda:0')\n",
            "95797 tensor(0.9993, device='cuda:0')\n",
            "95800 tensor(0.9960, device='cuda:0')\n",
            "95821 tensor(0.9988, device='cuda:0')\n",
            "95823 tensor(0.9992, device='cuda:0')\n",
            "95826 tensor(0.9979, device='cuda:0')\n",
            "95841 tensor(0.9930, device='cuda:0')\n",
            "95842 tensor(0.9937, device='cuda:0')\n",
            "95850 tensor(0.9968, device='cuda:0')\n",
            "95851 tensor(0.9965, device='cuda:0')\n",
            "95854 tensor(0.9996, device='cuda:0')\n",
            "95858 tensor(0.9980, device='cuda:0')\n",
            "95859 tensor(0.9988, device='cuda:0')\n",
            "95862 tensor(0.9999, device='cuda:0')\n",
            "95863 tensor(0.9981, device='cuda:0')\n",
            "95866 tensor(0.9940, device='cuda:0')\n",
            "95869 tensor(0.9984, device='cuda:0')\n",
            "95875 tensor(0.9996, device='cuda:0')\n",
            "95882 tensor(0.9909, device='cuda:0')\n",
            "95887 tensor(0.9902, device='cuda:0')\n",
            "95897 tensor(0.9959, device='cuda:0')\n",
            "95900 tensor(0.9908, device='cuda:0')\n",
            "95922 tensor(0.9970, device='cuda:0')\n",
            "95924 tensor(0.9929, device='cuda:0')\n",
            "95932 tensor(0.9917, device='cuda:0')\n",
            "95935 tensor(0.9921, device='cuda:0')\n",
            "95936 tensor(0.9963, device='cuda:0')\n",
            "95942 tensor(1.0000, device='cuda:0')\n",
            "95954 tensor(0.9994, device='cuda:0')\n",
            "95959 tensor(0.9942, device='cuda:0')\n",
            "95961 tensor(0.9982, device='cuda:0')\n",
            "95972 tensor(0.9937, device='cuda:0')\n",
            "95978 tensor(0.9999, device='cuda:0')\n",
            "95982 tensor(0.9907, device='cuda:0')\n",
            "95990 tensor(0.9917, device='cuda:0')\n",
            "95991 tensor(0.9915, device='cuda:0')\n",
            "95995 tensor(0.9993, device='cuda:0')\n",
            "95997 tensor(0.9957, device='cuda:0')\n",
            "95999 tensor(0.9990, device='cuda:0')\n",
            "96004 tensor(0.9935, device='cuda:0')\n",
            "96011 tensor(0.9988, device='cuda:0')\n",
            "96016 tensor(0.9985, device='cuda:0')\n",
            "96026 tensor(0.9975, device='cuda:0')\n",
            "96028 tensor(0.9997, device='cuda:0')\n",
            "96036 tensor(0.9925, device='cuda:0')\n",
            "96041 tensor(0.9958, device='cuda:0')\n",
            "96044 tensor(0.9981, device='cuda:0')\n",
            "96047 tensor(0.9994, device='cuda:0')\n",
            "96050 tensor(0.9987, device='cuda:0')\n",
            "96052 tensor(0.9983, device='cuda:0')\n",
            "96054 tensor(0.9990, device='cuda:0')\n",
            "96055 tensor(0.9995, device='cuda:0')\n",
            "96061 tensor(0.9998, device='cuda:0')\n",
            "96062 tensor(0.9998, device='cuda:0')\n",
            "96071 tensor(0.9992, device='cuda:0')\n",
            "96075 tensor(0.9909, device='cuda:0')\n",
            "96084 tensor(0.9988, device='cuda:0')\n",
            "96095 tensor(0.9966, device='cuda:0')\n",
            "96097 tensor(0.9993, device='cuda:0')\n",
            "96104 tensor(0.9962, device='cuda:0')\n",
            "96112 tensor(0.9902, device='cuda:0')\n",
            "96117 tensor(0.9903, device='cuda:0')\n",
            "96118 tensor(0.9934, device='cuda:0')\n",
            "96119 tensor(0.9994, device='cuda:0')\n",
            "96123 tensor(0.9972, device='cuda:0')\n",
            "96136 tensor(0.9981, device='cuda:0')\n",
            "96149 tensor(0.9992, device='cuda:0')\n",
            "96150 tensor(0.9978, device='cuda:0')\n",
            "96152 tensor(0.9994, device='cuda:0')\n",
            "96155 tensor(0.9947, device='cuda:0')\n",
            "96159 tensor(0.9979, device='cuda:0')\n",
            "96161 tensor(0.9981, device='cuda:0')\n",
            "96165 tensor(0.9969, device='cuda:0')\n",
            "96175 tensor(0.9944, device='cuda:0')\n",
            "96190 tensor(0.9963, device='cuda:0')\n",
            "96192 tensor(0.9983, device='cuda:0')\n",
            "96201 tensor(0.9994, device='cuda:0')\n",
            "96203 tensor(0.9984, device='cuda:0')\n",
            "96205 tensor(0.9998, device='cuda:0')\n",
            "96212 tensor(0.9983, device='cuda:0')\n",
            "96219 tensor(0.9918, device='cuda:0')\n",
            "96226 tensor(0.9959, device='cuda:0')\n",
            "96237 tensor(0.9969, device='cuda:0')\n",
            "96238 tensor(0.9973, device='cuda:0')\n",
            "96247 tensor(0.9986, device='cuda:0')\n",
            "96252 tensor(0.9991, device='cuda:0')\n",
            "96257 tensor(0.9990, device='cuda:0')\n",
            "96268 tensor(0.9985, device='cuda:0')\n",
            "96277 tensor(0.9976, device='cuda:0')\n",
            "96281 tensor(0.9908, device='cuda:0')\n",
            "96282 tensor(0.9989, device='cuda:0')\n",
            "96290 tensor(0.9996, device='cuda:0')\n",
            "96296 tensor(0.9985, device='cuda:0')\n",
            "96302 tensor(0.9997, device='cuda:0')\n",
            "96316 tensor(0.9946, device='cuda:0')\n",
            "96321 tensor(0.9968, device='cuda:0')\n",
            "96324 tensor(0.9969, device='cuda:0')\n",
            "96331 tensor(0.9988, device='cuda:0')\n",
            "96333 tensor(0.9985, device='cuda:0')\n",
            "96334 tensor(0.9991, device='cuda:0')\n",
            "96339 tensor(0.9934, device='cuda:0')\n",
            "96340 tensor(0.9945, device='cuda:0')\n",
            "96341 tensor(0.9976, device='cuda:0')\n",
            "96342 tensor(0.9914, device='cuda:0')\n",
            "96346 tensor(0.9999, device='cuda:0')\n",
            "96348 tensor(0.9951, device='cuda:0')\n",
            "96352 tensor(0.9997, device='cuda:0')\n",
            "96379 tensor(0.9986, device='cuda:0')\n",
            "96381 tensor(0.9907, device='cuda:0')\n",
            "96384 tensor(0.9999, device='cuda:0')\n",
            "96391 tensor(0.9900, device='cuda:0')\n",
            "96393 tensor(0.9972, device='cuda:0')\n",
            "96396 tensor(0.9954, device='cuda:0')\n",
            "96406 tensor(0.9941, device='cuda:0')\n",
            "96408 tensor(0.9989, device='cuda:0')\n",
            "96413 tensor(0.9997, device='cuda:0')\n",
            "96444 tensor(0.9987, device='cuda:0')\n",
            "96449 tensor(0.9974, device='cuda:0')\n",
            "96458 tensor(0.9984, device='cuda:0')\n",
            "96464 tensor(0.9978, device='cuda:0')\n",
            "96470 tensor(0.9966, device='cuda:0')\n",
            "96471 tensor(0.9998, device='cuda:0')\n",
            "96472 tensor(0.9994, device='cuda:0')\n",
            "96473 tensor(0.9907, device='cuda:0')\n",
            "96474 tensor(0.9993, device='cuda:0')\n",
            "96486 tensor(0.9939, device='cuda:0')\n",
            "96489 tensor(0.9990, device='cuda:0')\n",
            "96492 tensor(0.9926, device='cuda:0')\n",
            "96497 tensor(0.9946, device='cuda:0')\n",
            "96507 tensor(0.9987, device='cuda:0')\n",
            "96511 tensor(0.9990, device='cuda:0')\n",
            "96518 tensor(0.9993, device='cuda:0')\n",
            "96522 tensor(0.9964, device='cuda:0')\n",
            "96525 tensor(0.9925, device='cuda:0')\n",
            "96526 tensor(0.9988, device='cuda:0')\n",
            "96527 tensor(0.9997, device='cuda:0')\n",
            "96528 tensor(0.9998, device='cuda:0')\n",
            "96536 tensor(0.9986, device='cuda:0')\n",
            "96537 tensor(0.9905, device='cuda:0')\n",
            "96540 tensor(0.9969, device='cuda:0')\n",
            "96545 tensor(0.9956, device='cuda:0')\n",
            "96556 tensor(0.9985, device='cuda:0')\n",
            "96560 tensor(0.9907, device='cuda:0')\n",
            "96562 tensor(0.9943, device='cuda:0')\n",
            "96565 tensor(0.9984, device='cuda:0')\n",
            "96567 tensor(0.9971, device='cuda:0')\n",
            "96568 tensor(0.9906, device='cuda:0')\n",
            "96570 tensor(0.9965, device='cuda:0')\n",
            "96574 tensor(0.9997, device='cuda:0')\n",
            "96584 tensor(0.9998, device='cuda:0')\n",
            "96588 tensor(0.9963, device='cuda:0')\n",
            "96598 tensor(0.9997, device='cuda:0')\n",
            "96601 tensor(0.9948, device='cuda:0')\n",
            "96603 tensor(0.9979, device='cuda:0')\n",
            "96605 tensor(0.9911, device='cuda:0')\n",
            "96613 tensor(0.9983, device='cuda:0')\n",
            "96623 tensor(0.9967, device='cuda:0')\n",
            "96630 tensor(0.9958, device='cuda:0')\n",
            "96633 tensor(0.9965, device='cuda:0')\n",
            "96634 tensor(0.9949, device='cuda:0')\n",
            "96644 tensor(0.9927, device='cuda:0')\n",
            "96646 tensor(0.9967, device='cuda:0')\n",
            "96650 tensor(0.9984, device='cuda:0')\n",
            "96655 tensor(0.9986, device='cuda:0')\n",
            "96659 tensor(0.9995, device='cuda:0')\n",
            "96665 tensor(0.9902, device='cuda:0')\n",
            "96667 tensor(0.9998, device='cuda:0')\n",
            "96669 tensor(0.9935, device='cuda:0')\n",
            "96670 tensor(0.9979, device='cuda:0')\n",
            "96675 tensor(0.9948, device='cuda:0')\n",
            "96678 tensor(0.9990, device='cuda:0')\n",
            "96680 tensor(0.9993, device='cuda:0')\n",
            "96684 tensor(0.9996, device='cuda:0')\n",
            "96690 tensor(0.9943, device='cuda:0')\n",
            "96704 tensor(0.9932, device='cuda:0')\n",
            "96706 tensor(0.9999, device='cuda:0')\n",
            "96716 tensor(0.9939, device='cuda:0')\n",
            "96726 tensor(0.9931, device='cuda:0')\n",
            "96728 tensor(0.9959, device='cuda:0')\n",
            "96731 tensor(0.9992, device='cuda:0')\n",
            "96732 tensor(0.9995, device='cuda:0')\n",
            "96734 tensor(0.9990, device='cuda:0')\n",
            "96743 tensor(0.9917, device='cuda:0')\n",
            "96745 tensor(0.9999, device='cuda:0')\n",
            "96753 tensor(0.9969, device='cuda:0')\n",
            "96758 tensor(0.9974, device='cuda:0')\n",
            "96775 tensor(0.9917, device='cuda:0')\n",
            "96789 tensor(0.9968, device='cuda:0')\n",
            "96793 tensor(0.9984, device='cuda:0')\n",
            "96795 tensor(0.9942, device='cuda:0')\n",
            "96798 tensor(0.9918, device='cuda:0')\n",
            "96801 tensor(0.9917, device='cuda:0')\n",
            "96802 tensor(0.9914, device='cuda:0')\n",
            "96807 tensor(0.9999, device='cuda:0')\n",
            "96813 tensor(0.9972, device='cuda:0')\n",
            "96818 tensor(0.9937, device='cuda:0')\n",
            "96821 tensor(0.9969, device='cuda:0')\n",
            "96823 tensor(0.9993, device='cuda:0')\n",
            "96828 tensor(0.9996, device='cuda:0')\n",
            "96845 tensor(0.9966, device='cuda:0')\n",
            "96849 tensor(0.9961, device='cuda:0')\n",
            "96854 tensor(0.9977, device='cuda:0')\n",
            "96856 tensor(0.9928, device='cuda:0')\n",
            "96859 tensor(0.9989, device='cuda:0')\n",
            "96864 tensor(0.9920, device='cuda:0')\n",
            "96874 tensor(0.9911, device='cuda:0')\n",
            "96878 tensor(0.9994, device='cuda:0')\n",
            "96882 tensor(0.9974, device='cuda:0')\n",
            "96884 tensor(0.9975, device='cuda:0')\n",
            "96885 tensor(0.9961, device='cuda:0')\n",
            "96887 tensor(0.9994, device='cuda:0')\n",
            "96899 tensor(0.9947, device='cuda:0')\n",
            "96903 tensor(0.9978, device='cuda:0')\n",
            "96911 tensor(0.9921, device='cuda:0')\n",
            "96913 tensor(0.9972, device='cuda:0')\n",
            "96917 tensor(0.9978, device='cuda:0')\n",
            "96918 tensor(0.9915, device='cuda:0')\n",
            "96921 tensor(0.9934, device='cuda:0')\n",
            "96926 tensor(0.9998, device='cuda:0')\n",
            "96929 tensor(0.9928, device='cuda:0')\n",
            "96936 tensor(0.9989, device='cuda:0')\n",
            "96945 tensor(0.9904, device='cuda:0')\n",
            "96948 tensor(0.9997, device='cuda:0')\n",
            "96956 tensor(0.9993, device='cuda:0')\n",
            "96965 tensor(0.9992, device='cuda:0')\n",
            "96968 tensor(0.9988, device='cuda:0')\n",
            "96970 tensor(0.9999, device='cuda:0')\n",
            "96972 tensor(0.9924, device='cuda:0')\n",
            "96979 tensor(0.9974, device='cuda:0')\n",
            "96983 tensor(0.9983, device='cuda:0')\n",
            "96986 tensor(1.0000, device='cuda:0')\n",
            "96990 tensor(0.9967, device='cuda:0')\n",
            "97001 tensor(0.9991, device='cuda:0')\n",
            "97003 tensor(0.9987, device='cuda:0')\n",
            "97005 tensor(0.9912, device='cuda:0')\n",
            "97006 tensor(0.9984, device='cuda:0')\n",
            "97007 tensor(0.9961, device='cuda:0')\n",
            "97017 tensor(0.9980, device='cuda:0')\n",
            "97020 tensor(0.9952, device='cuda:0')\n",
            "97023 tensor(0.9987, device='cuda:0')\n",
            "97031 tensor(0.9920, device='cuda:0')\n",
            "97037 tensor(0.9929, device='cuda:0')\n",
            "97038 tensor(0.9994, device='cuda:0')\n",
            "97044 tensor(0.9973, device='cuda:0')\n",
            "97045 tensor(0.9931, device='cuda:0')\n",
            "97047 tensor(0.9928, device='cuda:0')\n",
            "97061 tensor(0.9994, device='cuda:0')\n",
            "97063 tensor(0.9916, device='cuda:0')\n",
            "97066 tensor(0.9955, device='cuda:0')\n",
            "97070 tensor(0.9979, device='cuda:0')\n",
            "97072 tensor(0.9902, device='cuda:0')\n",
            "97076 tensor(0.9993, device='cuda:0')\n",
            "97079 tensor(0.9987, device='cuda:0')\n",
            "97081 tensor(0.9999, device='cuda:0')\n",
            "97083 tensor(0.9943, device='cuda:0')\n",
            "97087 tensor(0.9989, device='cuda:0')\n",
            "97088 tensor(0.9974, device='cuda:0')\n",
            "97089 tensor(0.9965, device='cuda:0')\n",
            "97091 tensor(0.9976, device='cuda:0')\n",
            "97093 tensor(0.9948, device='cuda:0')\n",
            "97109 tensor(0.9982, device='cuda:0')\n",
            "97110 tensor(0.9999, device='cuda:0')\n",
            "97116 tensor(0.9970, device='cuda:0')\n",
            "97117 tensor(0.9998, device='cuda:0')\n",
            "97118 tensor(0.9959, device='cuda:0')\n",
            "97122 tensor(0.9985, device='cuda:0')\n",
            "97125 tensor(0.9988, device='cuda:0')\n",
            "97126 tensor(0.9910, device='cuda:0')\n",
            "97142 tensor(0.9994, device='cuda:0')\n",
            "97144 tensor(0.9960, device='cuda:0')\n",
            "97148 tensor(0.9980, device='cuda:0')\n",
            "97150 tensor(0.9994, device='cuda:0')\n",
            "97153 tensor(0.9985, device='cuda:0')\n",
            "97165 tensor(0.9969, device='cuda:0')\n",
            "97168 tensor(0.9966, device='cuda:0')\n",
            "97173 tensor(0.9903, device='cuda:0')\n",
            "97177 tensor(0.9935, device='cuda:0')\n",
            "97188 tensor(0.9940, device='cuda:0')\n",
            "97191 tensor(0.9999, device='cuda:0')\n",
            "97194 tensor(0.9902, device='cuda:0')\n",
            "97198 tensor(0.9907, device='cuda:0')\n",
            "97220 tensor(0.9953, device='cuda:0')\n",
            "97223 tensor(0.9965, device='cuda:0')\n",
            "97227 tensor(0.9999, device='cuda:0')\n",
            "97232 tensor(0.9998, device='cuda:0')\n",
            "97234 tensor(0.9924, device='cuda:0')\n",
            "97235 tensor(0.9996, device='cuda:0')\n",
            "97236 tensor(0.9929, device='cuda:0')\n",
            "97237 tensor(0.9946, device='cuda:0')\n",
            "97238 tensor(0.9998, device='cuda:0')\n",
            "97240 tensor(0.9988, device='cuda:0')\n",
            "97241 tensor(0.9994, device='cuda:0')\n",
            "97253 tensor(0.9935, device='cuda:0')\n",
            "97254 tensor(0.9935, device='cuda:0')\n",
            "97259 tensor(0.9947, device='cuda:0')\n",
            "97263 tensor(0.9994, device='cuda:0')\n",
            "97265 tensor(0.9998, device='cuda:0')\n",
            "97273 tensor(0.9984, device='cuda:0')\n",
            "97274 tensor(0.9906, device='cuda:0')\n",
            "97277 tensor(0.9997, device='cuda:0')\n",
            "97285 tensor(0.9983, device='cuda:0')\n",
            "97299 tensor(0.9965, device='cuda:0')\n",
            "97300 tensor(0.9944, device='cuda:0')\n",
            "97313 tensor(0.9998, device='cuda:0')\n",
            "97320 tensor(0.9979, device='cuda:0')\n",
            "97323 tensor(0.9965, device='cuda:0')\n",
            "97328 tensor(0.9974, device='cuda:0')\n",
            "97332 tensor(0.9921, device='cuda:0')\n",
            "97335 tensor(0.9973, device='cuda:0')\n",
            "97340 tensor(0.9970, device='cuda:0')\n",
            "97341 tensor(0.9995, device='cuda:0')\n",
            "97342 tensor(0.9996, device='cuda:0')\n",
            "97346 tensor(0.9941, device='cuda:0')\n",
            "97357 tensor(0.9914, device='cuda:0')\n",
            "97369 tensor(0.9914, device='cuda:0')\n",
            "97370 tensor(0.9992, device='cuda:0')\n",
            "97373 tensor(0.9991, device='cuda:0')\n",
            "97380 tensor(0.9987, device='cuda:0')\n",
            "97385 tensor(0.9997, device='cuda:0')\n",
            "97400 tensor(0.9959, device='cuda:0')\n",
            "97403 tensor(0.9985, device='cuda:0')\n",
            "97404 tensor(0.9991, device='cuda:0')\n",
            "97405 tensor(0.9992, device='cuda:0')\n",
            "97407 tensor(0.9990, device='cuda:0')\n",
            "97415 tensor(0.9967, device='cuda:0')\n",
            "97418 tensor(0.9941, device='cuda:0')\n",
            "97424 tensor(0.9998, device='cuda:0')\n",
            "97436 tensor(0.9973, device='cuda:0')\n",
            "97440 tensor(0.9973, device='cuda:0')\n",
            "97454 tensor(0.9980, device='cuda:0')\n",
            "97455 tensor(0.9997, device='cuda:0')\n",
            "97465 tensor(0.9991, device='cuda:0')\n",
            "97468 tensor(0.9993, device='cuda:0')\n",
            "97479 tensor(0.9994, device='cuda:0')\n",
            "97485 tensor(0.9991, device='cuda:0')\n",
            "97491 tensor(0.9905, device='cuda:0')\n",
            "97494 tensor(0.9946, device='cuda:0')\n",
            "97499 tensor(0.9977, device='cuda:0')\n",
            "97500 tensor(0.9907, device='cuda:0')\n",
            "97502 tensor(0.9902, device='cuda:0')\n",
            "97503 tensor(0.9921, device='cuda:0')\n",
            "97506 tensor(0.9990, device='cuda:0')\n",
            "97508 tensor(0.9983, device='cuda:0')\n",
            "97510 tensor(0.9986, device='cuda:0')\n",
            "97517 tensor(0.9931, device='cuda:0')\n",
            "97518 tensor(0.9953, device='cuda:0')\n",
            "97535 tensor(0.9997, device='cuda:0')\n",
            "97540 tensor(0.9981, device='cuda:0')\n",
            "97544 tensor(0.9919, device='cuda:0')\n",
            "97547 tensor(0.9916, device='cuda:0')\n",
            "97554 tensor(0.9992, device='cuda:0')\n",
            "97587 tensor(0.9906, device='cuda:0')\n",
            "97588 tensor(0.9998, device='cuda:0')\n",
            "97609 tensor(0.9999, device='cuda:0')\n",
            "97615 tensor(0.9977, device='cuda:0')\n",
            "97623 tensor(0.9995, device='cuda:0')\n",
            "97635 tensor(0.9933, device='cuda:0')\n",
            "97639 tensor(0.9982, device='cuda:0')\n",
            "97648 tensor(0.9919, device='cuda:0')\n",
            "97649 tensor(0.9966, device='cuda:0')\n",
            "97650 tensor(0.9948, device='cuda:0')\n",
            "97657 tensor(0.9940, device='cuda:0')\n",
            "97666 tensor(0.9988, device='cuda:0')\n",
            "97669 tensor(0.9988, device='cuda:0')\n",
            "97673 tensor(0.9958, device='cuda:0')\n",
            "97677 tensor(0.9927, device='cuda:0')\n",
            "97681 tensor(0.9982, device='cuda:0')\n",
            "97688 tensor(0.9997, device='cuda:0')\n",
            "97696 tensor(0.9996, device='cuda:0')\n",
            "97697 tensor(0.9973, device='cuda:0')\n",
            "97707 tensor(0.9940, device='cuda:0')\n",
            "97709 tensor(0.9906, device='cuda:0')\n",
            "97719 tensor(0.9995, device='cuda:0')\n",
            "97720 tensor(0.9938, device='cuda:0')\n",
            "97739 tensor(0.9997, device='cuda:0')\n",
            "97742 tensor(0.9958, device='cuda:0')\n",
            "97743 tensor(0.9912, device='cuda:0')\n",
            "97748 tensor(0.9926, device='cuda:0')\n",
            "97754 tensor(0.9976, device='cuda:0')\n",
            "97760 tensor(0.9927, device='cuda:0')\n",
            "97762 tensor(0.9995, device='cuda:0')\n",
            "97763 tensor(0.9918, device='cuda:0')\n",
            "97774 tensor(0.9999, device='cuda:0')\n",
            "97775 tensor(0.9956, device='cuda:0')\n",
            "97777 tensor(0.9957, device='cuda:0')\n",
            "97783 tensor(0.9969, device='cuda:0')\n",
            "97799 tensor(0.9988, device='cuda:0')\n",
            "97800 tensor(0.9995, device='cuda:0')\n",
            "97806 tensor(0.9957, device='cuda:0')\n",
            "97808 tensor(0.9999, device='cuda:0')\n",
            "97809 tensor(0.9977, device='cuda:0')\n",
            "97833 tensor(0.9995, device='cuda:0')\n",
            "97834 tensor(0.9991, device='cuda:0')\n",
            "97835 tensor(0.9933, device='cuda:0')\n",
            "97837 tensor(0.9960, device='cuda:0')\n",
            "97839 tensor(0.9980, device='cuda:0')\n",
            "97842 tensor(0.9913, device='cuda:0')\n",
            "97846 tensor(0.9981, device='cuda:0')\n",
            "97848 tensor(0.9997, device='cuda:0')\n",
            "97853 tensor(0.9992, device='cuda:0')\n",
            "97857 tensor(0.9985, device='cuda:0')\n",
            "97859 tensor(0.9907, device='cuda:0')\n",
            "97875 tensor(0.9995, device='cuda:0')\n",
            "97881 tensor(0.9906, device='cuda:0')\n",
            "97885 tensor(0.9985, device='cuda:0')\n",
            "97887 tensor(0.9909, device='cuda:0')\n",
            "97890 tensor(0.9981, device='cuda:0')\n",
            "97897 tensor(0.9947, device='cuda:0')\n",
            "97900 tensor(0.9993, device='cuda:0')\n",
            "97904 tensor(0.9998, device='cuda:0')\n",
            "97918 tensor(0.9975, device='cuda:0')\n",
            "97919 tensor(0.9996, device='cuda:0')\n",
            "97921 tensor(0.9985, device='cuda:0')\n",
            "97926 tensor(0.9995, device='cuda:0')\n",
            "97933 tensor(0.9992, device='cuda:0')\n",
            "97937 tensor(0.9994, device='cuda:0')\n",
            "97940 tensor(0.9936, device='cuda:0')\n",
            "97942 tensor(0.9961, device='cuda:0')\n",
            "97957 tensor(0.9956, device='cuda:0')\n",
            "97960 tensor(0.9902, device='cuda:0')\n",
            "97962 tensor(0.9935, device='cuda:0')\n",
            "97970 tensor(0.9989, device='cuda:0')\n",
            "97974 tensor(0.9902, device='cuda:0')\n",
            "97975 tensor(0.9990, device='cuda:0')\n",
            "97991 tensor(0.9967, device='cuda:0')\n",
            "97993 tensor(0.9935, device='cuda:0')\n",
            "98000 tensor(0.9904, device='cuda:0')\n",
            "98004 tensor(0.9988, device='cuda:0')\n",
            "98005 tensor(0.9917, device='cuda:0')\n",
            "98018 tensor(0.9936, device='cuda:0')\n",
            "98023 tensor(0.9993, device='cuda:0')\n",
            "98028 tensor(0.9940, device='cuda:0')\n",
            "98041 tensor(0.9952, device='cuda:0')\n",
            "98043 tensor(0.9996, device='cuda:0')\n",
            "98056 tensor(0.9952, device='cuda:0')\n",
            "98066 tensor(0.9908, device='cuda:0')\n",
            "98081 tensor(0.9991, device='cuda:0')\n",
            "98082 tensor(0.9970, device='cuda:0')\n",
            "98090 tensor(0.9991, device='cuda:0')\n",
            "98093 tensor(0.9923, device='cuda:0')\n",
            "98097 tensor(0.9917, device='cuda:0')\n",
            "98103 tensor(0.9904, device='cuda:0')\n",
            "98104 tensor(0.9995, device='cuda:0')\n",
            "98107 tensor(0.9988, device='cuda:0')\n",
            "98116 tensor(1.0000, device='cuda:0')\n",
            "98117 tensor(0.9989, device='cuda:0')\n",
            "98120 tensor(0.9994, device='cuda:0')\n",
            "98126 tensor(0.9947, device='cuda:0')\n",
            "98135 tensor(0.9974, device='cuda:0')\n",
            "98139 tensor(0.9996, device='cuda:0')\n",
            "98142 tensor(0.9985, device='cuda:0')\n",
            "98146 tensor(0.9973, device='cuda:0')\n",
            "98147 tensor(0.9915, device='cuda:0')\n",
            "98151 tensor(0.9910, device='cuda:0')\n",
            "98152 tensor(0.9990, device='cuda:0')\n",
            "98154 tensor(0.9991, device='cuda:0')\n",
            "98160 tensor(0.9943, device='cuda:0')\n",
            "98161 tensor(0.9945, device='cuda:0')\n",
            "98169 tensor(0.9931, device='cuda:0')\n",
            "98171 tensor(0.9975, device='cuda:0')\n",
            "98182 tensor(0.9933, device='cuda:0')\n",
            "98183 tensor(0.9986, device='cuda:0')\n",
            "98185 tensor(0.9922, device='cuda:0')\n",
            "98188 tensor(0.9933, device='cuda:0')\n",
            "98189 tensor(0.9987, device='cuda:0')\n",
            "98194 tensor(0.9990, device='cuda:0')\n",
            "98201 tensor(0.9999, device='cuda:0')\n",
            "98209 tensor(0.9975, device='cuda:0')\n",
            "98211 tensor(0.9974, device='cuda:0')\n",
            "98213 tensor(0.9941, device='cuda:0')\n",
            "98224 tensor(0.9944, device='cuda:0')\n",
            "98242 tensor(0.9994, device='cuda:0')\n",
            "98245 tensor(0.9999, device='cuda:0')\n",
            "98247 tensor(0.9964, device='cuda:0')\n",
            "98258 tensor(0.9972, device='cuda:0')\n",
            "98259 tensor(0.9997, device='cuda:0')\n",
            "98260 tensor(0.9998, device='cuda:0')\n",
            "98263 tensor(0.9981, device='cuda:0')\n",
            "98270 tensor(0.9995, device='cuda:0')\n",
            "98273 tensor(0.9988, device='cuda:0')\n",
            "98282 tensor(0.9988, device='cuda:0')\n",
            "98285 tensor(0.9999, device='cuda:0')\n",
            "98288 tensor(0.9952, device='cuda:0')\n",
            "98293 tensor(0.9966, device='cuda:0')\n",
            "98300 tensor(0.9970, device='cuda:0')\n",
            "98306 tensor(0.9983, device='cuda:0')\n",
            "98309 tensor(0.9950, device='cuda:0')\n",
            "98310 tensor(0.9985, device='cuda:0')\n",
            "98323 tensor(0.9967, device='cuda:0')\n",
            "98327 tensor(0.9997, device='cuda:0')\n",
            "98328 tensor(0.9933, device='cuda:0')\n",
            "98332 tensor(0.9989, device='cuda:0')\n",
            "98358 tensor(0.9979, device='cuda:0')\n",
            "98359 tensor(0.9909, device='cuda:0')\n",
            "98372 tensor(0.9932, device='cuda:0')\n",
            "98373 tensor(0.9928, device='cuda:0')\n",
            "98375 tensor(0.9999, device='cuda:0')\n",
            "98379 tensor(0.9997, device='cuda:0')\n",
            "98380 tensor(0.9996, device='cuda:0')\n",
            "98382 tensor(0.9991, device='cuda:0')\n",
            "98384 tensor(0.9975, device='cuda:0')\n",
            "98393 tensor(0.9967, device='cuda:0')\n",
            "98414 tensor(0.9998, device='cuda:0')\n",
            "98430 tensor(0.9952, device='cuda:0')\n",
            "98432 tensor(0.9999, device='cuda:0')\n",
            "98434 tensor(0.9961, device='cuda:0')\n",
            "98436 tensor(0.9979, device='cuda:0')\n",
            "98438 tensor(0.9977, device='cuda:0')\n",
            "98451 tensor(0.9994, device='cuda:0')\n",
            "98452 tensor(0.9993, device='cuda:0')\n",
            "98453 tensor(0.9975, device='cuda:0')\n",
            "98454 tensor(0.9945, device='cuda:0')\n",
            "98456 tensor(0.9989, device='cuda:0')\n",
            "98458 tensor(0.9948, device='cuda:0')\n",
            "98461 tensor(0.9967, device='cuda:0')\n",
            "98467 tensor(0.9998, device='cuda:0')\n",
            "98468 tensor(0.9997, device='cuda:0')\n",
            "98469 tensor(0.9975, device='cuda:0')\n",
            "98472 tensor(0.9992, device='cuda:0')\n",
            "98478 tensor(0.9999, device='cuda:0')\n",
            "98482 tensor(0.9985, device='cuda:0')\n",
            "98488 tensor(0.9972, device='cuda:0')\n",
            "98489 tensor(0.9918, device='cuda:0')\n",
            "98503 tensor(0.9967, device='cuda:0')\n",
            "98504 tensor(0.9984, device='cuda:0')\n",
            "98508 tensor(0.9951, device='cuda:0')\n",
            "98515 tensor(0.9941, device='cuda:0')\n",
            "98522 tensor(0.9960, device='cuda:0')\n",
            "98527 tensor(0.9906, device='cuda:0')\n",
            "98538 tensor(0.9991, device='cuda:0')\n",
            "98539 tensor(0.9902, device='cuda:0')\n",
            "98540 tensor(0.9991, device='cuda:0')\n",
            "98546 tensor(0.9941, device='cuda:0')\n",
            "98547 tensor(0.9917, device='cuda:0')\n",
            "98552 tensor(0.9985, device='cuda:0')\n",
            "98564 tensor(0.9974, device='cuda:0')\n",
            "98566 tensor(0.9925, device='cuda:0')\n",
            "98569 tensor(0.9943, device='cuda:0')\n",
            "98586 tensor(0.9999, device='cuda:0')\n",
            "98592 tensor(0.9952, device='cuda:0')\n",
            "98598 tensor(0.9921, device='cuda:0')\n",
            "98603 tensor(0.9946, device='cuda:0')\n",
            "98623 tensor(0.9954, device='cuda:0')\n",
            "98629 tensor(0.9963, device='cuda:0')\n",
            "98630 tensor(0.9995, device='cuda:0')\n",
            "98644 tensor(0.9960, device='cuda:0')\n",
            "98646 tensor(0.9996, device='cuda:0')\n",
            "98648 tensor(0.9999, device='cuda:0')\n",
            "98649 tensor(0.9987, device='cuda:0')\n",
            "98659 tensor(0.9943, device='cuda:0')\n",
            "98663 tensor(0.9972, device='cuda:0')\n",
            "98673 tensor(0.9901, device='cuda:0')\n",
            "98676 tensor(0.9949, device='cuda:0')\n",
            "98677 tensor(0.9989, device='cuda:0')\n",
            "98678 tensor(0.9960, device='cuda:0')\n",
            "98684 tensor(0.9997, device='cuda:0')\n",
            "98686 tensor(0.9975, device='cuda:0')\n",
            "98688 tensor(0.9988, device='cuda:0')\n",
            "98690 tensor(0.9994, device='cuda:0')\n",
            "98704 tensor(0.9994, device='cuda:0')\n",
            "98706 tensor(0.9914, device='cuda:0')\n",
            "98710 tensor(0.9955, device='cuda:0')\n",
            "98714 tensor(0.9999, device='cuda:0')\n",
            "98715 tensor(0.9970, device='cuda:0')\n",
            "98717 tensor(0.9996, device='cuda:0')\n",
            "98719 tensor(0.9993, device='cuda:0')\n",
            "98721 tensor(0.9970, device='cuda:0')\n",
            "98725 tensor(0.9998, device='cuda:0')\n",
            "98727 tensor(0.9978, device='cuda:0')\n",
            "98729 tensor(0.9967, device='cuda:0')\n",
            "98744 tensor(0.9970, device='cuda:0')\n",
            "98747 tensor(0.9979, device='cuda:0')\n",
            "98753 tensor(0.9914, device='cuda:0')\n",
            "98776 tensor(0.9995, device='cuda:0')\n",
            "98787 tensor(0.9968, device='cuda:0')\n",
            "98800 tensor(0.9941, device='cuda:0')\n",
            "98816 tensor(0.9927, device='cuda:0')\n",
            "98817 tensor(0.9998, device='cuda:0')\n",
            "98819 tensor(0.9972, device='cuda:0')\n",
            "98820 tensor(0.9946, device='cuda:0')\n",
            "98826 tensor(0.9913, device='cuda:0')\n",
            "98828 tensor(0.9946, device='cuda:0')\n",
            "98839 tensor(0.9958, device='cuda:0')\n",
            "98849 tensor(0.9966, device='cuda:0')\n",
            "98851 tensor(0.9996, device='cuda:0')\n",
            "98860 tensor(0.9903, device='cuda:0')\n",
            "98865 tensor(0.9976, device='cuda:0')\n",
            "98868 tensor(0.9976, device='cuda:0')\n",
            "98875 tensor(0.9961, device='cuda:0')\n",
            "98877 tensor(0.9985, device='cuda:0')\n",
            "98884 tensor(0.9993, device='cuda:0')\n",
            "98889 tensor(0.9951, device='cuda:0')\n",
            "98896 tensor(0.9952, device='cuda:0')\n",
            "98898 tensor(0.9955, device='cuda:0')\n",
            "98900 tensor(0.9958, device='cuda:0')\n",
            "98905 tensor(0.9907, device='cuda:0')\n",
            "98910 tensor(0.9901, device='cuda:0')\n",
            "98911 tensor(0.9993, device='cuda:0')\n",
            "98920 tensor(0.9991, device='cuda:0')\n",
            "98924 tensor(0.9975, device='cuda:0')\n",
            "98929 tensor(0.9968, device='cuda:0')\n",
            "98931 tensor(0.9980, device='cuda:0')\n",
            "98951 tensor(0.9900, device='cuda:0')\n",
            "98954 tensor(0.9987, device='cuda:0')\n",
            "98958 tensor(0.9996, device='cuda:0')\n",
            "98971 tensor(0.9980, device='cuda:0')\n",
            "98973 tensor(0.9933, device='cuda:0')\n",
            "98984 tensor(0.9948, device='cuda:0')\n",
            "98985 tensor(0.9964, device='cuda:0')\n",
            "98987 tensor(0.9966, device='cuda:0')\n",
            "99001 tensor(0.9991, device='cuda:0')\n",
            "99002 tensor(0.9964, device='cuda:0')\n",
            "99003 tensor(0.9986, device='cuda:0')\n",
            "99005 tensor(0.9958, device='cuda:0')\n",
            "99015 tensor(0.9997, device='cuda:0')\n",
            "99017 tensor(0.9909, device='cuda:0')\n",
            "99025 tensor(0.9946, device='cuda:0')\n",
            "99036 tensor(0.9949, device='cuda:0')\n",
            "99037 tensor(0.9989, device='cuda:0')\n",
            "99038 tensor(0.9976, device='cuda:0')\n",
            "99048 tensor(0.9950, device='cuda:0')\n",
            "99054 tensor(0.9999, device='cuda:0')\n",
            "99057 tensor(0.9995, device='cuda:0')\n",
            "99069 tensor(0.9987, device='cuda:0')\n",
            "99073 tensor(0.9935, device='cuda:0')\n",
            "99074 tensor(0.9971, device='cuda:0')\n",
            "99084 tensor(0.9912, device='cuda:0')\n",
            "99100 tensor(0.9999, device='cuda:0')\n",
            "99104 tensor(0.9990, device='cuda:0')\n",
            "99111 tensor(0.9995, device='cuda:0')\n",
            "99114 tensor(0.9956, device='cuda:0')\n",
            "99117 tensor(0.9983, device='cuda:0')\n",
            "99121 tensor(0.9957, device='cuda:0')\n",
            "99127 tensor(0.9987, device='cuda:0')\n",
            "99135 tensor(0.9989, device='cuda:0')\n",
            "99137 tensor(0.9996, device='cuda:0')\n",
            "99150 tensor(0.9963, device='cuda:0')\n",
            "99154 tensor(0.9999, device='cuda:0')\n",
            "99155 tensor(0.9987, device='cuda:0')\n",
            "99156 tensor(0.9928, device='cuda:0')\n",
            "99162 tensor(0.9997, device='cuda:0')\n",
            "99163 tensor(0.9928, device='cuda:0')\n",
            "99172 tensor(0.9923, device='cuda:0')\n",
            "99175 tensor(0.9986, device='cuda:0')\n",
            "99176 tensor(0.9960, device='cuda:0')\n",
            "99180 tensor(0.9999, device='cuda:0')\n",
            "99186 tensor(0.9931, device='cuda:0')\n",
            "99202 tensor(0.9907, device='cuda:0')\n",
            "99203 tensor(0.9996, device='cuda:0')\n",
            "99207 tensor(0.9954, device='cuda:0')\n",
            "99209 tensor(0.9920, device='cuda:0')\n",
            "99212 tensor(0.9979, device='cuda:0')\n",
            "99215 tensor(0.9992, device='cuda:0')\n",
            "99216 tensor(0.9925, device='cuda:0')\n",
            "99229 tensor(0.9988, device='cuda:0')\n",
            "99237 tensor(0.9985, device='cuda:0')\n",
            "99244 tensor(0.9936, device='cuda:0')\n",
            "99246 tensor(0.9928, device='cuda:0')\n",
            "99249 tensor(0.9998, device='cuda:0')\n",
            "99250 tensor(0.9952, device='cuda:0')\n",
            "99256 tensor(0.9909, device='cuda:0')\n",
            "99257 tensor(0.9998, device='cuda:0')\n",
            "99258 tensor(0.9977, device='cuda:0')\n",
            "99273 tensor(0.9958, device='cuda:0')\n",
            "99275 tensor(0.9951, device='cuda:0')\n",
            "99276 tensor(0.9963, device='cuda:0')\n",
            "99283 tensor(0.9998, device='cuda:0')\n",
            "99289 tensor(0.9980, device='cuda:0')\n",
            "99290 tensor(0.9950, device='cuda:0')\n",
            "99295 tensor(0.9997, device='cuda:0')\n",
            "99300 tensor(0.9998, device='cuda:0')\n",
            "99305 tensor(0.9974, device='cuda:0')\n",
            "99306 tensor(0.9982, device='cuda:0')\n",
            "99315 tensor(0.9970, device='cuda:0')\n",
            "99340 tensor(0.9927, device='cuda:0')\n",
            "99344 tensor(0.9949, device='cuda:0')\n",
            "99348 tensor(0.9943, device='cuda:0')\n",
            "99349 tensor(0.9979, device='cuda:0')\n",
            "99351 tensor(0.9986, device='cuda:0')\n",
            "99354 tensor(0.9970, device='cuda:0')\n",
            "99362 tensor(0.9973, device='cuda:0')\n",
            "99371 tensor(0.9950, device='cuda:0')\n",
            "99372 tensor(0.9989, device='cuda:0')\n",
            "99373 tensor(0.9983, device='cuda:0')\n",
            "99376 tensor(0.9997, device='cuda:0')\n",
            "99390 tensor(0.9991, device='cuda:0')\n",
            "99392 tensor(0.9995, device='cuda:0')\n",
            "99401 tensor(0.9998, device='cuda:0')\n",
            "99404 tensor(0.9966, device='cuda:0')\n",
            "99412 tensor(0.9988, device='cuda:0')\n",
            "99413 tensor(0.9912, device='cuda:0')\n",
            "99414 tensor(0.9942, device='cuda:0')\n",
            "99417 tensor(0.9932, device='cuda:0')\n",
            "99420 tensor(0.9979, device='cuda:0')\n",
            "99421 tensor(0.9912, device='cuda:0')\n",
            "99446 tensor(0.9982, device='cuda:0')\n",
            "99448 tensor(0.9961, device='cuda:0')\n",
            "99451 tensor(0.9937, device='cuda:0')\n",
            "99457 tensor(0.9992, device='cuda:0')\n",
            "99459 tensor(0.9912, device='cuda:0')\n",
            "99461 tensor(0.9962, device='cuda:0')\n",
            "99463 tensor(0.9986, device='cuda:0')\n",
            "99468 tensor(0.9981, device='cuda:0')\n",
            "99471 tensor(0.9909, device='cuda:0')\n",
            "99488 tensor(0.9989, device='cuda:0')\n",
            "99489 tensor(0.9970, device='cuda:0')\n",
            "99491 tensor(0.9962, device='cuda:0')\n",
            "99496 tensor(0.9955, device='cuda:0')\n",
            "99505 tensor(0.9965, device='cuda:0')\n",
            "99507 tensor(0.9977, device='cuda:0')\n",
            "99508 tensor(0.9967, device='cuda:0')\n",
            "99510 tensor(0.9959, device='cuda:0')\n",
            "99518 tensor(0.9997, device='cuda:0')\n",
            "99519 tensor(0.9908, device='cuda:0')\n",
            "99522 tensor(0.9991, device='cuda:0')\n",
            "99529 tensor(0.9909, device='cuda:0')\n",
            "99536 tensor(0.9955, device='cuda:0')\n",
            "99547 tensor(0.9918, device='cuda:0')\n",
            "99556 tensor(0.9967, device='cuda:0')\n",
            "99565 tensor(0.9942, device='cuda:0')\n",
            "99574 tensor(0.9941, device='cuda:0')\n",
            "99582 tensor(0.9985, device='cuda:0')\n",
            "99589 tensor(0.9996, device='cuda:0')\n",
            "99594 tensor(0.9973, device='cuda:0')\n",
            "99600 tensor(0.9982, device='cuda:0')\n",
            "99608 tensor(0.9983, device='cuda:0')\n",
            "99625 tensor(0.9983, device='cuda:0')\n",
            "99627 tensor(0.9901, device='cuda:0')\n",
            "99638 tensor(0.9999, device='cuda:0')\n",
            "99641 tensor(0.9917, device='cuda:0')\n",
            "99648 tensor(0.9999, device='cuda:0')\n",
            "99654 tensor(0.9944, device='cuda:0')\n",
            "99656 tensor(0.9928, device='cuda:0')\n",
            "99658 tensor(0.9998, device='cuda:0')\n",
            "99660 tensor(0.9985, device='cuda:0')\n",
            "99663 tensor(0.9996, device='cuda:0')\n",
            "99674 tensor(0.9988, device='cuda:0')\n",
            "99697 tensor(0.9997, device='cuda:0')\n",
            "99705 tensor(0.9988, device='cuda:0')\n",
            "99710 tensor(0.9992, device='cuda:0')\n",
            "99714 tensor(0.9958, device='cuda:0')\n",
            "99715 tensor(0.9971, device='cuda:0')\n",
            "99723 tensor(0.9946, device='cuda:0')\n",
            "99725 tensor(0.9921, device='cuda:0')\n",
            "99728 tensor(0.9951, device='cuda:0')\n",
            "99731 tensor(0.9998, device='cuda:0')\n",
            "99737 tensor(0.9976, device='cuda:0')\n",
            "99744 tensor(0.9940, device='cuda:0')\n",
            "99745 tensor(0.9978, device='cuda:0')\n",
            "99754 tensor(0.9909, device='cuda:0')\n",
            "99757 tensor(0.9993, device='cuda:0')\n",
            "99758 tensor(0.9991, device='cuda:0')\n",
            "99760 tensor(0.9995, device='cuda:0')\n",
            "99765 tensor(0.9989, device='cuda:0')\n",
            "99767 tensor(0.9991, device='cuda:0')\n",
            "99769 tensor(0.9913, device='cuda:0')\n",
            "99772 tensor(0.9936, device='cuda:0')\n",
            "99773 tensor(0.9979, device='cuda:0')\n",
            "99780 tensor(0.9996, device='cuda:0')\n",
            "99791 tensor(0.9938, device='cuda:0')\n",
            "99804 tensor(0.9925, device='cuda:0')\n",
            "99814 tensor(0.9974, device='cuda:0')\n",
            "99815 tensor(0.9992, device='cuda:0')\n",
            "99820 tensor(0.9932, device='cuda:0')\n",
            "99830 tensor(0.9997, device='cuda:0')\n",
            "99853 tensor(0.9965, device='cuda:0')\n",
            "99863 tensor(0.9974, device='cuda:0')\n",
            "99866 tensor(0.9939, device='cuda:0')\n",
            "99872 tensor(0.9952, device='cuda:0')\n",
            "99875 tensor(0.9952, device='cuda:0')\n",
            "99882 tensor(0.9970, device='cuda:0')\n",
            "99889 tensor(0.9939, device='cuda:0')\n",
            "99894 tensor(0.9993, device='cuda:0')\n",
            "99899 tensor(0.9932, device='cuda:0')\n",
            "99916 tensor(0.9948, device='cuda:0')\n",
            "99919 tensor(0.9971, device='cuda:0')\n",
            "99921 tensor(0.9981, device='cuda:0')\n",
            "99922 tensor(0.9952, device='cuda:0')\n",
            "99945 tensor(0.9962, device='cuda:0')\n",
            "99948 tensor(0.9966, device='cuda:0')\n",
            "99950 tensor(0.9935, device='cuda:0')\n",
            "99951 tensor(0.9913, device='cuda:0')\n",
            "99959 tensor(0.9909, device='cuda:0')\n",
            "99964 tensor(0.9995, device='cuda:0')\n",
            "99968 tensor(0.9952, device='cuda:0')\n",
            "99969 tensor(0.9982, device='cuda:0')\n",
            "99974 tensor(0.9971, device='cuda:0')\n",
            "99977 tensor(0.9902, device='cuda:0')\n",
            "99982 tensor(0.9936, device='cuda:0')\n",
            "99997 tensor(0.9928, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZK9Pozt4SSa",
        "outputId": "04cd55fc-6628-4b66-bdb6-cd2f801676a8"
      },
      "source": [
        "print(label.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwEwRfaIrIwb",
        "outputId": "904d8e17-a984-4cb8-e010-e5f220a67671"
      },
      "source": [
        "print(len(l))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbbsNoy92Q1N"
      },
      "source": [
        "class NewSoup(Dataset):\n",
        "  def __init__(self,l):\n",
        "    super().__init__()\n",
        "    self.l = l\n",
        "  def __len__(self):\n",
        "    return len(self.l)\n",
        "  def __getitem__(self,i):\n",
        "    return self.l[i][0],self.l[i][1].item()\n",
        "newsoup = NewSoup(l)\n",
        "del l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqephFKhyVdl",
        "outputId": "ee458393-d664-4e9c-81f2-4457c6353911"
      },
      "source": [
        "dataset = torch.utils.data.ConcatDataset([soup,newsoup])\n",
        "print(len(dataset),len(soup),len(newsoup))\n",
        "souptrain = DataLoader(dataset=dataset,batch_size=batch_size,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23714 5000 18714\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}